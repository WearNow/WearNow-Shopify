{
  "version": 3,
  "sources": ["../../ts-invariant/src/invariant.ts", "../../@apollo/src/version.ts", "../../@apollo/src/utilities/globals/maybe.ts", "../../@apollo/src/utilities/globals/global.ts", "../../@apollo/src/utilities/common/makeUniqueId.ts", "../../@apollo/src/utilities/common/stringifyForDisplay.ts", "../../@apollo/src/utilities/globals/invariantWrappers.ts", "../../@apollo/src/utilities/globals/index.ts", "../../optimism/node_modules/@wry/trie/src/index.ts", "../../@wry/caches/src/strong.ts", "../../@wry/caches/src/weak.ts", "../../@wry/context/src/slot.ts", "../../@wry/context/src/index.ts", "../../optimism/src/context.ts", "../../optimism/src/helpers.ts", "../../optimism/src/entry.ts", "../../optimism/src/dep.ts", "../../optimism/src/index.ts", "../../@apollo/src/utilities/graphql/directives.ts", "../../@wry/trie/src/index.ts", "../../@apollo/src/utilities/common/canUse.ts", "../../@apollo/src/utilities/common/objects.ts", "../../@apollo/src/utilities/graphql/fragments.ts", "../../@apollo/src/utilities/caching/caches.ts", "../../@apollo/src/utilities/caching/sizes.ts", "../../@apollo/src/utilities/caching/getMemoryInternals.ts", "../../@apollo/src/utilities/common/canonicalStringify.ts", "../../@apollo/src/utilities/graphql/storeUtils.ts", "../../@apollo/src/utilities/graphql/getFromAST.ts", "../../@apollo/src/utilities/graphql/DocumentTransform.ts", "../../@apollo/src/utilities/graphql/print.ts", "../../@apollo/src/utilities/common/arrays.ts", "../../@apollo/src/utilities/graphql/transform.ts", "../../@apollo/src/utilities/policies/pagination.ts", "../../@apollo/src/utilities/common/mergeDeep.ts", "../../zen-observable-ts/module.js", "../../symbol-observable/es/ponyfill.js", "../../symbol-observable/es/index.js", "../../@apollo/src/utilities/observables/Observable.ts", "../../@apollo/src/utilities/common/cloneDeep.ts", "../../@apollo/src/utilities/common/maybeDeepFreeze.ts", "../../@apollo/src/utilities/observables/iteration.ts", "../../@apollo/src/utilities/observables/asyncMap.ts", "../../@apollo/src/utilities/observables/subclassing.ts", "../../@apollo/src/utilities/observables/Concast.ts", "../../@apollo/src/utilities/common/incrementalResult.ts", "../../@apollo/src/utilities/common/errorHandling.ts", "../../@apollo/src/utilities/common/compact.ts", "../../@apollo/src/utilities/common/mergeOptions.ts", "../../@wry/equality/src/index.ts", "../../@apollo/src/core/equalByQuery.ts", "../../@apollo/src/cache/core/cache.ts", "../../@apollo/src/cache/core/types/Cache.ts", "../../@apollo/src/cache/core/types/common.ts", "../../@apollo/src/cache/inmemory/helpers.ts", "../../@apollo/src/cache/inmemory/entityStore.ts", "../../@apollo/src/cache/inmemory/object-canon.ts", "../../@apollo/src/cache/inmemory/readFromStore.ts", "../../@apollo/src/cache/inmemory/reactiveVars.ts", "../../@apollo/src/cache/inmemory/key-extractor.ts", "../../@apollo/src/cache/inmemory/policies.ts", "../../@apollo/src/cache/inmemory/writeToStore.ts", "../../@apollo/src/cache/inmemory/inMemoryCache.ts", "../../@apollo/src/cache/inmemory/fragmentRegistry.ts"],
  "sourcesContent": ["const genericMessage = \"Invariant Violation\";\nconst {\n  setPrototypeOf = function (obj: any, proto: any) {\n    obj.__proto__ = proto;\n    return obj;\n  },\n} = Object as any;\n\nexport class InvariantError extends Error {\n  framesToPop = 1;\n  name = genericMessage;\n  constructor(message: string | number = genericMessage) {\n    super(\n      typeof message === \"number\"\n        ? `${genericMessage}: ${message} (see https://github.com/apollographql/invariant-packages)`\n        : message\n    );\n    setPrototypeOf(this, InvariantError.prototype);\n  }\n}\n\nexport function invariant(\n  condition: any,\n  message?: string | number,\n): asserts condition {\n  if (!condition) {\n    throw new InvariantError(message);\n  }\n}\n\nconst verbosityLevels = [\"debug\", \"log\", \"warn\", \"error\", \"silent\"] as const;\nexport type VerbosityLevel = (typeof verbosityLevels)[number];\nexport type ConsoleMethodName = Exclude<VerbosityLevel, \"silent\">;\nlet verbosityLevel = verbosityLevels.indexOf(\"log\");\n\nfunction wrapConsoleMethod<M extends ConsoleMethodName>(name: M) {\n  return function () {\n    if (verbosityLevels.indexOf(name) >= verbosityLevel) {\n      // Default to console.log if this host environment happens not to provide\n      // all the console.* methods we need.\n      const method = console[name] || console.log;\n      return method.apply(console, arguments as any);\n    }\n  } as (typeof console)[M];\n}\n\nexport namespace invariant {\n  export const debug = wrapConsoleMethod(\"debug\");\n  export const log = wrapConsoleMethod(\"log\");\n  export const warn = wrapConsoleMethod(\"warn\");\n  export const error = wrapConsoleMethod(\"error\");\n}\n\nexport function setVerbosity(level: VerbosityLevel): VerbosityLevel {\n  const old = verbosityLevels[verbosityLevel];\n  verbosityLevel = Math.max(0, verbosityLevels.indexOf(level));\n  return old;\n}\n\nexport default invariant;\n", "export const version = \"local\";\n", "export function maybe<T>(thunk: () => T): T | undefined {\n  try {\n    return thunk();\n  } catch {}\n}\n", "import { maybe } from \"./maybe.js\";\n\ndeclare global {\n  const __DEV__: boolean; // will be removed in `dist` by the `postprocessDist` script\n  interface Window {\n    __DEV__?: boolean;\n  }\n}\n\nexport default (maybe(() => globalThis) ||\n  maybe(() => window) ||\n  maybe(() => self) ||\n  maybe(() => global) ||\n  // We don't expect the Function constructor ever to be invoked at runtime, as\n  // long as at least one of globalThis, window, self, or global is defined, so\n  // we are under no obligation to make it easy for static analysis tools to\n  // detect syntactic usage of the Function constructor. If you think you can\n  // improve your static analysis to detect this obfuscation, think again. This\n  // is an arms race you cannot win, at least not in JavaScript.\n  maybe(function () {\n    return maybe.constructor(\"return this\")();\n  })) as typeof globalThis & Window;\n", "const prefixCounts = new Map<string, number>();\n\n// These IDs won't be globally unique, but they will be unique within this\n// process, thanks to the counter, and unguessable thanks to the random suffix.\nexport function makeUniqueId(prefix: string) {\n  const count = prefixCounts.get(prefix) || 1;\n  prefixCounts.set(prefix, count + 1);\n  return `${prefix}:${count}:${Math.random().toString(36).slice(2)}`;\n}\n", "import { makeUniqueId } from \"./makeUniqueId.js\";\n\nexport function stringifyForDisplay(value: any, space = 0): string {\n  const undefId = makeUniqueId(\"stringifyForDisplay\");\n  return JSON.stringify(\n    value,\n    (key, value) => {\n      return value === void 0 ? undefId : value;\n    },\n    space\n  )\n    .split(JSON.stringify(undefId))\n    .join(\"<undefined>\");\n}\n", "import { invariant as originalInvariant, InvariantError } from \"ts-invariant\";\nimport { version } from \"../../version.js\";\nimport global from \"./global.js\";\nimport type { ErrorCodes } from \"../../invariantErrorCodes.js\";\nimport { stringifyForDisplay } from \"../common/stringifyForDisplay.js\";\n\nfunction wrap(fn: (msg?: string, ...args: any[]) => void) {\n  return function (message?: string | number, ...args: any[]) {\n    if (typeof message === \"number\") {\n      const arg0 = message;\n      message = getHandledErrorMsg(arg0);\n      if (!message) {\n        message = getFallbackErrorMsg(arg0, args);\n        args = [];\n      }\n    }\n    fn(...[message].concat(args));\n  };\n}\n\ntype LogFunction = {\n  /**\n   * Logs a `$level` message if the user used `ts-invariant`'s `setVerbosity` to set\n   * a verbosity level of `$level` or lower. (defaults to `\"log\"`).\n   *\n   * The user will either be presented with a link to the documentation for the message,\n   * or they can use the `loadDevMessages` to add the message strings to the bundle.\n   * The documentation will display the message without argument substitution.\n   * Instead, the arguments will be printed on the console after the link.\n   *\n   * `message` can only be a string, a concatenation of strings, or a ternary statement\n   * that results in a string. This will be enforced on build, where the message will\n   * be replaced with a message number.\n   *\n   * String substitutions like %s, %o, %d or %f are supported.\n   */\n  (message?: any, ...optionalParams: unknown[]): void;\n};\n\ntype WrappedInvariant = {\n  /**\n   * Throws and InvariantError with the given message if the condition is false.\n   *\n   * `message` can only be a string, a concatenation of strings, or a ternary statement\n   * that results in a string. This will be enforced on build, where the message will\n   * be replaced with a message number.\n   *\n   * The user will either be presented with a link to the documentation for the message,\n   * or they can use the `loadErrorMessages` to add the message strings to the bundle.\n   * The documentation will display the message with the arguments substituted.\n   *\n   * String substitutions with %s are supported and will also return\n   * pretty-stringified objects.\n   * Excess `optionalParams` will be swallowed.\n   */\n  (\n    condition: any,\n    message?: string | number,\n    ...optionalParams: unknown[]\n  ): asserts condition;\n\n  debug: LogFunction;\n  log: LogFunction;\n  warn: LogFunction;\n  error: LogFunction;\n};\nconst invariant: WrappedInvariant = Object.assign(\n  function invariant(\n    condition: any,\n    message?: string | number,\n    ...args: unknown[]\n  ): asserts condition {\n    if (!condition) {\n      originalInvariant(\n        condition,\n        getHandledErrorMsg(message, args) || getFallbackErrorMsg(message, args)\n      );\n    }\n  },\n  {\n    debug: wrap(originalInvariant.debug),\n    log: wrap(originalInvariant.log),\n    warn: wrap(originalInvariant.warn),\n    error: wrap(originalInvariant.error),\n  }\n);\n\n/**\n * Returns an InvariantError.\n *\n * `message` can only be a string, a concatenation of strings, or a ternary statement\n * that results in a string. This will be enforced on build, where the message will\n * be replaced with a message number.\n * String substitutions with %s are supported and will also return\n * pretty-stringified objects.\n * Excess `optionalParams` will be swallowed.\n */\nfunction newInvariantError(\n  message?: string | number,\n  ...optionalParams: unknown[]\n) {\n  return new InvariantError(\n    getHandledErrorMsg(message, optionalParams) ||\n      getFallbackErrorMsg(message, optionalParams)\n  );\n}\n\nconst ApolloErrorMessageHandler = Symbol.for(\n  \"ApolloErrorMessageHandler_\" + version\n);\ndeclare global {\n  interface Window {\n    [ApolloErrorMessageHandler]?: {\n      (message: string | number, args: string[]): string | undefined;\n    } & ErrorCodes;\n  }\n}\n\nfunction stringify(arg: any) {\n  if (typeof arg == \"string\") {\n    return arg;\n  }\n\n  try {\n    return stringifyForDisplay(arg, 2).slice(0, 1000);\n  } catch {\n    return \"<non-serializable>\";\n  }\n}\n\nfunction getHandledErrorMsg(\n  message?: string | number,\n  messageArgs: unknown[] = []\n) {\n  if (!message) return;\n  return (\n    global[ApolloErrorMessageHandler] &&\n    global[ApolloErrorMessageHandler](message, messageArgs.map(stringify))\n  );\n}\n\nfunction getFallbackErrorMsg(\n  message?: string | number,\n  messageArgs: unknown[] = []\n) {\n  if (!message) return;\n  return `An error occurred! For more details, see the full error text at https://go.apollo.dev/c/err#${encodeURIComponent(\n    JSON.stringify({\n      version,\n      message,\n      args: messageArgs.map(stringify),\n    })\n  )}`;\n}\n\nexport {\n  invariant,\n  InvariantError,\n  newInvariantError,\n  ApolloErrorMessageHandler,\n};\n", "import {\n  invariant,\n  newInvariantError,\n  InvariantError,\n} from \"./invariantWrappers.js\";\n\nexport { maybe } from \"./maybe.js\";\nexport { default as global } from \"./global.js\";\nexport { invariant, newInvariantError, InvariantError };\n\n/**\n * @deprecated we do not use this internally anymore,\n * it is just exported for backwards compatibility\n */\n// this file is extempt from automatic `__DEV__` replacement\n// so we have to write it out here\n// @ts-ignore\nexport const DEV = globalThis.__DEV__ !== false;\nexport { DEV as __DEV__ };\n", "// A [trie](https://en.wikipedia.org/wiki/Trie) data structure that holds\n// object keys weakly, yet can also hold non-object keys, unlike the\n// native `WeakMap`.\n\n// If no makeData function is supplied, the looked-up data will be an empty,\n// null-prototype Object.\nconst defaultMakeData = () => Object.create(null);\n\n// Useful for processing arguments objects as well as arrays.\nconst { forEach, slice } = Array.prototype;\nconst { hasOwnProperty } = Object.prototype;\n\nexport class Trie<Data> {\n  // Since a `WeakMap` cannot hold primitive values as keys, we need a\n  // backup `Map` instance to hold primitive keys. Both `this._weakMap`\n  // and `this._strongMap` are lazily initialized.\n  private weak?: WeakMap<any, Trie<Data>>;\n  private strong?: Map<any, Trie<Data>>;\n  private data?: Data;\n\n  constructor(\n    private weakness = true,\n    private makeData: (array: any[]) => Data = defaultMakeData,\n  ) {}\n\n  public lookup<T extends any[]>(...array: T): Data {\n    return this.lookupArray(array);\n  }\n\n  public lookupArray<T extends IArguments | any[]>(array: T): Data {\n    let node: Trie<Data> = this;\n    forEach.call(array, key => node = node.getChildTrie(key));\n    return hasOwnProperty.call(node, \"data\")\n      ? node.data as Data\n      : node.data = this.makeData(slice.call(array));\n  }\n\n  public peek<T extends any[]>(...array: T): Data | undefined {\n    return this.peekArray(array);\n  }\n\n  public peekArray<T extends IArguments | any[]>(array: T): Data | undefined {\n    let node: Trie<Data> | undefined = this;\n\n    for (let i = 0, len = array.length; node && i < len; ++i) {\n      const map: Trie<Data>[\"weak\" | \"strong\"] =\n        this.weakness && isObjRef(array[i]) ? node.weak : node.strong;\n\n      node = map && map.get(array[i]);\n    }\n\n    return node && node.data;\n  }\n\n  private getChildTrie(key: any) {\n    const map = this.weakness && isObjRef(key)\n      ? this.weak || (this.weak = new WeakMap<any, Trie<Data>>())\n      : this.strong || (this.strong = new Map<any, Trie<Data>>());\n    let child = map.get(key);\n    if (!child) map.set(key, child = new Trie<Data>(this.weakness, this.makeData));\n    return child;\n  }\n}\n\nfunction isObjRef(value: any) {\n  switch (typeof value) {\n  case \"object\":\n    if (value === null) break;\n    // Fall through to return true...\n  case \"function\":\n    return true;\n  }\n  return false;\n}\n", "import type { CommonCache } from \"./common\";\n\ninterface Node<K, V> {\n  key: K;\n  value: V;\n  newer: Node<K, V> | null;\n  older: Node<K, V> | null;\n}\n\nfunction defaultDispose() {}\n\nexport class StrongCache<K = any, V = any> implements CommonCache<K, V> {\n  private map = new Map<K, Node<K, V>>();\n  private newest: Node<K, V> | null = null;\n  private oldest: Node<K, V> | null = null;\n\n  constructor(\n    private max = Infinity,\n    public dispose: (value: V, key: K) => void = defaultDispose,\n  ) {}\n\n  public has(key: K): boolean {\n    return this.map.has(key);\n  }\n\n  public get(key: K): V | undefined {\n    const node = this.getNode(key);\n    return node && node.value;\n  }\n\n  public get size() {\n    return this.map.size;\n  }\n\n  private getNode(key: K): Node<K, V> | undefined {\n    const node = this.map.get(key);\n\n    if (node && node !== this.newest) {\n      const { older, newer } = node;\n\n      if (newer) {\n        newer.older = older;\n      }\n\n      if (older) {\n        older.newer = newer;\n      }\n\n      node.older = this.newest;\n      node.older!.newer = node;\n\n      node.newer = null;\n      this.newest = node;\n\n      if (node === this.oldest) {\n        this.oldest = newer;\n      }\n    }\n\n    return node;\n  }\n\n  public set(key: K, value: V): V {\n    let node = this.getNode(key);\n    if (node) {\n      return node.value = value;\n    }\n\n    node = {\n      key,\n      value,\n      newer: null,\n      older: this.newest\n    };\n\n    if (this.newest) {\n      this.newest.newer = node;\n    }\n\n    this.newest = node;\n    this.oldest = this.oldest || node;\n\n    this.map.set(key, node);\n\n    return node.value;\n  }\n\n  public clean() {\n    while (this.oldest && this.map.size > this.max) {\n      this.delete(this.oldest.key);\n    }\n  }\n\n  public delete(key: K): boolean {\n    const node = this.map.get(key);\n    if (node) {\n      if (node === this.newest) {\n        this.newest = node.older;\n      }\n\n      if (node === this.oldest) {\n        this.oldest = node.newer;\n      }\n\n      if (node.newer) {\n        node.newer.older = node.older;\n      }\n\n      if (node.older) {\n        node.older.newer = node.newer;\n      }\n\n      this.map.delete(key);\n      this.dispose(node.value, key);\n\n      return true;\n    }\n\n    return false;\n  }\n}\n", "import type { CommonCache } from \"./common\";\n\ninterface PartialNode<K extends object, V> {\n  value: V;\n  newer: Node<K, V> | null;\n  older: Node<K, V> | null;\n}\n\ninterface UnfinalizedNode<K extends object, V> extends PartialNode<K, V> {\n  keyRef?: undefined;\n  key: K;\n}\n\ninterface FullNode<K extends object, V> extends PartialNode<K, V> {\n  keyRef: WeakRef<K>;\n  key?: undefined;\n}\n\ntype Node<K extends object, V> = FullNode<K, V> | UnfinalizedNode<K, V>;\n\nfunction noop() {}\nconst defaultDispose = noop;\n\nconst _WeakRef =\n  typeof WeakRef !== \"undefined\"\n    ? WeakRef\n    : (function <T>(value: T) {\n        return { deref: () => value } satisfies Omit<\n          WeakRef<any>,\n          typeof Symbol.toStringTag\n        >;\n      } as any as typeof WeakRef);\nconst _WeakMap = typeof WeakMap !== \"undefined\" ? WeakMap : Map;\nconst _FinalizationRegistry =\n  typeof FinalizationRegistry !== \"undefined\"\n    ? FinalizationRegistry\n    : (function <T>() {\n        return {\n          register: noop,\n          unregister: noop,\n        } satisfies Omit<FinalizationRegistry<T>, typeof Symbol.toStringTag>;\n      } as any as typeof FinalizationRegistry);\n\nconst finalizationBatchSize = 10024;\n\nexport class WeakCache<K extends object = any, V = any>\n  implements CommonCache<K, V>\n{\n  private map = new _WeakMap<K, Node<K, V>>();\n  private registry: FinalizationRegistry<Node<K, V>>;\n  private newest: Node<K, V> | null = null;\n  private oldest: Node<K, V> | null = null;\n  private unfinalizedNodes: Set<UnfinalizedNode<K, V>> = new Set();\n  private finalizationScheduled = false;\n  public size = 0;\n\n  constructor(\n    private max = Infinity,\n    public dispose: (value: V, key?: K) => void = defaultDispose\n  ) {\n    this.registry = new _FinalizationRegistry<Node<K, V>>(\n      this.deleteNode.bind(this)\n    );\n  }\n\n  public has(key: K): boolean {\n    return this.map.has(key);\n  }\n\n  public get(key: K): V | undefined {\n    const node = this.getNode(key);\n    return node && node.value;\n  }\n\n  private getNode(key: K): Node<K, V> | undefined {\n    const node = this.map.get(key);\n\n    if (node && node !== this.newest) {\n      const { older, newer } = node;\n\n      if (newer) {\n        newer.older = older;\n      }\n\n      if (older) {\n        older.newer = newer;\n      }\n\n      node.older = this.newest;\n      node.older!.newer = node;\n\n      node.newer = null;\n      this.newest = node;\n\n      if (node === this.oldest) {\n        this.oldest = newer;\n      }\n    }\n\n    return node;\n  }\n\n  public set(key: K, value: V): V {\n    let node = this.getNode(key);\n    if (node) {\n      return (node.value = value);\n    }\n\n    node = {\n      key,\n      value,\n      newer: null,\n      older: this.newest,\n    };\n\n    if (this.newest) {\n      this.newest.newer = node;\n    }\n\n    this.newest = node;\n    this.oldest = this.oldest || node;\n\n    this.scheduleFinalization(node);\n    this.map.set(key, node);\n    this.size++;\n\n    return node.value;\n  }\n\n  public clean() {\n    while (this.oldest && this.size > this.max) {\n      this.deleteNode(this.oldest);\n    }\n  }\n\n  private deleteNode(node: Node<K, V>) {\n    if (node === this.newest) {\n      this.newest = node.older;\n    }\n\n    if (node === this.oldest) {\n      this.oldest = node.newer;\n    }\n\n    if (node.newer) {\n      node.newer.older = node.older;\n    }\n\n    if (node.older) {\n      node.older.newer = node.newer;\n    }\n\n    this.size--;\n    const key = node.key || (node.keyRef && node.keyRef.deref());\n    this.dispose(node.value, key);\n    if (!node.keyRef) {\n      this.unfinalizedNodes.delete(node);\n    } else {\n      this.registry.unregister(node);\n    }\n    if (key) this.map.delete(key);\n  }\n\n  public delete(key: K): boolean {\n    const node = this.map.get(key);\n    if (node) {\n      this.deleteNode(node);\n\n      return true;\n    }\n\n    return false;\n  }\n\n  private scheduleFinalization(node: UnfinalizedNode<K, V>) {\n    this.unfinalizedNodes.add(node);\n    if (!this.finalizationScheduled) {\n      this.finalizationScheduled = true;\n      queueMicrotask(this.finalize);\n    }\n  }\n\n  private finalize = () => {\n    const iterator = this.unfinalizedNodes.values();\n    for (let i = 0; i < finalizationBatchSize; i++) {\n      const node = iterator.next().value;\n      if (!node) break;\n      this.unfinalizedNodes.delete(node);\n      const key = node.key;\n      delete (node as unknown as FullNode<K, V>).key;\n      (node as unknown as FullNode<K, V>).keyRef = new _WeakRef(key);\n      this.registry.register(key, node, node);\n    }\n    if (this.unfinalizedNodes.size > 0) {\n      queueMicrotask(this.finalize);\n    } else {\n      this.finalizationScheduled = false;\n    }\n  };\n}\n", "type Context = {\n  parent: Context | null;\n  slots: { [slotId: string]: any };\n}\n\n// This currentContext variable will only be used if the makeSlotClass\n// function is called, which happens only if this is the first copy of the\n// @wry/context package to be imported.\nlet currentContext: Context | null = null;\n\n// This unique internal object is used to denote the absence of a value\n// for a given Slot, and is never exposed to outside code.\nconst MISSING_VALUE: any = {};\n\nlet idCounter = 1;\n\n// Although we can't do anything about the cost of duplicated code from\n// accidentally bundling multiple copies of the @wry/context package, we can\n// avoid creating the Slot class more than once using makeSlotClass.\nconst makeSlotClass = () => class Slot<TValue> {\n  // If you have a Slot object, you can find out its slot.id, but you cannot\n  // guess the slot.id of a Slot you don't have access to, thanks to the\n  // randomized suffix.\n  public readonly id = [\n    \"slot\",\n    idCounter++,\n    Date.now(),\n    Math.random().toString(36).slice(2),\n  ].join(\":\");\n\n  public hasValue() {\n    for (let context = currentContext; context; context = context.parent) {\n      // We use the Slot object iself as a key to its value, which means the\n      // value cannot be obtained without a reference to the Slot object.\n      if (this.id in context.slots) {\n        const value = context.slots[this.id];\n        if (value === MISSING_VALUE) break;\n        if (context !== currentContext) {\n          // Cache the value in currentContext.slots so the next lookup will\n          // be faster. This caching is safe because the tree of contexts and\n          // the values of the slots are logically immutable.\n          currentContext!.slots[this.id] = value;\n        }\n        return true;\n      }\n    }\n    if (currentContext) {\n      // If a value was not found for this Slot, it's never going to be found\n      // no matter how many times we look it up, so we might as well cache\n      // the absence of the value, too.\n      currentContext.slots[this.id] = MISSING_VALUE;\n    }\n    return false;\n  }\n\n  public getValue(): TValue | undefined {\n    if (this.hasValue()) {\n      return currentContext!.slots[this.id] as TValue;\n    }\n  }\n\n  public withValue<TResult, TArgs extends any[], TThis = any>(\n    value: TValue,\n    callback: (this: TThis, ...args: TArgs) => TResult,\n    // Given the prevalence of arrow functions, specifying arguments is likely\n    // to be much more common than specifying `this`, hence this ordering:\n    args?: TArgs,\n    thisArg?: TThis,\n  ): TResult {\n    const slots = {\n      __proto__: null,\n      [this.id]: value,\n    };\n    const parent = currentContext;\n    currentContext = { parent, slots };\n    try {\n      // Function.prototype.apply allows the arguments array argument to be\n      // omitted or undefined, so args! is fine here.\n      return callback.apply(thisArg!, args!);\n    } finally {\n      currentContext = parent;\n    }\n  }\n\n  // Capture the current context and wrap a callback function so that it\n  // reestablishes the captured context when called.\n  static bind<TArgs extends any[], TResult, TThis = any>(\n    callback: (this: TThis, ...args: TArgs) => TResult,\n  ) {\n    const context = currentContext;\n    return function (this: TThis) {\n      const saved = currentContext;\n      try {\n        currentContext = context;\n        return callback.apply(this, arguments as any);\n      } finally {\n        currentContext = saved;\n      }\n    } as typeof callback;\n  }\n\n  // Immediately run a callback function without any captured context.\n  static noContext<TResult, TArgs extends any[], TThis = any>(\n    callback: (this: TThis, ...args: TArgs) => TResult,\n    // Given the prevalence of arrow functions, specifying arguments is likely\n    // to be much more common than specifying `this`, hence this ordering:\n    args?: TArgs,\n    thisArg?: TThis,\n  ) {\n    if (currentContext) {\n      const saved = currentContext;\n      try {\n        currentContext = null;\n        // Function.prototype.apply allows the arguments array argument to be\n        // omitted or undefined, so args! is fine here.\n        return callback.apply(thisArg!, args!);\n      } finally {\n        currentContext = saved;\n      }\n    } else {\n      return callback.apply(thisArg!, args!);\n    }\n  }\n};\n\nfunction maybe<T>(fn: () => T): T | undefined {\n  try {\n    return fn();\n  } catch (ignored) {}\n}\n\n// We store a single global implementation of the Slot class as a permanent\n// non-enumerable property of the globalThis object. This obfuscation does\n// nothing to prevent access to the Slot class, but at least it ensures the\n// implementation (i.e. currentContext) cannot be tampered with, and all copies\n// of the @wry/context package (hopefully just one) will share the same Slot\n// implementation. Since the first copy of the @wry/context package to be\n// imported wins, this technique imposes a steep cost for any future breaking\n// changes to the Slot class.\nconst globalKey = \"@wry/context:Slot\";\n\nconst host =\n  // Prefer globalThis when available.\n  // https://github.com/benjamn/wryware/issues/347\n  maybe(() => globalThis) ||\n  // Fall back to global, which works in Node.js and may be converted by some\n  // bundlers to the appropriate identifier (window, self, ...) depending on the\n  // bundling target. https://github.com/endojs/endo/issues/576#issuecomment-1178515224\n  maybe(() => global) ||\n  // Otherwise, use a dummy host that's local to this module. We used to fall\n  // back to using the Array constructor as a namespace, but that was flagged in\n  // https://github.com/benjamn/wryware/issues/347, and can be avoided.\n  Object.create(null) as typeof Array;\n\n// Whichever globalHost we're using, make TypeScript happy about the additional\n// globalKey property.\nconst globalHost: typeof host & {\n  [globalKey]?: typeof Slot;\n} = host;\n\nexport const Slot: ReturnType<typeof makeSlotClass> =\n  globalHost[globalKey] ||\n  // Earlier versions of this package stored the globalKey property on the Array\n  // constructor, so we check there as well, to prevent Slot class duplication.\n  (Array as typeof globalHost)[globalKey] ||\n  (function (Slot) {\n    try {\n      Object.defineProperty(globalHost, globalKey, {\n        value: Slot,\n        enumerable: false,\n        writable: false,\n        // When it was possible for globalHost to be the Array constructor (a\n        // legacy Slot dedup strategy), it was important for the property to be\n        // configurable:true so it could be deleted. That does not seem to be as\n        // important when globalHost is the global object, but I don't want to\n        // cause similar problems again, and configurable:true seems safest.\n        // https://github.com/endojs/endo/issues/576#issuecomment-1178274008\n        configurable: true\n      });\n    } finally {\n      return Slot;\n    }\n  })(makeSlotClass());\n", "import { Slot } from \"./slot.js\";\nexport { Slot }\nexport const { bind, noContext } = Slot;\n\n// Relying on the @types/node declaration of global.setTimeout can make\n// things tricky for dowstream projects (see PR #7).\ndeclare function setTimeout(\n  callback: (...args: any[]) => any,\n  ms?: number,\n  ...args: any[]\n): any;\n\n// Like global.setTimeout, except the callback runs with captured context.\nexport { setTimeoutWithContext as setTimeout };\nfunction setTimeoutWithContext(callback: () => any, delay: number) {\n  return setTimeout(bind(callback), delay);\n}\n\n// Turn any generator function into an async function (using yield instead\n// of await), with context automatically preserved across yields.\nexport function asyncFromGen<\n  TArgs extends any[],\n  TYield = any,\n  TReturn = any,\n  TNext = any,\n>(\n  genFn: (...args: TArgs) => Generator<TYield, TReturn, TNext>\n) {\n  return function (this: any) {\n    const gen = genFn.apply(this, arguments as any);\n\n    type Method = (\n      this: Generator<TYield, TReturn, TNext>,\n      arg: any,\n    ) => IteratorResult<TYield, TReturn>;\n\n    const boundNext: Method = bind(gen.next);\n    const boundThrow: Method = bind(gen.throw!);\n\n    return new Promise((resolve, reject) => {\n      function invoke(method: Method, argument: any) {\n        try {\n          var result: any = method.call(gen, argument);\n        } catch (error) {\n          return reject(error);\n        }\n        const next = result.done ? resolve : invokeNext;\n        if (isPromiseLike(result.value)) {\n          result.value.then(next, result.done ? reject : invokeThrow);\n        } else {\n          next(result.value);\n        }\n      }\n      const invokeNext = (value?: any) => invoke(boundNext, value);\n      const invokeThrow = (error: any) => invoke(boundThrow, error);\n      invokeNext();\n    });\n  } as (...args: TArgs) => Promise<any>;\n}\n\nfunction isPromiseLike(value: any): value is PromiseLike<any> {\n  return value && typeof value.then === \"function\";\n}\n\n// If you use the fibers npm package to implement coroutines in Node.js,\n// you should call this function at least once to ensure context management\n// remains coherent across any yields.\nconst wrappedFibers: Function[] = [];\nexport function wrapYieldingFiberMethods<F extends Function>(Fiber: F): F {\n  // There can be only one implementation of Fiber per process, so this array\n  // should never grow longer than one element.\n  if (wrappedFibers.indexOf(Fiber) < 0) {\n    const wrap = (obj: any, method: string) => {\n      const fn = obj[method];\n      obj[method] = function () {\n        return noContext(fn, arguments as any, this);\n      };\n    }\n    // These methods can yield, according to\n    // https://github.com/laverdet/node-fibers/blob/ddebed9b8ae3883e57f822e2108e6943e5c8d2a8/fibers.js#L97-L100\n    wrap(Fiber, \"yield\");\n    wrap(Fiber.prototype, \"run\");\n    wrap(Fiber.prototype, \"throwInto\");\n    wrappedFibers.push(Fiber);\n  }\n  return Fiber;\n}\n", "import { Slot } from \"@wry/context\";\nimport { AnyEntry } from \"./entry.js\";\n\nexport const parentEntrySlot = new Slot<AnyEntry | undefined>();\n\nexport function nonReactive<R>(fn: () => R): R {\n  return parentEntrySlot.withValue(void 0, fn);\n}\n\nexport { Slot }\nexport {\n  bind as bindContext,\n  noContext,\n  setTimeout,\n  asyncFromGen,\n} from \"@wry/context\";\n", "export type NoInfer<T> = [T][T extends any ? 0 : never];\n\nexport const {\n  hasOwnProperty,\n} = Object.prototype;\n\nexport const arrayFromSet: <T>(set: Set<T>) => T[] =\n  Array.from ||\n  function (set) {\n    const array: any[] = [];\n    set.forEach(item => array.push(item));\n    return array;\n  };\n\nexport type Unsubscribable = {\n  unsubscribe?: void | (() => any);\n}\n\nexport function maybeUnsubscribe(entryOrDep: Unsubscribable) {\n  const { unsubscribe } = entryOrDep;\n  if (typeof unsubscribe === \"function\") {\n    entryOrDep.unsubscribe = void 0;\n    unsubscribe();\n  }\n}\n", "import { parentEntrySlot } from \"./context.js\";\nimport { OptimisticWrapOptions } from \"./index.js\";\nimport { Dep } from \"./dep.js\";\nimport { maybeUnsubscribe, arrayFromSet, Unsubscribable } from \"./helpers.js\";\n\nconst emptySetPool: Set<any>[] = [];\nconst POOL_TARGET_SIZE = 100;\n\n// Since this package might be used browsers, we should avoid using the\n// Node built-in assert module.\nfunction assert(condition: any, optionalMessage?: string) {\n  if (! condition) {\n    throw new Error(optionalMessage || \"assertion failure\");\n  }\n}\n\n// Since exceptions are cached just like normal values, we need an efficient\n// way of representing unknown, ordinary, and exceptional values.\ntype Value<T> =\n  | []           // unknown\n  | [T]          // known value\n  | [void, any]; // known exception\n\nfunction valueIs(a: Value<any>, b: Value<any>) {\n  const len = a.length;\n  return (\n    // Unknown values are not equal to each other.\n    len > 0 &&\n    // Both values must be ordinary (or both exceptional) to be equal.\n    len === b.length &&\n    // The underlying value or exception must be the same.\n    a[len - 1] === b[len - 1]\n  );\n}\n\nfunction valueGet<T>(value: Value<T>): T {\n  switch (value.length) {\n    case 0: throw new Error(\"unknown value\");\n    case 1: return value[0];\n    case 2: throw value[1];\n  }\n}\n\nfunction valueCopy<T>(value: Value<T>): Value<T> {\n  return value.slice(0) as Value<T>;\n}\n\nexport type AnyEntry = Entry<any, any>;\n\nexport class Entry<TArgs extends any[], TValue> {\n  public static count = 0;\n\n  public normalizeResult: OptimisticWrapOptions<TArgs, any, any, TValue>[\"normalizeResult\"];\n  public subscribe: OptimisticWrapOptions<TArgs>[\"subscribe\"];\n  public unsubscribe: Unsubscribable[\"unsubscribe\"];\n\n  public readonly parents = new Set<AnyEntry>();\n  public readonly childValues = new Map<AnyEntry, Value<any>>();\n\n  // When this Entry has children that are dirty, this property becomes\n  // a Set containing other Entry objects, borrowed from emptySetPool.\n  // When the set becomes empty, it gets recycled back to emptySetPool.\n  public dirtyChildren: Set<AnyEntry> | null = null;\n\n  public dirty = true;\n  public recomputing = false;\n  public readonly value: Value<TValue> = [];\n\n  constructor(\n    public readonly fn: (...args: TArgs) => TValue,\n  ) {\n    ++Entry.count;\n  }\n\n  public peek(): TValue | undefined {\n    if (this.value.length === 1 && !mightBeDirty(this)) {\n      rememberParent(this);\n      return this.value[0];\n    }\n  }\n\n  // This is the most important method of the Entry API, because it\n  // determines whether the cached this.value can be returned immediately,\n  // or must be recomputed. The overall performance of the caching system\n  // depends on the truth of the following observations: (1) this.dirty is\n  // usually false, (2) this.dirtyChildren is usually null/empty, and thus\n  // (3) valueGet(this.value) is usually returned without recomputation.\n  public recompute(args: TArgs): TValue {\n    assert(! this.recomputing, \"already recomputing\");\n    rememberParent(this);\n    return mightBeDirty(this)\n      ? reallyRecompute(this, args)\n      : valueGet(this.value);\n  }\n\n  public setDirty() {\n    if (this.dirty) return;\n    this.dirty = true;\n    reportDirty(this);\n    // We can go ahead and unsubscribe here, since any further dirty\n    // notifications we receive will be redundant, and unsubscribing may\n    // free up some resources, e.g. file watchers.\n    maybeUnsubscribe(this);\n  }\n\n  public dispose() {\n    this.setDirty();\n\n    // Sever any dependency relationships with our own children, so those\n    // children don't retain this parent Entry in their child.parents sets,\n    // thereby preventing it from being fully garbage collected.\n    forgetChildren(this);\n\n    // Because this entry has been kicked out of the cache (in index.js),\n    // we've lost the ability to find out if/when this entry becomes dirty,\n    // whether that happens through a subscription, because of a direct call\n    // to entry.setDirty(), or because one of its children becomes dirty.\n    // Because of this loss of future information, we have to assume the\n    // worst (that this entry might have become dirty very soon), so we must\n    // immediately mark this entry's parents as dirty. Normally we could\n    // just call entry.setDirty() rather than calling parent.setDirty() for\n    // each parent, but that would leave this entry in parent.childValues\n    // and parent.dirtyChildren, which would prevent the child from being\n    // truly forgotten.\n    eachParent(this, (parent, child) => {\n      parent.setDirty();\n      forgetChild(parent, this);\n    });\n  }\n\n  public forget() {\n    // The code that creates Entry objects in index.ts will replace this method\n    // with one that actually removes the Entry from the cache, which will also\n    // trigger the entry.dispose method.\n    this.dispose();\n  }\n\n  private deps: Set<Dep<any>> | null = null;\n\n  public dependOn(dep: Dep<any>) {\n    dep.add(this);\n    if (! this.deps) {\n      this.deps = emptySetPool.pop() || new Set<Set<AnyEntry>>();\n    }\n    this.deps.add(dep);\n  }\n\n  public forgetDeps() {\n    if (this.deps) {\n      arrayFromSet(this.deps).forEach(dep => dep.delete(this));\n      this.deps.clear();\n      emptySetPool.push(this.deps);\n      this.deps = null;\n    }\n  }\n}\n\nfunction rememberParent(child: AnyEntry) {\n  const parent = parentEntrySlot.getValue();\n  if (parent) {\n    child.parents.add(parent);\n\n    if (! parent.childValues.has(child)) {\n      parent.childValues.set(child, []);\n    }\n\n    if (mightBeDirty(child)) {\n      reportDirtyChild(parent, child);\n    } else {\n      reportCleanChild(parent, child);\n    }\n\n    return parent;\n  }\n}\n\nfunction reallyRecompute(entry: AnyEntry, args: any[]) {\n  forgetChildren(entry);\n\n  // Set entry as the parent entry while calling recomputeNewValue(entry).\n  parentEntrySlot.withValue(entry, recomputeNewValue, [entry, args]);\n\n  if (maybeSubscribe(entry, args)) {\n    // If we successfully recomputed entry.value and did not fail to\n    // (re)subscribe, then this Entry is no longer explicitly dirty.\n    setClean(entry);\n  }\n\n  return valueGet(entry.value);\n}\n\nfunction recomputeNewValue(entry: AnyEntry, args: any[]) {\n  entry.recomputing = true;\n\n  const { normalizeResult } = entry;\n  let oldValueCopy: Value<any> | undefined;\n  if (normalizeResult && entry.value.length === 1) {\n    oldValueCopy = valueCopy(entry.value);\n  }\n\n  // Make entry.value an empty array, representing an unknown value.\n  entry.value.length = 0;\n\n  try {\n    // If entry.fn succeeds, entry.value will become a normal Value.\n    entry.value[0] = entry.fn.apply(null, args);\n\n    // If we have a viable oldValueCopy to compare with the (successfully\n    // recomputed) new entry.value, and they are not already === identical, give\n    // normalizeResult a chance to pick/choose/reuse parts of oldValueCopy[0]\n    // and/or entry.value[0] to determine the final cached entry.value.\n    if (normalizeResult && oldValueCopy && !valueIs(oldValueCopy, entry.value)) {\n      try {\n        entry.value[0] = normalizeResult(entry.value[0], oldValueCopy[0]);\n      } catch {\n        // If normalizeResult throws, just use the newer value, rather than\n        // saving the exception as entry.value[1].\n      }\n    }\n\n  } catch (e) {\n    // If entry.fn throws, entry.value will hold that exception.\n    entry.value[1] = e;\n  }\n\n  // Either way, this line is always reached.\n  entry.recomputing = false;\n}\n\nfunction mightBeDirty(entry: AnyEntry) {\n  return entry.dirty || !!(entry.dirtyChildren && entry.dirtyChildren.size);\n}\n\nfunction setClean(entry: AnyEntry) {\n  entry.dirty = false;\n\n  if (mightBeDirty(entry)) {\n    // This Entry may still have dirty children, in which case we can't\n    // let our parents know we're clean just yet.\n    return;\n  }\n\n  reportClean(entry);\n}\n\nfunction reportDirty(child: AnyEntry) {\n  eachParent(child, reportDirtyChild);\n}\n\nfunction reportClean(child: AnyEntry) {\n  eachParent(child, reportCleanChild);\n}\n\nfunction eachParent(\n  child: AnyEntry,\n  callback: (parent: AnyEntry, child: AnyEntry) => any,\n) {\n  const parentCount = child.parents.size;\n  if (parentCount) {\n    const parents = arrayFromSet(child.parents);\n    for (let i = 0; i < parentCount; ++i) {\n      callback(parents[i], child);\n    }\n  }\n}\n\n// Let a parent Entry know that one of its children may be dirty.\nfunction reportDirtyChild(parent: AnyEntry, child: AnyEntry) {\n  // Must have called rememberParent(child) before calling\n  // reportDirtyChild(parent, child).\n  assert(parent.childValues.has(child));\n  assert(mightBeDirty(child));\n  const parentWasClean = !mightBeDirty(parent);\n\n  if (! parent.dirtyChildren) {\n    parent.dirtyChildren = emptySetPool.pop() || new Set;\n\n  } else if (parent.dirtyChildren.has(child)) {\n    // If we already know this child is dirty, then we must have already\n    // informed our own parents that we are dirty, so we can terminate\n    // the recursion early.\n    return;\n  }\n\n  parent.dirtyChildren.add(child);\n\n  // If parent was clean before, it just became (possibly) dirty (according to\n  // mightBeDirty), since we just added child to parent.dirtyChildren.\n  if (parentWasClean) {\n    reportDirty(parent);\n  }\n}\n\n// Let a parent Entry know that one of its children is no longer dirty.\nfunction reportCleanChild(parent: AnyEntry, child: AnyEntry) {\n  // Must have called rememberChild(child) before calling\n  // reportCleanChild(parent, child).\n  assert(parent.childValues.has(child));\n  assert(! mightBeDirty(child));\n\n  const childValue = parent.childValues.get(child)!;\n  if (childValue.length === 0) {\n    parent.childValues.set(child, valueCopy(child.value));\n  } else if (! valueIs(childValue, child.value)) {\n    parent.setDirty();\n  }\n\n  removeDirtyChild(parent, child);\n\n  if (mightBeDirty(parent)) {\n    return;\n  }\n\n  reportClean(parent);\n}\n\nfunction removeDirtyChild(parent: AnyEntry, child: AnyEntry) {\n  const dc = parent.dirtyChildren;\n  if (dc) {\n    dc.delete(child);\n    if (dc.size === 0) {\n      if (emptySetPool.length < POOL_TARGET_SIZE) {\n        emptySetPool.push(dc);\n      }\n      parent.dirtyChildren = null;\n    }\n  }\n}\n\n// Removes all children from this entry and returns an array of the\n// removed children.\nfunction forgetChildren(parent: AnyEntry) {\n  if (parent.childValues.size > 0) {\n    parent.childValues.forEach((_value, child) => {\n      forgetChild(parent, child);\n    });\n  }\n\n  // Remove this parent Entry from any sets to which it was added by the\n  // addToSet method.\n  parent.forgetDeps();\n\n  // After we forget all our children, this.dirtyChildren must be empty\n  // and therefore must have been reset to null.\n  assert(parent.dirtyChildren === null);\n}\n\nfunction forgetChild(parent: AnyEntry, child: AnyEntry) {\n  child.parents.delete(parent);\n  parent.childValues.delete(child);\n  removeDirtyChild(parent, child);\n}\n\nfunction maybeSubscribe(entry: AnyEntry, args: any[]) {\n  if (typeof entry.subscribe === \"function\") {\n    try {\n      maybeUnsubscribe(entry); // Prevent double subscriptions.\n      entry.unsubscribe = entry.subscribe.apply(null, args);\n    } catch (e) {\n      // If this Entry has a subscribe function and it threw an exception\n      // (or an unsubscribe function it previously returned now throws),\n      // return false to indicate that we were not able to subscribe (or\n      // unsubscribe), and this Entry should remain dirty.\n      entry.setDirty();\n      return false;\n    }\n  }\n\n  // Returning true indicates either that there was no entry.subscribe\n  // function or that it succeeded.\n  return true;\n}\n", "import { AnyEntry } from \"./entry.js\";\nimport { OptimisticWrapOptions } from \"./index.js\";\nimport { parentEntrySlot } from \"./context.js\";\nimport {\n  hasOwnProperty,\n  Unsubscribable,\n  maybeUnsubscribe,\n  arrayFromSet,\n } from \"./helpers.js\";\n\ntype EntryMethodName = keyof typeof EntryMethods;\nconst EntryMethods = {\n  setDirty: true, // Mark parent Entry as needing to be recomputed (default)\n  dispose: true,  // Detach parent Entry from parents and children, but leave in LRU cache\n  forget: true,   // Fully remove parent Entry from LRU cache and computation graph\n};\n\nexport type OptimisticDependencyFunction<TKey> =\n  ((key: TKey) => void) & {\n    dirty: (key: TKey, entryMethodName?: EntryMethodName) => void;\n  };\n\nexport type Dep<TKey> = Set<AnyEntry> & {\n  subscribe: OptimisticWrapOptions<[TKey]>[\"subscribe\"];\n} & Unsubscribable;\n\nexport function dep<TKey>(options?: {\n  subscribe: Dep<TKey>[\"subscribe\"];\n}) {\n  const depsByKey = new Map<TKey, Dep<TKey>>();\n  const subscribe = options && options.subscribe;\n\n  function depend(key: TKey) {\n    const parent = parentEntrySlot.getValue();\n    if (parent) {\n      let dep = depsByKey.get(key);\n      if (!dep) {\n        depsByKey.set(key, dep = new Set as Dep<TKey>);\n      }\n      parent.dependOn(dep);\n      if (typeof subscribe === \"function\") {\n        maybeUnsubscribe(dep);\n        dep.unsubscribe = subscribe(key);\n      }\n    }\n  }\n\n  depend.dirty = function dirty(\n    key: TKey,\n    entryMethodName?: EntryMethodName,\n  ) {\n    const dep = depsByKey.get(key);\n    if (dep) {\n      const m: EntryMethodName = (\n        entryMethodName &&\n        hasOwnProperty.call(EntryMethods, entryMethodName)\n      ) ? entryMethodName : \"setDirty\";\n      // We have to use arrayFromSet(dep).forEach instead of dep.forEach,\n      // because modifying a Set while iterating over it can cause elements in\n      // the Set to be removed from the Set before they've been iterated over.\n      arrayFromSet(dep).forEach(entry => entry[m]());\n      depsByKey.delete(key);\n      maybeUnsubscribe(dep);\n    }\n  };\n\n  return depend as OptimisticDependencyFunction<TKey>;\n}\n", "import { Trie } from \"@wry/trie\";\n\nimport { StrongCache, CommonCache } from \"@wry/caches\";\nimport { Entry, AnyEntry } from \"./entry.js\";\nimport { parentEntrySlot } from \"./context.js\";\nimport type { NoInfer } from \"./helpers.js\";\n\n// These helper functions are important for making optimism work with\n// asynchronous code. In order to register parent-child dependencies,\n// optimism needs to know about any currently active parent computations.\n// In ordinary synchronous code, the parent context is implicit in the\n// execution stack, but asynchronous code requires some extra guidance in\n// order to propagate context from one async task segment to the next.\nexport {\n  bindContext,\n  noContext,\n  nonReactive,\n  setTimeout,\n  asyncFromGen,\n  Slot,\n} from \"./context.js\";\n\n// A lighter-weight dependency, similar to OptimisticWrapperFunction, except\n// with only one argument, no makeCacheKey, no wrapped function to recompute,\n// and no result value. Useful for representing dependency leaves in the graph\n// of computation. Subscriptions are supported.\nexport { dep, OptimisticDependencyFunction } from \"./dep.js\";\n\n// The defaultMakeCacheKey function is remarkably powerful, because it gives\n// a unique object for any shallow-identical list of arguments. If you need\n// to implement a custom makeCacheKey function, you may find it helpful to\n// delegate the final work to defaultMakeCacheKey, which is why we export it\n// here. However, you may want to avoid defaultMakeCacheKey if your runtime\n// does not support WeakMap, or you have the ability to return a string key.\n// In those cases, just write your own custom makeCacheKey functions.\nlet defaultKeyTrie: Trie<object> | undefined;\nexport function defaultMakeCacheKey(...args: any[]): object {\n  const trie = defaultKeyTrie || (\n    defaultKeyTrie = new Trie(typeof WeakMap === \"function\")\n  );\n  return trie.lookupArray(args);\n}\n\n// If you're paranoid about memory leaks, or you want to avoid using WeakMap\n// under the hood, but you still need the behavior of defaultMakeCacheKey,\n// import this constructor to create your own tries.\nexport { Trie as KeyTrie }\n\nexport type OptimisticWrapperFunction<\n  TArgs extends any[],\n  TResult,\n  TKeyArgs extends any[] = TArgs,\n  TCacheKey = any,\n> = ((...args: TArgs) => TResult) & {\n  // Get the current number of Entry objects in the LRU cache.\n  readonly size: number;\n\n  // Snapshot of wrap options used to create this wrapper function.\n  options: OptionsWithCacheInstance<TArgs, TKeyArgs, TCacheKey>;\n\n  // \"Dirty\" any cached Entry stored for the given arguments, marking that Entry\n  // and its ancestors as potentially needing to be recomputed. The .dirty(...)\n  // method of an optimistic function takes the same parameter types as the\n  // original function by default, unless a keyArgs function is configured, and\n  // then it matters that .dirty takes TKeyArgs instead of TArgs.\n  dirty: (...args: TKeyArgs) => void;\n  // A version of .dirty that accepts a key returned by .getKey.\n  dirtyKey: (key: TCacheKey | undefined) => void;\n\n  // Examine the current value without recomputing it.\n  peek: (...args: TKeyArgs) => TResult | undefined;\n  // A version of .peek that accepts a key returned by .getKey.\n  peekKey: (key: TCacheKey | undefined) => TResult | undefined;\n\n  // Completely remove the entry from the cache, dirtying any parent entries.\n  forget: (...args: TKeyArgs) => boolean;\n  // A version of .forget that accepts a key returned by .getKey.\n  forgetKey: (key: TCacheKey | undefined) => boolean;\n\n  // In order to use the -Key version of the above functions, you need a key\n  // rather than the arguments used to compute the key. These two functions take\n  // TArgs or TKeyArgs and return the corresponding TCacheKey. If no keyArgs\n  // function has been configured, TArgs will be the same as TKeyArgs, and thus\n  // getKey and makeCacheKey will be synonymous.\n  getKey: (...args: TArgs) => TCacheKey | undefined;\n\n  // This property is equivalent to the makeCacheKey function provided in the\n  // OptimisticWrapOptions, or (if no options.makeCacheKey function is provided)\n  // a default implementation of makeCacheKey. This function is also exposed as\n  // optimistic.options.makeCacheKey, somewhat redundantly.\n  makeCacheKey: (...args: TKeyArgs) => TCacheKey | undefined;\n};\n\nexport { CommonCache }\nexport interface CommonCacheConstructor<TCacheKey, TResult, TArgs extends any[]> extends Function {\n  new <K extends TCacheKey, V extends Entry<TArgs, TResult>>(max?: number, dispose?: (value: V, key?: K) => void): CommonCache<K,V>;\n}\n\nexport type OptimisticWrapOptions<\n  TArgs extends any[],\n  TKeyArgs extends any[] = TArgs,\n  TCacheKey = any,\n  TResult = any,\n> = {\n  // The maximum number of cache entries that should be retained before the\n  // cache begins evicting the oldest ones.\n  max?: number;\n  // Transform the raw arguments to some other type of array, which will then\n  // be passed to makeCacheKey.\n  keyArgs?: (...args: TArgs) => TKeyArgs;\n  // The makeCacheKey function takes the same arguments that were passed to\n  // the wrapper function and returns a single value that can be used as a key\n  // in a Map to identify the cached result.\n  makeCacheKey?: (...args: NoInfer<TKeyArgs>) => TCacheKey | undefined;\n  // Called when a new value is computed to allow efficient normalization of\n  // results over time, for example by returning older if equal(newer, older).\n  normalizeResult?: (newer: TResult, older: TResult) => TResult;\n  // If provided, the subscribe function should either return an unsubscribe\n  // function or return nothing.\n  subscribe?: (...args: TArgs) => void | (() => any);\n  cache?: CommonCache<NoInfer<TCacheKey>, Entry<NoInfer<TArgs>, NoInfer<TResult>>>\n    | CommonCacheConstructor<NoInfer<TCacheKey>, NoInfer<TResult>, NoInfer<TArgs>>;\n};\n\nexport interface OptionsWithCacheInstance<\n  TArgs extends any[],\n  TKeyArgs extends any[] = TArgs,\n  TCacheKey = any,\n  TResult = any,\n> extends OptimisticWrapOptions<TArgs, TKeyArgs, TCacheKey, TResult> {\n  cache: CommonCache<NoInfer<TCacheKey>, Entry<NoInfer<TArgs>, NoInfer<TResult>>>;\n};\n\nconst caches = new Set<CommonCache<any, AnyEntry>>();\n\nexport function wrap<\n  TArgs extends any[],\n  TResult,\n  TKeyArgs extends any[] = TArgs,\n  TCacheKey = any,\n>(originalFunction: (...args: TArgs) => TResult, {\n  max = Math.pow(2, 16),\n  keyArgs,\n  makeCacheKey = (defaultMakeCacheKey as () => TCacheKey),\n  normalizeResult,\n  subscribe,\n  cache: cacheOption = StrongCache,\n}: OptimisticWrapOptions<TArgs, TKeyArgs, TCacheKey, TResult> = Object.create(null)) {\n  const cache: CommonCache<TCacheKey, Entry<TArgs, TResult>> =\n    typeof cacheOption === \"function\"\n      ? new cacheOption(max, entry => entry.dispose())\n      : cacheOption;\n\n  const optimistic = function (): TResult {\n    const key = makeCacheKey.apply(\n      null,\n      keyArgs ? keyArgs.apply(null, arguments as any) : arguments as any\n    );\n\n    if (key === void 0) {\n      return originalFunction.apply(null, arguments as any);\n    }\n\n    let entry = cache.get(key)!;\n    if (!entry) {\n      cache.set(key, entry = new Entry(originalFunction));\n      entry.normalizeResult = normalizeResult;\n      entry.subscribe = subscribe;\n      // Give the Entry the ability to trigger cache.delete(key), even though\n      // the Entry itself does not know about key or cache.\n      entry.forget = () => cache.delete(key);\n    }\n\n    const value = entry.recompute(\n      Array.prototype.slice.call(arguments) as TArgs,\n    );\n\n    // Move this entry to the front of the least-recently used queue,\n    // since we just finished computing its value.\n    cache.set(key, entry);\n\n    caches.add(cache);\n\n    // Clean up any excess entries in the cache, but only if there is no\n    // active parent entry, meaning we're not in the middle of a larger\n    // computation that might be flummoxed by the cleaning.\n    if (! parentEntrySlot.hasValue()) {\n      caches.forEach(cache => cache.clean());\n      caches.clear();\n    }\n\n    return value;\n  } as OptimisticWrapperFunction<TArgs, TResult, TKeyArgs, TCacheKey>;\n\n  Object.defineProperty(optimistic, \"size\", {\n    get: () => cache.size,\n    configurable: false,\n    enumerable: false,\n  });\n\n  Object.freeze(optimistic.options = {\n    max,\n    keyArgs,\n    makeCacheKey,\n    normalizeResult,\n    subscribe,\n    cache,\n  });\n\n  function dirtyKey(key: TCacheKey | undefined) {\n    const entry = key && cache.get(key);\n    if (entry) {\n      entry.setDirty();\n    }\n  }\n  optimistic.dirtyKey = dirtyKey;\n  optimistic.dirty = function dirty() {\n    dirtyKey(makeCacheKey.apply(null, arguments as any));\n  };\n\n  function peekKey(key: TCacheKey | undefined) {\n    const entry = key && cache.get(key);\n    if (entry) {\n      return entry.peek();\n    }\n  }\n  optimistic.peekKey = peekKey;\n  optimistic.peek = function peek() {\n    return peekKey(makeCacheKey.apply(null, arguments as any));\n  };\n\n  function forgetKey(key: TCacheKey | undefined) {\n    return key ? cache.delete(key) : false;\n  }\n  optimistic.forgetKey = forgetKey;\n  optimistic.forget = function forget() {\n    return forgetKey(makeCacheKey.apply(null, arguments as any));\n  };\n\n  optimistic.makeCacheKey = makeCacheKey;\n  optimistic.getKey = keyArgs ? function getKey() {\n    return makeCacheKey.apply(null, keyArgs.apply(null, arguments as any));\n  } : makeCacheKey as (...args: any[]) => TCacheKey | undefined;\n\n  return Object.freeze(optimistic);\n}\n", "import { invariant } from \"../globals/index.js\";\n\n// Provides the methods that allow QueryManager to handle the `skip` and\n// `include` directives within GraphQL.\nimport type {\n  SelectionNode,\n  VariableNode,\n  BooleanValueNode,\n  DirectiveNode,\n  DocumentNode,\n  ArgumentNode,\n  ValueNode,\n  ASTNode,\n} from \"graphql\";\nimport { visit, BREAK } from \"graphql\";\n\nexport type DirectiveInfo = {\n  [fieldName: string]: { [argName: string]: any };\n};\n\nexport function shouldInclude(\n  { directives }: SelectionNode,\n  variables?: Record<string, any>\n): boolean {\n  if (!directives || !directives.length) {\n    return true;\n  }\n  return getInclusionDirectives(directives).every(\n    ({ directive, ifArgument }) => {\n      let evaledValue: boolean = false;\n      if (ifArgument.value.kind === \"Variable\") {\n        evaledValue =\n          variables && variables[(ifArgument.value as VariableNode).name.value];\n        invariant(\n          evaledValue !== void 0,\n          `Invalid variable referenced in @%s directive.`,\n          directive.name.value\n        );\n      } else {\n        evaledValue = (ifArgument.value as BooleanValueNode).value;\n      }\n      return directive.name.value === \"skip\" ? !evaledValue : evaledValue;\n    }\n  );\n}\n\nexport function getDirectiveNames(root: ASTNode) {\n  const names: string[] = [];\n\n  visit(root, {\n    Directive(node: DirectiveNode) {\n      names.push(node.name.value);\n    },\n  });\n\n  return names;\n}\n\nexport const hasAnyDirectives = (names: string[], root: ASTNode) =>\n  hasDirectives(names, root, false);\n\nexport const hasAllDirectives = (names: string[], root: ASTNode) =>\n  hasDirectives(names, root, true);\n\nexport function hasDirectives(names: string[], root: ASTNode, all?: boolean) {\n  const nameSet = new Set(names);\n  const uniqueCount = nameSet.size;\n\n  visit(root, {\n    Directive(node) {\n      if (nameSet.delete(node.name.value) && (!all || !nameSet.size)) {\n        return BREAK;\n      }\n    },\n  });\n\n  // If we found all the names, nameSet will be empty. If we only care about\n  // finding some of them, the < condition is sufficient.\n  return all ? !nameSet.size : nameSet.size < uniqueCount;\n}\n\nexport function hasClientExports(document: DocumentNode) {\n  return document && hasDirectives([\"client\", \"export\"], document, true);\n}\n\nexport type InclusionDirectives = Array<{\n  directive: DirectiveNode;\n  ifArgument: ArgumentNode;\n}>;\n\nfunction isInclusionDirective({ name: { value } }: DirectiveNode): boolean {\n  return value === \"skip\" || value === \"include\";\n}\n\nexport function getInclusionDirectives(\n  directives: ReadonlyArray<DirectiveNode>\n): InclusionDirectives {\n  const result: InclusionDirectives = [];\n\n  if (directives && directives.length) {\n    directives.forEach((directive) => {\n      if (!isInclusionDirective(directive)) return;\n\n      const directiveArguments = directive.arguments;\n      const directiveName = directive.name.value;\n\n      invariant(\n        directiveArguments && directiveArguments.length === 1,\n        `Incorrect number of arguments for the @%s directive.`,\n        directiveName\n      );\n\n      const ifArgument = directiveArguments![0];\n      invariant(\n        ifArgument.name && ifArgument.name.value === \"if\",\n        `Invalid argument for the @%s directive.`,\n        directiveName\n      );\n\n      const ifValue: ValueNode = ifArgument.value;\n\n      // means it has to be a variable value if this is a valid @skip or @include directive\n      invariant(\n        ifValue &&\n          (ifValue.kind === \"Variable\" || ifValue.kind === \"BooleanValue\"),\n        `Argument for the @%s directive must be a variable or a boolean value.`,\n        directiveName\n      );\n\n      result.push({ directive, ifArgument });\n    });\n  }\n\n  return result;\n}\n", "// A [trie](https://en.wikipedia.org/wiki/Trie) data structure that holds\n// object keys weakly, yet can also hold non-object keys, unlike the\n// native `WeakMap`.\n\n// If no makeData function is supplied, the looked-up data will be an empty,\n// null-prototype Object.\nconst defaultMakeData = () => Object.create(null);\n\n// Useful for processing arguments objects as well as arrays.\nconst { forEach, slice } = Array.prototype;\nconst { hasOwnProperty } = Object.prototype;\n\nexport class Trie<Data> {\n  // Since a `WeakMap` cannot hold primitive values as keys, we need a\n  // backup `Map` instance to hold primitive keys. Both `this._weakMap`\n  // and `this._strongMap` are lazily initialized.\n  private weak?: WeakMap<any, Trie<Data>>;\n  private strong?: Map<any, Trie<Data>>;\n  private data?: Data;\n\n  constructor(\n    private weakness = true,\n    private makeData: (array: any[]) => Data = defaultMakeData,\n  ) {}\n\n  public lookup<T extends any[]>(...array: T): Data;\n  public lookup(): Data {\n    return this.lookupArray(arguments);\n  }\n\n  public lookupArray<T extends IArguments | any[]>(array: T): Data {\n    let node: Trie<Data> = this;\n    forEach.call(array, key => node = node.getChildTrie(key));\n    return hasOwnProperty.call(node, \"data\")\n      ? node.data as Data\n      : node.data = this.makeData(slice.call(array));\n  }\n\n  public peek<T extends any[]>(...array: T): Data | undefined;\n  public peek(): Data | undefined {\n    return this.peekArray(arguments);\n  }\n\n  public peekArray<T extends IArguments | any[]>(array: T): Data | undefined {\n    let node: Trie<Data> | undefined = this;\n\n    for (let i = 0, len = array.length; node && i < len; ++i) {\n      const map = node.mapFor(array[i], false);\n      node = map && map.get(array[i]);\n    }\n\n    return node && node.data;\n  }\n\n  public remove(...array: any[]): Data | undefined;\n  public remove(): Data | undefined {\n    return this.removeArray(arguments);\n  }\n\n  public removeArray<T extends IArguments | any[]>(array: T): Data | undefined {\n    let data: Data | undefined;\n\n    if (array.length) {\n      const head = array[0];\n      const map = this.mapFor(head, false);\n      const child = map && map.get(head);\n      if (child) {\n        data = child.removeArray(slice.call(array, 1));\n        if (!child.data && !child.weak && !(child.strong && child.strong.size)) {\n          map.delete(head);\n        }\n      }\n    } else {\n      data = this.data;\n      delete this.data;\n    }\n\n    return data;\n  }\n\n  private getChildTrie(key: any) {\n    const map = this.mapFor(key, true)!;\n    let child = map.get(key);\n    if (!child) map.set(key, child = new Trie<Data>(this.weakness, this.makeData));\n    return child;\n  }\n\n  private mapFor(key: any, create: boolean): Trie<Data>[\"weak\" | \"strong\"] | undefined {\n    return this.weakness && isObjRef(key)\n      ? this.weak || (create ? this.weak = new WeakMap : void 0)\n      : this.strong || (create ? this.strong = new Map : void 0);\n  }\n}\n\nfunction isObjRef(value: any) {\n  switch (typeof value) {\n  case \"object\":\n    if (value === null) break;\n    // Fall through to return true...\n  case \"function\":\n    return true;\n  }\n  return false;\n}\n", "import { maybe } from \"../globals/index.js\";\n\nconst isReactNative = maybe(() => navigator.product) == \"ReactNative\";\n\nexport const canUseWeakMap =\n  typeof WeakMap === \"function\" &&\n  !(isReactNative && !(global as any).HermesInternal);\n\nexport const canUseWeakSet = typeof WeakSet === \"function\";\n\nexport const canUseSymbol =\n  typeof Symbol === \"function\" && typeof Symbol.for === \"function\";\n\nexport const canUseAsyncIteratorSymbol = canUseSymbol && Symbol.asyncIterator;\n\nexport const canUseDOM =\n  typeof maybe(() => window.document.createElement) === \"function\";\n\nconst usingJSDOM: boolean =\n  // Following advice found in this comment from @domenic (maintainer of jsdom):\n  // https://github.com/jsdom/jsdom/issues/1537#issuecomment-229405327\n  //\n  // Since we control the version of Jest and jsdom used when running Apollo\n  // Client tests, and that version is recent enought to include \" jsdom/x.y.z\"\n  // at the end of the user agent string, I believe this case is all we need to\n  // check. Testing for \"Node.js\" was recommended for backwards compatibility\n  // with older version of jsdom, but we don't have that problem.\n  maybe(() => navigator.userAgent.indexOf(\"jsdom\") >= 0) || false;\n\n// Our tests should all continue to pass if we remove this !usingJSDOM\n// condition, thereby allowing useLayoutEffect when using jsdom. Unfortunately,\n// if we allow useLayoutEffect, then useSyncExternalStore generates many\n// warnings about useLayoutEffect doing nothing on the server. While these\n// warnings are harmless, this !usingJSDOM condition seems to be the best way to\n// prevent them (i.e. skipping useLayoutEffect when using jsdom).\nexport const canUseLayoutEffect = (canUseDOM || isReactNative) && !usingJSDOM;\n", "export function isNonNullObject(obj: any): obj is Record<string | number, any> {\n  return obj !== null && typeof obj === \"object\";\n}\n\nexport function isPlainObject(obj: any): obj is Record<string | number, any> {\n  return (\n    obj !== null &&\n    typeof obj === \"object\" &&\n    (Object.getPrototypeOf(obj) === Object.prototype ||\n      Object.getPrototypeOf(obj) === null)\n  );\n}\n", "import { invariant, newInvariantError } from \"../globals/index.js\";\n\nimport type {\n  DocumentNode,\n  FragmentDefinitionNode,\n  InlineFragmentNode,\n  SelectionNode,\n} from \"graphql\";\n\n// TODO(brian): A hack until this issue is resolved (https://github.com/graphql/graphql-js/issues/3356)\ntype Kind = any;\ntype OperationTypeNode = any;\n/**\n * Returns a query document which adds a single query operation that only\n * spreads the target fragment inside of it.\n *\n * So for example a document of:\n *\n * ```graphql\n * fragment foo on Foo { a b c }\n * ```\n *\n * Turns into:\n *\n * ```graphql\n * { ...foo }\n *\n * fragment foo on Foo { a b c }\n * ```\n *\n * The target fragment will either be the only fragment in the document, or a\n * fragment specified by the provided `fragmentName`. If there is more than one\n * fragment, but a `fragmentName` was not defined then an error will be thrown.\n */\nexport function getFragmentQueryDocument(\n  document: DocumentNode,\n  fragmentName?: string\n): DocumentNode {\n  let actualFragmentName = fragmentName;\n\n  // Build an array of all our fragment definitions that will be used for\n  // validations. We also do some validations on the other definitions in the\n  // document while building this list.\n  const fragments: Array<FragmentDefinitionNode> = [];\n  document.definitions.forEach((definition) => {\n    // Throw an error if we encounter an operation definition because we will\n    // define our own operation definition later on.\n    if (definition.kind === \"OperationDefinition\") {\n      throw newInvariantError(\n        `Found a %s operation%s. ` +\n          \"No operations are allowed when using a fragment as a query. Only fragments are allowed.\",\n        definition.operation,\n        definition.name ? ` named '${definition.name.value}'` : \"\"\n      );\n    }\n    // Add our definition to the fragments array if it is a fragment\n    // definition.\n    if (definition.kind === \"FragmentDefinition\") {\n      fragments.push(definition);\n    }\n  });\n\n  // If the user did not give us a fragment name then let us try to get a\n  // name from a single fragment in the definition.\n  if (typeof actualFragmentName === \"undefined\") {\n    invariant(\n      fragments.length === 1,\n      `Found %s fragments. \\`fragmentName\\` must be provided when there is not exactly 1 fragment.`,\n      fragments.length\n    );\n    actualFragmentName = fragments[0].name.value;\n  }\n\n  // Generate a query document with an operation that simply spreads the\n  // fragment inside of it.\n  const query: DocumentNode = {\n    ...document,\n    definitions: [\n      {\n        kind: \"OperationDefinition\" as Kind,\n        // OperationTypeNode is an enum\n        operation: \"query\" as OperationTypeNode,\n        selectionSet: {\n          kind: \"SelectionSet\" as Kind,\n          selections: [\n            {\n              kind: \"FragmentSpread\" as Kind,\n              name: {\n                kind: \"Name\" as Kind,\n                value: actualFragmentName,\n              },\n            },\n          ],\n        },\n      },\n      ...document.definitions,\n    ],\n  };\n\n  return query;\n}\n\n/**\n * This is an interface that describes a map from fragment names to fragment definitions.\n */\nexport interface FragmentMap {\n  [fragmentName: string]: FragmentDefinitionNode;\n}\n\nexport type FragmentMapFunction = (\n  fragmentName: string\n) => FragmentDefinitionNode | null;\n\n// Utility function that takes a list of fragment definitions and makes a hash out of them\n// that maps the name of the fragment to the fragment definition.\nexport function createFragmentMap(\n  fragments: FragmentDefinitionNode[] = []\n): FragmentMap {\n  const symTable: FragmentMap = {};\n  fragments.forEach((fragment) => {\n    symTable[fragment.name.value] = fragment;\n  });\n  return symTable;\n}\n\nexport function getFragmentFromSelection(\n  selection: SelectionNode,\n  fragmentMap?: FragmentMap | FragmentMapFunction\n): InlineFragmentNode | FragmentDefinitionNode | null {\n  switch (selection.kind) {\n    case \"InlineFragment\":\n      return selection;\n    case \"FragmentSpread\": {\n      const fragmentName = selection.name.value;\n      if (typeof fragmentMap === \"function\") {\n        return fragmentMap(fragmentName);\n      }\n      const fragment = fragmentMap && fragmentMap[fragmentName];\n      invariant(fragment, `No fragment named %s`, fragmentName);\n      return fragment || null;\n    }\n    default:\n      return null;\n  }\n}\n", "import { WeakCache, StrongCache } from \"@wry/caches\";\n\ninterface CleanableCache {\n  size: number;\n  max?: number;\n  clean: () => void;\n}\nconst scheduledCleanup = new WeakSet<CleanableCache>();\nfunction schedule(cache: CleanableCache) {\n  if (cache.size <= (cache.max || -1)) {\n    return;\n  }\n  if (!scheduledCleanup.has(cache)) {\n    scheduledCleanup.add(cache);\n    setTimeout(() => {\n      cache.clean();\n      scheduledCleanup.delete(cache);\n    }, 100);\n  }\n}\n/**\n * @internal\n * A version of WeakCache that will auto-schedule a cleanup of the cache when\n * a new item is added and the cache reached maximum size.\n * Throttled to once per 100ms.\n *\n * @privateRemarks\n * Should be used throughout the rest of the codebase instead of WeakCache,\n * with the notable exception of usage in `wrap` from `optimism` - that one\n * already handles cleanup and should remain a `WeakCache`.\n */\nexport const AutoCleanedWeakCache = function (\n  max?: number | undefined,\n  dispose?: ((value: any, key: any) => void) | undefined\n) {\n  /*\n  Some builds of `WeakCache` are function prototypes, some are classes.\n  This library still builds with an ES5 target, so we can't extend the\n  real classes.\n  Instead, we have to use this workaround until we switch to a newer build\n  target.\n  */\n  const cache = new WeakCache(max, dispose);\n  cache.set = function (key: any, value: any) {\n    const ret = WeakCache.prototype.set.call(this, key, value);\n    schedule(this as any as CleanableCache);\n    return ret;\n  };\n  return cache;\n} as any as typeof WeakCache;\n/**\n * @internal\n */\nexport type AutoCleanedWeakCache<K extends object, V> = WeakCache<K, V>;\n\n/**\n * @internal\n * A version of StrongCache that will auto-schedule a cleanup of the cache when\n * a new item is added and the cache reached maximum size.\n * Throttled to once per 100ms.\n *\n * @privateRemarks\n * Should be used throughout the rest of the codebase instead of StrongCache,\n * with the notable exception of usage in `wrap` from `optimism` - that one\n * already handles cleanup and should remain a `StrongCache`.\n */\nexport const AutoCleanedStrongCache = function (\n  max?: number | undefined,\n  dispose?: ((value: any, key: any) => void) | undefined\n) {\n  /*\n  Some builds of `StrongCache` are function prototypes, some are classes.\n  This library still builds with an ES5 target, so we can't extend the\n  real classes.\n  Instead, we have to use this workaround until we switch to a newer build\n  target.\n  */\n  const cache = new StrongCache(max, dispose);\n  cache.set = function (key: any, value: any) {\n    const ret = StrongCache.prototype.set.call(this, key, value);\n    schedule(this as any as CleanableCache);\n    return ret;\n  };\n  return cache;\n} as any as typeof StrongCache;\n/**\n * @internal\n */\nexport type AutoCleanedStrongCache<K, V> = StrongCache<K, V>;\n", "import { global } from \"../globals/index.js\";\n\ndeclare global {\n  interface Window {\n    [cacheSizeSymbol]?: Partial<CacheSizes>;\n  }\n}\n\n/**\n * The cache sizes used by various Apollo Client caches.\n *\n * @remarks\n * All configurable caches hold memoized values. If an item is\n * cache-collected, it incurs only a small performance impact and\n * doesn't cause data loss. A smaller cache size might save you memory.\n *\n * You should choose cache sizes appropriate for storing a reasonable\n * number of values rather than every value. To prevent too much recalculation,\n * choose cache sizes that are at least large enough to hold memoized values for\n * all hooks/queries on the screen at any given time.\n */\n/*\n * We assume a \"base value\" of 1000 here, which is already very generous.\n * In most applications, it will be very unlikely that 1000 different queries\n * are on screen at the same time.\n */\nexport interface CacheSizes {\n  /**\n   * Cache size for the [`print`](https://github.com/apollographql/apollo-client/blob/main/src/utilities/graphql/print.ts) function.\n   *\n   * It is called with transformed `DocumentNode`s.\n   *\n   * @defaultValue\n   * Defaults to `2000`.\n   *\n   * @remarks\n   * This method is called to transform a GraphQL query AST parsed by `gql`\n   * back into a GraphQL string.\n   *\n   * @privateRemarks\n   * This method is called from the `QueryManager` and various `ApolloLink`s,\n   * always with the \"serverQuery\", so the server-facing part of a transformed\n   * `DocumentNode`.\n   */\n  print: number;\n  /**\n   * Cache size for the [`parser`](https://github.com/apollographql/apollo-client/blob/main/src/react/parser/index.ts) function.\n   *\n   * It is called with user-provided `DocumentNode`s.\n   *\n   * @defaultValue\n   * Defaults to `1000`.\n   *\n   * @remarks\n   * This method is called by HOCs and hooks.\n   *\n   * @privateRemarks\n   * This function is used directly in HOCs, and nowadays mainly accessed by\n   * calling `verifyDocumentType` from various hooks.\n   * It is called with a user-provided DocumentNode.\n   */\n  parser: number;\n  /**\n   * Cache size for the cache of [`DocumentTransform`](https://github.com/apollographql/apollo-client/blob/main/src/utilities/graphql/DocumentTransform.ts)\n   * instances with the `cache` option set to `true`.\n   *\n   * Can be called with user-defined or already-transformed `DocumentNode`s.\n   *\n   * @defaultValue\n   * Defaults to `2000`.\n   *\n   * @remarks\n   * The cache size here should be chosen with other `DocumentTransform`s in mind.\n   * For example, if there was a `DocumentTransform` that would take `x` `DocumentNode`s,\n   * and returned a differently-transformed `DocumentNode` depending if the app is\n   * online or offline, then we assume that the cache returns `2*x` documents.\n   * If that were concatenated with another `DocumentTransform` that would\n   * also duplicate the cache size, you'd need to account for `4*x` documents\n   * returned by the second transform.\n   *\n   * Due to an implementation detail of Apollo Client, if you use custom document\n   * transforms you should always add `n` (the \"base\" number of user-provided\n   * Documents) to the resulting cache size.\n   *\n   * If we assume that the user-provided transforms receive `n` documents and\n   * return `n` documents, the cache size should be `2*n`.\n   *\n   * If we assume that the chain of user-provided transforms receive `n` documents and\n   * return `4*n` documents, the cache size should be `5*n`.\n   *\n   * This size should also then be used in every other cache that mentions that\n   * it operates on a \"transformed\" `DocumentNode`.\n   *\n   * @privateRemarks\n   * Cache size for the `performWork` method of each [`DocumentTransform`](https://github.com/apollographql/apollo-client/blob/main/src/utilities/graphql/DocumentTransform.ts).\n   *\n   * No user-provided DocumentNode will actually be \"the last one\", as we run the\n   * `defaultDocumentTransform` before *and* after the user-provided transforms.\n   * For that reason, we need the extra `n` here - `n` for \"before transformation\"\n   * plus the actual maximum cache size of the user-provided transform chain.\n   *\n   * This method is called from `transformDocument`, which is called from\n   * `QueryManager` with a user-provided DocumentNode.\n   * It is also called with already-transformed DocumentNodes, assuming the\n   * user provided additional transforms.\n   *\n   */\n  \"documentTransform.cache\": number;\n  /**\n   * A cache inside of [`QueryManager`](https://github.com/apollographql/apollo-client/blob/main/src/core/QueryManager.ts).\n   *\n   * It is called with transformed `DocumentNode`s.\n   *\n   * @defaultValue\n   * Defaults to `2000`.\n   *\n   * @privateRemarks\n   * Cache size for the `transformCache` used in the `getDocumentInfo` method of `QueryManager`.\n   * Called throughout the `QueryManager` with transformed DocumentNodes.\n   */\n  \"queryManager.getDocumentInfo\": number;\n  /**\n   * A cache inside of [`PersistedQueryLink`](https://github.com/apollographql/apollo-client/blob/main/src/link/persisted-queries/index.ts).\n   *\n   * It is called with transformed `DocumentNode`s.\n   *\n   * @defaultValue\n   * Defaults to `2000`.\n   *\n   * @remarks\n   * This cache is used to cache the hashes of persisted queries.\n   *\n   * @privateRemarks\n   * Cache size for the `hashesByQuery` cache in the `PersistedQueryLink`.\n   */\n  \"PersistedQueryLink.persistedQueryHashes\": number;\n  /**\n   * Cache used by [`canonicalStringify`](https://github.com/apollographql/apollo-client/blob/main/src/utilities/common/canonicalStringify.ts).\n   *\n   * @defaultValue\n   * Defaults to `1000`.\n   *\n   * @remarks\n   * This cache contains the sorted keys of objects that are stringified by\n   * `canonicalStringify`.\n   * It uses the stringified unsorted keys of objects as keys.\n   * The cache will not grow beyond the size of different object **shapes**\n   * encountered in an application, no matter how much actual data gets stringified.\n   *\n   * @privateRemarks\n   * Cache size for the `sortingMap` in `canonicalStringify`.\n   */\n  canonicalStringify: number;\n  /**\n   * A cache inside of [`FragmentRegistry`](https://github.com/apollographql/apollo-client/blob/main/src/cache/inmemory/fragmentRegistry.ts).\n   *\n   * Can be called with user-defined or already-transformed `DocumentNode`s.\n   *\n   * @defaultValue\n   * Defaults to `2000`.\n   *\n   * @privateRemarks\n   *\n   * Cache size for the `transform` method of FragmentRegistry.\n   * This function is called as part of the `defaultDocumentTransform` which will be called with\n   * user-provided and already-transformed DocumentNodes.\n   *\n   */\n  \"fragmentRegistry.transform\": number;\n  /**\n   * A cache inside of [`FragmentRegistry`](https://github.com/apollographql/apollo-client/blob/main/src/cache/inmemory/fragmentRegistry.ts).\n   *\n   * This function is called with fragment names in the form of a string.\n   *\n   * @defaultValue\n   * Defaults to `1000`.\n   *\n   * @remarks\n   * The size of this case should be chosen with the number of fragments in\n   * your application in mind.\n   *\n   * Note:\n   * This function is a dependency of `fragmentRegistry.transform`, so having too small of a cache size here\n   * might involuntarily invalidate values in the `transform` cache.\n   *\n   * @privateRemarks\n   * Cache size for the `lookup` method of FragmentRegistry.\n   */\n  \"fragmentRegistry.lookup\": number;\n  /**\n   * Cache size for the `findFragmentSpreads` method of [`FragmentRegistry`](https://github.com/apollographql/apollo-client/blob/main/src/cache/inmemory/fragmentRegistry.ts).\n   *\n   * This function is called with transformed `DocumentNode`s, as well as recursively\n   * with every fragment spread referenced within that, or a fragment referenced by a\n   * fragment spread.\n   *\n   * @defaultValue\n   * Defaults to `4000`.\n   *\n   * @remarks\n   *\n   * Note: This function is a dependency of `fragmentRegistry.transform`, so having too small of cache size here\n   * might involuntarily invalidate values in the `transform` cache.\n   */\n  \"fragmentRegistry.findFragmentSpreads\": number;\n  /**\n   * Cache size for the `getFragmentDoc` method of [`ApolloCache`](https://github.com/apollographql/apollo-client/blob/main/src/cache/core/cache.ts).\n   *\n   * This function is called with user-provided fragment definitions.\n   *\n   * @defaultValue\n   * Defaults to `1000`.\n   *\n   * @remarks\n   * This function is called from `readFragment` with user-provided fragment definitions.\n   */\n  \"cache.fragmentQueryDocuments\": number;\n  /**\n   * Cache used in [`removeTypenameFromVariables`](https://github.com/apollographql/apollo-client/blob/main/src/link/remove-typename/removeTypenameFromVariables.ts).\n   *\n   * This function is called transformed `DocumentNode`s.\n   *\n   * @defaultValue\n   * Defaults to `2000`.\n   *\n   * @privateRemarks\n   * Cache size for the `getVariableDefinitions` function of `removeTypenameFromVariables`.\n   */\n  \"removeTypenameFromVariables.getVariableDefinitions\": number;\n  /**\n   * Cache size for the `maybeBroadcastWatch` method on [`InMemoryCache`](https://github.com/apollographql/apollo-client/blob/main/src/cache/inmemory/inMemoryCache.ts).\n   *\n   * Note: `maybeBroadcastWatch` will be set to the `resultCacheMaxSize` option and\n   * will fall back to this configuration value if the option is not set.\n   *\n   * @defaultValue\n   * Defaults to `5000`.\n   *\n   * @remarks\n   * This method is used for dependency tracking in the `InMemoryCache` and\n   * prevents from unnecessary re-renders.\n   * It is recommended to keep this value significantly higher than the number of\n   * possible subscribers you will have active at the same time in your application\n   * at any time.\n   */\n  \"inMemoryCache.maybeBroadcastWatch\": number;\n  /**\n   * Cache size for the `executeSelectionSet` method on [`StoreReader`](https://github.com/apollographql/apollo-client/blob/main/src/cache/inmemory/readFromStore.ts).\n   *\n   * Note:\n   * `executeSelectionSet` will be set to the `resultCacheMaxSize` option and\n   * will fall back to this configuration value if the option is not set.\n   *\n   * @defaultValue\n   * Defaults to `10000`.\n   *\n   * @remarks\n   * Every object that is read from the cache will be cached here, so it is\n   * recommended to set this to a high value.\n   */\n  \"inMemoryCache.executeSelectionSet\": number;\n  /**\n   * Cache size for the `executeSubSelectedArray` method on [`StoreReader`](https://github.com/apollographql/apollo-client/blob/main/src/cache/inmemory/readFromStore.ts).\n   *\n   * Note:\n   * `executeSubSelectedArray` will be set to the `resultCacheMaxSize` option and\n   * will fall back to this configuration value if the option is not set.\n   *\n   * @defaultValue\n   * Defaults to `5000`.\n   *\n   * @remarks\n   * Every array that is read from the cache will be cached here, so it is\n   * recommended to set this to a high value.\n   */\n  \"inMemoryCache.executeSubSelectedArray\": number;\n}\n\nconst cacheSizeSymbol = Symbol.for(\"apollo.cacheSize\");\n/**\n *\n * The global cache size configuration for Apollo Client.\n *\n * @remarks\n *\n * You can directly modify this object, but any modification will\n * only have an effect on caches that are created after the modification.\n *\n * So for global caches, such as `parser`, `canonicalStringify` and `print`,\n * you might need to call `.reset` on them, which will essentially re-create them.\n *\n * Alternatively, you can set `globalThis[Symbol.for(\"apollo.cacheSize\")]` before\n * you load the Apollo Client package:\n *\n * @example\n * ```ts\n * globalThis[Symbol.for(\"apollo.cacheSize\")] = {\n *   parser: 100\n * } satisfies Partial<CacheSizes> // the `satisfies` is optional if using TypeScript\n * ```\n */\nexport const cacheSizes: Partial<CacheSizes> = { ...global[cacheSizeSymbol] };\n\nexport const enum defaultCacheSizes {\n  parser = 1000,\n  canonicalStringify = 1000,\n  print = 2000,\n  \"documentTransform.cache\" = 2000,\n  \"queryManager.getDocumentInfo\" = 2000,\n  \"PersistedQueryLink.persistedQueryHashes\" = 2000,\n  \"fragmentRegistry.transform\" = 2000,\n  \"fragmentRegistry.lookup\" = 1000,\n  \"fragmentRegistry.findFragmentSpreads\" = 4000,\n  \"cache.fragmentQueryDocuments\" = 1000,\n  \"removeTypenameFromVariables.getVariableDefinitions\" = 2000,\n  \"inMemoryCache.maybeBroadcastWatch\" = 5000,\n  \"inMemoryCache.executeSelectionSet\" = 50000,\n  \"inMemoryCache.executeSubSelectedArray\" = 10000,\n}\n", "import type { OptimisticWrapperFunction } from \"optimism\";\nimport type {\n  InMemoryCache,\n  DocumentTransform,\n  ApolloLink,\n  ApolloCache,\n} from \"../../core/index.js\";\nimport type { ApolloClient } from \"../../core/index.js\";\nimport type { CacheSizes } from \"./sizes.js\";\nimport { cacheSizes, defaultCacheSizes } from \"./sizes.js\";\n\nconst globalCaches: {\n  print?: () => number;\n  parser?: () => number;\n  canonicalStringify?: () => number;\n} = {};\n\nexport function registerGlobalCache(\n  name: keyof typeof globalCaches,\n  getSize: () => number\n) {\n  globalCaches[name] = getSize;\n}\n\n/**\n * Transformative helper type to turn a function of the form\n * ```ts\n * (this: any) => R\n * ```\n * into a function of the form\n * ```ts\n * () => R\n * ```\n * preserving the return type, but removing the `this` parameter.\n *\n * @remarks\n *\n * Further down in the definitions of `_getApolloClientMemoryInternals`,\n * `_getApolloCacheMemoryInternals` and `_getInMemoryCacheMemoryInternals`,\n * having the `this` parameter annotation is extremely useful for type checking\n * inside the function.\n *\n * If this is preserved in the exported types, though, it leads to a situation\n * where `ApolloCache.getMemoryInternals` is a function that requires a `this`\n * of the type `ApolloCache`, while the extending class `InMemoryCache` has a\n * `getMemoryInternals` function that requires a `this` of the type\n * `InMemoryCache`.\n * This is not compatible with TypeScript's inheritence system (although it is\n * perfectly correct), and so TypeScript will complain loudly.\n *\n * We still want to define our functions with the `this` annotation, though,\n * and have the return type inferred.\n * (This requirement for return type inference here makes it impossible to use\n * a function overload that is more explicit on the inner overload than it is\n * on the external overload.)\n *\n * So in the end, we use this helper to remove the `this` annotation from the\n * exported function types, while keeping it in the internal implementation.\n *\n */\ntype RemoveThis<T> = T extends (this: any) => infer R ? () => R : never;\n\n/**\n * For internal purposes only - please call `ApolloClient.getMemoryInternals` instead\n * @internal\n */\nexport const getApolloClientMemoryInternals =\n  __DEV__ ?\n    (_getApolloClientMemoryInternals as RemoveThis<\n      typeof _getApolloClientMemoryInternals\n    >)\n  : undefined;\n\n/**\n * For internal purposes only - please call `ApolloClient.getMemoryInternals` instead\n * @internal\n */\nexport const getInMemoryCacheMemoryInternals =\n  __DEV__ ?\n    (_getInMemoryCacheMemoryInternals as RemoveThis<\n      typeof _getInMemoryCacheMemoryInternals\n    >)\n  : undefined;\n\n/**\n * For internal purposes only - please call `ApolloClient.getMemoryInternals` instead\n * @internal\n */\nexport const getApolloCacheMemoryInternals =\n  __DEV__ ?\n    (_getApolloCacheMemoryInternals as RemoveThis<\n      typeof _getApolloCacheMemoryInternals\n    >)\n  : undefined;\n\nfunction getCurrentCacheSizes() {\n  // `defaultCacheSizes` is a `const enum` that will be inlined during build, so we have to reconstruct it's shape here\n  const defaults: Record<keyof CacheSizes, number> = {\n    parser: defaultCacheSizes[\"parser\"],\n    canonicalStringify: defaultCacheSizes[\"canonicalStringify\"],\n    print: defaultCacheSizes[\"print\"],\n    \"documentTransform.cache\": defaultCacheSizes[\"documentTransform.cache\"],\n    \"queryManager.getDocumentInfo\":\n      defaultCacheSizes[\"queryManager.getDocumentInfo\"],\n    \"PersistedQueryLink.persistedQueryHashes\":\n      defaultCacheSizes[\"PersistedQueryLink.persistedQueryHashes\"],\n    \"fragmentRegistry.transform\":\n      defaultCacheSizes[\"fragmentRegistry.transform\"],\n    \"fragmentRegistry.lookup\": defaultCacheSizes[\"fragmentRegistry.lookup\"],\n    \"fragmentRegistry.findFragmentSpreads\":\n      defaultCacheSizes[\"fragmentRegistry.findFragmentSpreads\"],\n    \"cache.fragmentQueryDocuments\":\n      defaultCacheSizes[\"cache.fragmentQueryDocuments\"],\n    \"removeTypenameFromVariables.getVariableDefinitions\":\n      defaultCacheSizes[\"removeTypenameFromVariables.getVariableDefinitions\"],\n    \"inMemoryCache.maybeBroadcastWatch\":\n      defaultCacheSizes[\"inMemoryCache.maybeBroadcastWatch\"],\n    \"inMemoryCache.executeSelectionSet\":\n      defaultCacheSizes[\"inMemoryCache.executeSelectionSet\"],\n    \"inMemoryCache.executeSubSelectedArray\":\n      defaultCacheSizes[\"inMemoryCache.executeSubSelectedArray\"],\n  };\n  return Object.fromEntries(\n    Object.entries(defaults).map(([k, v]) => [\n      k,\n      cacheSizes[k as keyof CacheSizes] || v,\n    ])\n  );\n}\n\nfunction _getApolloClientMemoryInternals(this: ApolloClient<any>) {\n  if (!__DEV__) throw new Error(\"only supported in development mode\");\n\n  return {\n    limits: getCurrentCacheSizes(),\n    sizes: {\n      print: globalCaches.print?.(),\n      parser: globalCaches.parser?.(),\n      canonicalStringify: globalCaches.canonicalStringify?.(),\n      links: linkInfo(this.link),\n      queryManager: {\n        getDocumentInfo: this[\"queryManager\"][\"transformCache\"].size,\n        documentTransforms: transformInfo(\n          this[\"queryManager\"].documentTransform\n        ),\n      },\n      ...(this.cache.getMemoryInternals?.() as Partial<\n        ReturnType<typeof _getApolloCacheMemoryInternals>\n      > &\n        Partial<ReturnType<typeof _getInMemoryCacheMemoryInternals>>),\n    },\n  };\n}\n\nfunction _getApolloCacheMemoryInternals(this: ApolloCache<any>) {\n  return {\n    cache: {\n      fragmentQueryDocuments: getWrapperInformation(this[\"getFragmentDoc\"]),\n    },\n  };\n}\n\nfunction _getInMemoryCacheMemoryInternals(this: InMemoryCache) {\n  const fragments = this.config.fragments as\n    | undefined\n    | {\n        findFragmentSpreads?: Function;\n        transform?: Function;\n        lookup?: Function;\n      };\n\n  return {\n    ..._getApolloCacheMemoryInternals.apply(this as any),\n    addTypenameDocumentTransform: transformInfo(this[\"addTypenameTransform\"]),\n    inMemoryCache: {\n      executeSelectionSet: getWrapperInformation(\n        this[\"storeReader\"][\"executeSelectionSet\"]\n      ),\n      executeSubSelectedArray: getWrapperInformation(\n        this[\"storeReader\"][\"executeSubSelectedArray\"]\n      ),\n      maybeBroadcastWatch: getWrapperInformation(this[\"maybeBroadcastWatch\"]),\n    },\n    fragmentRegistry: {\n      findFragmentSpreads: getWrapperInformation(\n        fragments?.findFragmentSpreads\n      ),\n      lookup: getWrapperInformation(fragments?.lookup),\n      transform: getWrapperInformation(fragments?.transform),\n    },\n  };\n}\n\nfunction isWrapper(f?: Function): f is OptimisticWrapperFunction<any, any> {\n  return !!f && \"dirtyKey\" in f;\n}\n\nfunction getWrapperInformation(f?: Function) {\n  return isWrapper(f) ? f.size : undefined;\n}\n\nfunction isDefined<T>(value: T | undefined | null): value is T {\n  return value != null;\n}\n\nfunction transformInfo(transform?: DocumentTransform) {\n  return recurseTransformInfo(transform).map((cache) => ({ cache }));\n}\n\nfunction recurseTransformInfo(transform?: DocumentTransform): number[] {\n  return transform ?\n      [\n        getWrapperInformation(transform?.[\"performWork\"]),\n        ...recurseTransformInfo(transform?.[\"left\"]),\n        ...recurseTransformInfo(transform?.[\"right\"]),\n      ].filter(isDefined)\n    : [];\n}\n\nfunction linkInfo(link?: ApolloLink): unknown[] {\n  return link ?\n      [\n        link?.getMemoryInternals?.(),\n        ...linkInfo(link?.left),\n        ...linkInfo(link?.right),\n      ].filter(isDefined)\n    : [];\n}\n", "import {\n  AutoCleanedStrongCache,\n  cacheSizes,\n  defaultCacheSizes,\n} from \"../../utilities/caching/index.js\";\nimport { registerGlobalCache } from \"../caching/getMemoryInternals.js\";\n\n/**\n * Like JSON.stringify, but with object keys always sorted in the same order.\n *\n * To achieve performant sorting, this function uses a Map from JSON-serialized\n * arrays of keys (in any order) to sorted arrays of the same keys, with a\n * single sorted array reference shared by all permutations of the keys.\n *\n * As a drawback, this function will add a little bit more memory for every\n * object encountered that has different (more, less, a different order of) keys\n * than in the past.\n *\n * In a typical application, this extra memory usage should not play a\n * significant role, as `canonicalStringify` will be called for only a limited\n * number of object shapes, and the cache will not grow beyond a certain point.\n * But in some edge cases, this could be a problem, so we provide\n * canonicalStringify.reset() as a way of clearing the cache.\n * */\nexport const canonicalStringify = Object.assign(\n  function canonicalStringify(value: any): string {\n    return JSON.stringify(value, stableObjectReplacer);\n  },\n  {\n    reset() {\n      // Clearing the sortingMap will reclaim all cached memory, without\n      // affecting the logical results of canonicalStringify, but potentially\n      // sacrificing performance until the cache is refilled.\n      sortingMap = new AutoCleanedStrongCache<string, readonly string[]>(\n        cacheSizes.canonicalStringify || defaultCacheSizes.canonicalStringify\n      );\n    },\n  }\n);\n\nif (__DEV__) {\n  registerGlobalCache(\"canonicalStringify\", () => sortingMap.size);\n}\n\n// Values are JSON-serialized arrays of object keys (in any order), and values\n// are sorted arrays of the same keys.\nlet sortingMap!: AutoCleanedStrongCache<string, readonly string[]>;\ncanonicalStringify.reset();\n\n// The JSON.stringify function takes an optional second argument called a\n// replacer function. This function is called for each key-value pair in the\n// object being stringified, and its return value is used instead of the\n// original value. If the replacer function returns a new value, that value is\n// stringified as JSON instead of the original value of the property.\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify#the_replacer_parameter\nfunction stableObjectReplacer(key: string, value: any) {\n  if (value && typeof value === \"object\") {\n    const proto = Object.getPrototypeOf(value);\n    // We don't want to mess with objects that are not \"plain\" objects, which\n    // means their prototype is either Object.prototype or null. This check also\n    // prevents needlessly rearranging the indices of arrays.\n    if (proto === Object.prototype || proto === null) {\n      const keys = Object.keys(value);\n      // If keys is already sorted, let JSON.stringify serialize the original\n      // value instead of creating a new object with keys in the same order.\n      if (keys.every(everyKeyInOrder)) return value;\n      const unsortedKey = JSON.stringify(keys);\n      let sortedKeys = sortingMap.get(unsortedKey);\n      if (!sortedKeys) {\n        keys.sort();\n        const sortedKey = JSON.stringify(keys);\n        // Checking for sortedKey in the sortingMap allows us to share the same\n        // sorted array reference for all permutations of the same set of keys.\n        sortedKeys = sortingMap.get(sortedKey) || keys;\n        sortingMap.set(unsortedKey, sortedKeys);\n        sortingMap.set(sortedKey, sortedKeys);\n      }\n      const sortedObject = Object.create(proto);\n      // Reassigning the keys in sorted order will cause JSON.stringify to\n      // serialize them in sorted order.\n      sortedKeys.forEach((key) => {\n        sortedObject[key] = value[key];\n      });\n      return sortedObject;\n    }\n  }\n  return value;\n}\n\n// Since everything that happens in stableObjectReplacer benefits from being as\n// efficient as possible, we use a static function as the callback for\n// keys.every in order to test if the provided keys are already sorted without\n// allocating extra memory for a callback.\nfunction everyKeyInOrder(\n  key: string,\n  i: number,\n  keys: readonly string[]\n): boolean {\n  return i === 0 || keys[i - 1] <= key;\n}\n", "import { newInvariantError } from \"../globals/index.js\";\n\nimport type {\n  DirectiveNode,\n  FieldNode,\n  IntValueNode,\n  FloatValueNode,\n  StringValueNode,\n  BooleanValueNode,\n  ObjectValueNode,\n  ListValueNode,\n  EnumValueNode,\n  NullValueNode,\n  VariableNode,\n  InlineFragmentNode,\n  ValueNode,\n  SelectionNode,\n  NameNode,\n  SelectionSetNode,\n  DocumentNode,\n  FragmentSpreadNode,\n} from \"graphql\";\n\nimport { isNonNullObject } from \"../common/objects.js\";\nimport type { FragmentMap } from \"./fragments.js\";\nimport { getFragmentFromSelection } from \"./fragments.js\";\nimport { canonicalStringify } from \"../common/canonicalStringify.js\";\n\nexport interface Reference {\n  readonly __ref: string;\n}\n\nexport function makeReference(id: string): Reference {\n  return { __ref: String(id) };\n}\n\nexport function isReference(obj: any): obj is Reference {\n  return Boolean(\n    obj && typeof obj === \"object\" && typeof obj.__ref === \"string\"\n  );\n}\n\nexport type StoreValue =\n  | number\n  | string\n  | string[]\n  | Reference\n  | Reference[]\n  | null\n  | undefined\n  | void\n  | Object;\n\nexport interface StoreObject {\n  __typename?: string;\n  [storeFieldName: string]: StoreValue;\n}\n\n/**\n * Workaround for a TypeScript quirk:\n * types per default have an implicit index signature that makes them\n * assignable to `StoreObject`.\n * interfaces do not have that implicit index signature, so they cannot\n * be assigned to `StoreObject`.\n * This type just maps over a type or interface that is passed in,\n * implicitly adding the index signature.\n * That way, the result can be assigned to `StoreObject`.\n *\n * This is important if some user-defined interface is used e.g.\n * in cache.modify, where the `toReference` method expects a\n * `StoreObject` as input.\n */\nexport type AsStoreObject<T extends { __typename?: string }> = {\n  [K in keyof T]: T[K];\n};\n\nexport function isDocumentNode(value: any): value is DocumentNode {\n  return (\n    isNonNullObject(value) &&\n    (value as DocumentNode).kind === \"Document\" &&\n    Array.isArray((value as DocumentNode).definitions)\n  );\n}\n\nfunction isStringValue(value: ValueNode): value is StringValueNode {\n  return value.kind === \"StringValue\";\n}\n\nfunction isBooleanValue(value: ValueNode): value is BooleanValueNode {\n  return value.kind === \"BooleanValue\";\n}\n\nfunction isIntValue(value: ValueNode): value is IntValueNode {\n  return value.kind === \"IntValue\";\n}\n\nfunction isFloatValue(value: ValueNode): value is FloatValueNode {\n  return value.kind === \"FloatValue\";\n}\n\nfunction isVariable(value: ValueNode): value is VariableNode {\n  return value.kind === \"Variable\";\n}\n\nfunction isObjectValue(value: ValueNode): value is ObjectValueNode {\n  return value.kind === \"ObjectValue\";\n}\n\nfunction isListValue(value: ValueNode): value is ListValueNode {\n  return value.kind === \"ListValue\";\n}\n\nfunction isEnumValue(value: ValueNode): value is EnumValueNode {\n  return value.kind === \"EnumValue\";\n}\n\nfunction isNullValue(value: ValueNode): value is NullValueNode {\n  return value.kind === \"NullValue\";\n}\n\nexport function valueToObjectRepresentation(\n  argObj: any,\n  name: NameNode,\n  value: ValueNode,\n  variables?: Object\n) {\n  if (isIntValue(value) || isFloatValue(value)) {\n    argObj[name.value] = Number(value.value);\n  } else if (isBooleanValue(value) || isStringValue(value)) {\n    argObj[name.value] = value.value;\n  } else if (isObjectValue(value)) {\n    const nestedArgObj = {};\n    value.fields.map((obj) =>\n      valueToObjectRepresentation(nestedArgObj, obj.name, obj.value, variables)\n    );\n    argObj[name.value] = nestedArgObj;\n  } else if (isVariable(value)) {\n    const variableValue = (variables || ({} as any))[value.name.value];\n    argObj[name.value] = variableValue;\n  } else if (isListValue(value)) {\n    argObj[name.value] = value.values.map((listValue) => {\n      const nestedArgArrayObj = {};\n      valueToObjectRepresentation(\n        nestedArgArrayObj,\n        name,\n        listValue,\n        variables\n      );\n      return (nestedArgArrayObj as any)[name.value];\n    });\n  } else if (isEnumValue(value)) {\n    argObj[name.value] = (value as EnumValueNode).value;\n  } else if (isNullValue(value)) {\n    argObj[name.value] = null;\n  } else {\n    throw newInvariantError(\n      `The inline argument \"%s\" of kind \"%s\"` +\n        \"is not supported. Use variables instead of inline arguments to \" +\n        \"overcome this limitation.\",\n      name.value,\n      (value as any).kind\n    );\n  }\n}\n\nexport function storeKeyNameFromField(\n  field: FieldNode,\n  variables?: Object\n): string {\n  let directivesObj: any = null;\n  if (field.directives) {\n    directivesObj = {};\n    field.directives.forEach((directive) => {\n      directivesObj[directive.name.value] = {};\n\n      if (directive.arguments) {\n        directive.arguments.forEach(({ name, value }) =>\n          valueToObjectRepresentation(\n            directivesObj[directive.name.value],\n            name,\n            value,\n            variables\n          )\n        );\n      }\n    });\n  }\n\n  let argObj: any = null;\n  if (field.arguments && field.arguments.length) {\n    argObj = {};\n    field.arguments.forEach(({ name, value }) =>\n      valueToObjectRepresentation(argObj, name, value, variables)\n    );\n  }\n\n  return getStoreKeyName(field.name.value, argObj, directivesObj);\n}\n\nexport type Directives = {\n  [directiveName: string]: {\n    [argName: string]: any;\n  };\n};\n\nconst KNOWN_DIRECTIVES: string[] = [\n  \"connection\",\n  \"include\",\n  \"skip\",\n  \"client\",\n  \"rest\",\n  \"export\",\n  \"nonreactive\",\n];\n\n// Default stable JSON.stringify implementation used by getStoreKeyName. Can be\n// updated/replaced with something better by calling\n// getStoreKeyName.setStringify(newStringifyFunction).\nlet storeKeyNameStringify: (value: any) => string = canonicalStringify;\n\nexport const getStoreKeyName = Object.assign(\n  function (\n    fieldName: string,\n    args?: Record<string, any> | null,\n    directives?: Directives\n  ): string {\n    if (\n      args &&\n      directives &&\n      directives[\"connection\"] &&\n      directives[\"connection\"][\"key\"]\n    ) {\n      if (\n        directives[\"connection\"][\"filter\"] &&\n        (directives[\"connection\"][\"filter\"] as string[]).length > 0\n      ) {\n        const filterKeys =\n          directives[\"connection\"][\"filter\"] ?\n            (directives[\"connection\"][\"filter\"] as string[])\n          : [];\n        filterKeys.sort();\n\n        const filteredArgs = {} as { [key: string]: any };\n        filterKeys.forEach((key) => {\n          filteredArgs[key] = args[key];\n        });\n\n        return `${directives[\"connection\"][\"key\"]}(${storeKeyNameStringify(\n          filteredArgs\n        )})`;\n      } else {\n        return directives[\"connection\"][\"key\"];\n      }\n    }\n\n    let completeFieldName: string = fieldName;\n\n    if (args) {\n      // We can't use `JSON.stringify` here since it's non-deterministic,\n      // and can lead to different store key names being created even though\n      // the `args` object used during creation has the same properties/values.\n      const stringifiedArgs: string = storeKeyNameStringify(args);\n      completeFieldName += `(${stringifiedArgs})`;\n    }\n\n    if (directives) {\n      Object.keys(directives).forEach((key) => {\n        if (KNOWN_DIRECTIVES.indexOf(key) !== -1) return;\n        if (directives[key] && Object.keys(directives[key]).length) {\n          completeFieldName += `@${key}(${storeKeyNameStringify(\n            directives[key]\n          )})`;\n        } else {\n          completeFieldName += `@${key}`;\n        }\n      });\n    }\n\n    return completeFieldName;\n  },\n  {\n    setStringify(s: typeof storeKeyNameStringify) {\n      const previous = storeKeyNameStringify;\n      storeKeyNameStringify = s;\n      return previous;\n    },\n  }\n);\n\nexport function argumentsObjectFromField(\n  field: FieldNode | DirectiveNode,\n  variables?: Record<string, any>\n): Object | null {\n  if (field.arguments && field.arguments.length) {\n    const argObj: Object = {};\n    field.arguments.forEach(({ name, value }) =>\n      valueToObjectRepresentation(argObj, name, value, variables)\n    );\n    return argObj;\n  }\n  return null;\n}\n\nexport function resultKeyNameFromField(field: FieldNode): string {\n  return field.alias ? field.alias.value : field.name.value;\n}\n\nexport function getTypenameFromResult(\n  result: Record<string, any>,\n  selectionSet: SelectionSetNode,\n  fragmentMap?: FragmentMap\n): string | undefined {\n  let fragments: undefined | Array<InlineFragmentNode | FragmentSpreadNode>;\n  for (const selection of selectionSet.selections) {\n    if (isField(selection)) {\n      if (selection.name.value === \"__typename\") {\n        return result[resultKeyNameFromField(selection)];\n      }\n    } else if (fragments) {\n      fragments.push(selection);\n    } else {\n      fragments = [selection];\n    }\n  }\n  if (typeof result.__typename === \"string\") {\n    return result.__typename;\n  }\n  if (fragments) {\n    for (const selection of fragments) {\n      const typename = getTypenameFromResult(\n        result,\n        getFragmentFromSelection(selection, fragmentMap)!.selectionSet,\n        fragmentMap\n      );\n      if (typeof typename === \"string\") {\n        return typename;\n      }\n    }\n  }\n}\n\nexport function isField(selection: SelectionNode): selection is FieldNode {\n  return selection.kind === \"Field\";\n}\n\nexport function isInlineFragment(\n  selection: SelectionNode\n): selection is InlineFragmentNode {\n  return selection.kind === \"InlineFragment\";\n}\n\nexport type VariableValue = (node: VariableNode) => any;\n", "import { invariant, newInvariantError } from \"../globals/index.js\";\n\nimport type {\n  DocumentNode,\n  OperationDefinitionNode,\n  FragmentDefinitionNode,\n  ValueNode,\n} from \"graphql\";\n\nimport { valueToObjectRepresentation } from \"./storeUtils.js\";\n\ntype OperationDefinitionWithName = OperationDefinitionNode & {\n  name: NonNullable<OperationDefinitionNode[\"name\"]>;\n};\n\n// Checks the document for errors and throws an exception if there is an error.\nexport function checkDocument(doc: DocumentNode) {\n  invariant(\n    doc && doc.kind === \"Document\",\n    `Expecting a parsed GraphQL document. Perhaps you need to wrap the query \\\nstring in a \"gql\" tag? http://docs.apollostack.com/apollo-client/core.html#gql`\n  );\n\n  const operations = doc.definitions\n    .filter((d) => d.kind !== \"FragmentDefinition\")\n    .map((definition) => {\n      if (definition.kind !== \"OperationDefinition\") {\n        throw newInvariantError(\n          `Schema type definitions not allowed in queries. Found: \"%s\"`,\n          definition.kind\n        );\n      }\n      return definition;\n    });\n\n  invariant(\n    operations.length <= 1,\n    `Ambiguous GraphQL document: contains %s operations`,\n    operations.length\n  );\n\n  return doc;\n}\n\nexport function getOperationDefinition(\n  doc: DocumentNode\n): OperationDefinitionNode | undefined {\n  checkDocument(doc);\n  return doc.definitions.filter(\n    (definition): definition is OperationDefinitionNode =>\n      definition.kind === \"OperationDefinition\"\n  )[0];\n}\n\nexport function getOperationName(doc: DocumentNode): string | null {\n  return (\n    doc.definitions\n      .filter(\n        (definition): definition is OperationDefinitionWithName =>\n          definition.kind === \"OperationDefinition\" && !!definition.name\n      )\n      .map((x) => x.name.value)[0] || null\n  );\n}\n\n// Returns the FragmentDefinitions from a particular document as an array\nexport function getFragmentDefinitions(\n  doc: DocumentNode\n): FragmentDefinitionNode[] {\n  return doc.definitions.filter(\n    (definition): definition is FragmentDefinitionNode =>\n      definition.kind === \"FragmentDefinition\"\n  );\n}\n\nexport function getQueryDefinition(doc: DocumentNode): OperationDefinitionNode {\n  const queryDef = getOperationDefinition(doc)!;\n\n  invariant(\n    queryDef && queryDef.operation === \"query\",\n    \"Must contain a query definition.\"\n  );\n\n  return queryDef;\n}\n\nexport function getFragmentDefinition(\n  doc: DocumentNode\n): FragmentDefinitionNode {\n  invariant(\n    doc.kind === \"Document\",\n    `Expecting a parsed GraphQL document. Perhaps you need to wrap the query \\\nstring in a \"gql\" tag? http://docs.apollostack.com/apollo-client/core.html#gql`\n  );\n\n  invariant(\n    doc.definitions.length <= 1,\n    \"Fragment must have exactly one definition.\"\n  );\n\n  const fragmentDef = doc.definitions[0] as FragmentDefinitionNode;\n\n  invariant(\n    fragmentDef.kind === \"FragmentDefinition\",\n    \"Must be a fragment definition.\"\n  );\n\n  return fragmentDef as FragmentDefinitionNode;\n}\n\n/**\n * Returns the first operation definition found in this document.\n * If no operation definition is found, the first fragment definition will be returned.\n * If no definitions are found, an error will be thrown.\n */\nexport function getMainDefinition(\n  queryDoc: DocumentNode\n): OperationDefinitionNode | FragmentDefinitionNode {\n  checkDocument(queryDoc);\n\n  let fragmentDefinition;\n\n  for (let definition of queryDoc.definitions) {\n    if (definition.kind === \"OperationDefinition\") {\n      const operation = (definition as OperationDefinitionNode).operation;\n      if (\n        operation === \"query\" ||\n        operation === \"mutation\" ||\n        operation === \"subscription\"\n      ) {\n        return definition as OperationDefinitionNode;\n      }\n    }\n    if (definition.kind === \"FragmentDefinition\" && !fragmentDefinition) {\n      // we do this because we want to allow multiple fragment definitions\n      // to precede an operation definition.\n      fragmentDefinition = definition as FragmentDefinitionNode;\n    }\n  }\n\n  if (fragmentDefinition) {\n    return fragmentDefinition;\n  }\n\n  throw newInvariantError(\n    \"Expected a parsed GraphQL query with a query, mutation, subscription, or a fragment.\"\n  );\n}\n\nexport function getDefaultValues(\n  definition: OperationDefinitionNode | undefined\n): Record<string, any> {\n  const defaultValues = Object.create(null);\n  const defs = definition && definition.variableDefinitions;\n  if (defs && defs.length) {\n    defs.forEach((def) => {\n      if (def.defaultValue) {\n        valueToObjectRepresentation(\n          defaultValues,\n          def.variable.name,\n          def.defaultValue as ValueNode\n        );\n      }\n    });\n  }\n  return defaultValues;\n}\n", "import { Trie } from \"@wry/trie\";\nimport { canUseWeakMap, canUseWeakSet } from \"../common/canUse.js\";\nimport { checkDocument } from \"./getFromAST.js\";\nimport { invariant } from \"../globals/index.js\";\nimport type { DocumentNode } from \"graphql\";\nimport { WeakCache } from \"@wry/caches\";\nimport { wrap } from \"optimism\";\nimport { cacheSizes } from \"../caching/index.js\";\n\nexport type DocumentTransformCacheKey = ReadonlyArray<unknown>;\n\ntype TransformFn = (document: DocumentNode) => DocumentNode;\n\ninterface DocumentTransformOptions {\n  /**\n   * Determines whether to cache the transformed GraphQL document. Caching can speed up repeated calls to the document transform for the same input document. Set to `false` to completely disable caching for the document transform. When disabled, this option takes precedence over the [`getCacheKey`](#getcachekey) option.\n   *\n   * The default value is `true`.\n   */\n  cache?: boolean;\n  /**\n   * Defines a custom cache key for a GraphQL document that will determine whether to re-run the document transform when given the same input GraphQL document. Returns an array that defines the cache key. Return `undefined` to disable caching for that GraphQL document.\n   *\n   * > **Note:** The items in the array may be any type, but also need to be referentially stable to guarantee a stable cache key.\n   *\n   * The default implementation of this function returns the `document` as the cache key.\n   */\n  getCacheKey?: (\n    document: DocumentNode\n  ) => DocumentTransformCacheKey | undefined;\n}\n\nfunction identity(document: DocumentNode) {\n  return document;\n}\n\nexport class DocumentTransform {\n  private readonly transform: TransformFn;\n  private cached: boolean;\n\n  private readonly resultCache =\n    canUseWeakSet ? new WeakSet<DocumentNode>() : new Set<DocumentNode>();\n\n  // This default implementation of getCacheKey can be overridden by providing\n  // options.getCacheKey to the DocumentTransform constructor. In general, a\n  // getCacheKey function may either return an array of keys (often including\n  // the document) to be used as a cache key, or undefined to indicate the\n  // transform for this document should not be cached.\n  private getCacheKey(\n    document: DocumentNode\n  ): DocumentTransformCacheKey | undefined {\n    return [document];\n  }\n\n  static identity() {\n    // No need to cache this transform since it just returns the document\n    // unchanged. This should save a bit of memory that would otherwise be\n    // needed to populate the `documentCache` of this transform.\n    return new DocumentTransform(identity, { cache: false });\n  }\n\n  static split(\n    predicate: (document: DocumentNode) => boolean,\n    left: DocumentTransform,\n    right: DocumentTransform = DocumentTransform.identity()\n  ) {\n    return Object.assign(\n      new DocumentTransform(\n        (document) => {\n          const documentTransform = predicate(document) ? left : right;\n\n          return documentTransform.transformDocument(document);\n        },\n        // Reasonably assume both `left` and `right` transforms handle their own caching\n        { cache: false }\n      ),\n      { left, right }\n    );\n  }\n\n  constructor(\n    transform: TransformFn,\n    options: DocumentTransformOptions = Object.create(null)\n  ) {\n    this.transform = transform;\n\n    if (options.getCacheKey) {\n      // Override default `getCacheKey` function, which returns [document].\n      this.getCacheKey = options.getCacheKey;\n    }\n    this.cached = options.cache !== false;\n\n    this.resetCache();\n  }\n\n  /**\n   * Resets the internal cache of this transform, if it has one.\n   */\n  resetCache() {\n    if (this.cached) {\n      const stableCacheKeys = new Trie<WeakKey>(canUseWeakMap);\n      this.performWork = wrap(\n        DocumentTransform.prototype.performWork.bind(this),\n        {\n          makeCacheKey: (document) => {\n            const cacheKeys = this.getCacheKey(document);\n            if (cacheKeys) {\n              invariant(\n                Array.isArray(cacheKeys),\n                \"`getCacheKey` must return an array or undefined\"\n              );\n              return stableCacheKeys.lookupArray(cacheKeys);\n            }\n          },\n          max: cacheSizes[\"documentTransform.cache\"],\n          cache: WeakCache<any, any>,\n        }\n      );\n    }\n  }\n\n  private performWork(document: DocumentNode) {\n    checkDocument(document);\n    return this.transform(document);\n  }\n\n  transformDocument(document: DocumentNode) {\n    // If a user passes an already transformed result back to this function,\n    // immediately return it.\n    if (this.resultCache.has(document)) {\n      return document;\n    }\n\n    const transformedDocument = this.performWork(document);\n\n    this.resultCache.add(transformedDocument);\n\n    return transformedDocument;\n  }\n\n  concat(otherTransform: DocumentTransform): DocumentTransform {\n    return Object.assign(\n      new DocumentTransform(\n        (document) => {\n          return otherTransform.transformDocument(\n            this.transformDocument(document)\n          );\n        },\n        // Reasonably assume both transforms handle their own caching\n        { cache: false }\n      ),\n      {\n        left: this,\n        right: otherTransform,\n      }\n    );\n  }\n\n  /**\n   * @internal\n   * Used to iterate through all transforms that are concatenations or `split` links.\n   */\n  readonly left?: DocumentTransform;\n  /**\n   * @internal\n   * Used to iterate through all transforms that are concatenations or `split` links.\n   */\n  readonly right?: DocumentTransform;\n}\n", "import type { ASTNode } from \"graphql\";\nimport { print as origPrint } from \"graphql\";\nimport {\n  AutoCleanedWeakCache,\n  cacheSizes,\n  defaultCacheSizes,\n} from \"../caching/index.js\";\nimport { registerGlobalCache } from \"../caching/getMemoryInternals.js\";\n\nlet printCache!: AutoCleanedWeakCache<ASTNode, string>;\nexport const print = Object.assign(\n  (ast: ASTNode) => {\n    let result = printCache.get(ast);\n\n    if (!result) {\n      result = origPrint(ast);\n      printCache.set(ast, result);\n    }\n    return result;\n  },\n  {\n    reset() {\n      printCache = new AutoCleanedWeakCache<ASTNode, string>(\n        cacheSizes.print || defaultCacheSizes.print\n      );\n    },\n  }\n);\nprint.reset();\n\nif (__DEV__) {\n  registerGlobalCache(\"print\", () => (printCache ? printCache.size : 0));\n}\n", "// A version of Array.isArray that works better with readonly arrays.\nexport const isArray: (a: any) => a is any[] | readonly any[] = Array.isArray;\n\nexport function isNonEmptyArray<T>(value?: ArrayLike<T>): value is Array<T> {\n  return Array.isArray(value) && value.length > 0;\n}\n", "import { invariant } from \"../globals/index.js\";\n\nimport type {\n  DocumentNode,\n  SelectionNode,\n  SelectionSetNode,\n  OperationDefinitionNode,\n  FieldNode,\n  DirectiveNode,\n  FragmentDefinitionNode,\n  ArgumentNode,\n  FragmentSpreadNode,\n  VariableDefinitionNode,\n  ASTNode,\n  ASTVisitFn,\n  InlineFragmentNode,\n} from \"graphql\";\nimport { visit, Kind } from \"graphql\";\n\nimport {\n  checkDocument,\n  getOperationDefinition,\n  getFragmentDefinition,\n  getFragmentDefinitions,\n  getMainDefinition,\n} from \"./getFromAST.js\";\nimport { isField } from \"./storeUtils.js\";\nimport type { FragmentMap } from \"./fragments.js\";\nimport { createFragmentMap } from \"./fragments.js\";\nimport { isArray, isNonEmptyArray } from \"../common/arrays.js\";\n\n// https://github.com/graphql/graphql-js/blob/8d7c8fccf5a9846a50785de04abda58a7eb13fc0/src/language/visitor.ts#L20-L23\ninterface EnterLeaveVisitor<TVisitedNode extends ASTNode> {\n  readonly enter?: ASTVisitFn<TVisitedNode>;\n  readonly leave?: ASTVisitFn<TVisitedNode>;\n}\n\nexport type RemoveNodeConfig<N> = {\n  name?: string;\n  test?: (node: N) => boolean;\n  remove?: boolean;\n};\n\nexport type GetNodeConfig<N> = {\n  name?: string;\n  test?: (node: N) => boolean;\n};\n\nexport type RemoveDirectiveConfig = RemoveNodeConfig<DirectiveNode>;\nexport type GetDirectiveConfig = GetNodeConfig<DirectiveNode>;\nexport type RemoveArgumentsConfig = RemoveNodeConfig<ArgumentNode>;\nexport type GetFragmentSpreadConfig = GetNodeConfig<FragmentSpreadNode>;\nexport type RemoveFragmentSpreadConfig = RemoveNodeConfig<FragmentSpreadNode>;\nexport type RemoveFragmentDefinitionConfig =\n  RemoveNodeConfig<FragmentDefinitionNode>;\nexport type RemoveVariableDefinitionConfig =\n  RemoveNodeConfig<VariableDefinitionNode>;\n\nconst TYPENAME_FIELD: FieldNode = {\n  kind: Kind.FIELD,\n  name: {\n    kind: Kind.NAME,\n    value: \"__typename\",\n  },\n};\n\nfunction isEmpty(\n  op: OperationDefinitionNode | FragmentDefinitionNode,\n  fragmentMap: FragmentMap\n): boolean {\n  return (\n    !op ||\n    op.selectionSet.selections.every(\n      (selection) =>\n        selection.kind === Kind.FRAGMENT_SPREAD &&\n        isEmpty(fragmentMap[selection.name.value], fragmentMap)\n    )\n  );\n}\n\nfunction nullIfDocIsEmpty(doc: DocumentNode) {\n  return (\n      isEmpty(\n        getOperationDefinition(doc) || getFragmentDefinition(doc),\n        createFragmentMap(getFragmentDefinitions(doc))\n      )\n    ) ?\n      null\n    : doc;\n}\n\nfunction getDirectiveMatcher(\n  configs: (RemoveDirectiveConfig | GetDirectiveConfig)[]\n) {\n  const names = new Map<string, RemoveDirectiveConfig | GetDirectiveConfig>();\n\n  const tests = new Map<\n    (directive: DirectiveNode) => boolean,\n    RemoveDirectiveConfig | GetDirectiveConfig\n  >();\n\n  configs.forEach((directive) => {\n    if (directive) {\n      if (directive.name) {\n        names.set(directive.name, directive);\n      } else if (directive.test) {\n        tests.set(directive.test, directive);\n      }\n    }\n  });\n\n  return (directive: DirectiveNode) => {\n    let config = names.get(directive.name.value);\n    if (!config && tests.size) {\n      tests.forEach((testConfig, test) => {\n        if (test(directive)) {\n          config = testConfig;\n        }\n      });\n    }\n    return config;\n  };\n}\n\n// Helper interface and function used by removeDirectivesFromDocument to keep\n// track of variable references and fragments spreads found within a given\n// operation or fragment definition.\ninterface InternalInUseInfo {\n  variables: Set<string>;\n  fragmentSpreads: Set<string>;\n  // Set to true when we deliberately remove a fragment definition, so we can\n  // make sure also to remove dangling ...spreads that refer to it.\n  removed?: boolean;\n  // Populated by the populateTransitiveVars helper function below.\n  transitiveVars?: Set<string>;\n}\nfunction makeInUseGetterFunction<TKey>(defaultKey: TKey) {\n  const map = new Map<TKey, InternalInUseInfo>();\n\n  return function inUseGetterFunction(\n    key: TKey = defaultKey\n  ): InternalInUseInfo {\n    let inUse = map.get(key);\n    if (!inUse) {\n      map.set(\n        key,\n        (inUse = {\n          // Variable and fragment spread names used directly within this\n          // operation or fragment definition, as identified by key. These sets\n          // will be populated during the first traversal of the document in\n          // removeDirectivesFromDocument below.\n          variables: new Set(),\n          fragmentSpreads: new Set(),\n        })\n      );\n    }\n    return inUse;\n  };\n}\n\nexport function removeDirectivesFromDocument(\n  directives: RemoveDirectiveConfig[],\n  doc: DocumentNode\n): DocumentNode | null {\n  checkDocument(doc);\n\n  // Passing empty strings to makeInUseGetterFunction means we handle anonymous\n  // operations as if their names were \"\". Anonymous fragment definitions are\n  // not supposed to be possible, but the same default naming strategy seems\n  // appropriate for that case as well.\n  const getInUseByOperationName = makeInUseGetterFunction<string>(\"\");\n  const getInUseByFragmentName = makeInUseGetterFunction<string>(\"\");\n  const getInUse = (\n    ancestors: readonly (ASTNode | readonly ASTNode[])[]\n  ): InternalInUseInfo | null => {\n    for (\n      let p = 0, ancestor: ASTNode | readonly ASTNode[];\n      p < ancestors.length && (ancestor = ancestors[p]);\n      ++p\n    ) {\n      if (isArray(ancestor)) continue;\n      if (ancestor.kind === Kind.OPERATION_DEFINITION) {\n        // If an operation is anonymous, we use the empty string as its key.\n        return getInUseByOperationName(ancestor.name && ancestor.name.value);\n      }\n      if (ancestor.kind === Kind.FRAGMENT_DEFINITION) {\n        return getInUseByFragmentName(ancestor.name.value);\n      }\n    }\n    invariant.error(`Could not find operation or fragment`);\n    return null;\n  };\n\n  let operationCount = 0;\n  for (let i = doc.definitions.length - 1; i >= 0; --i) {\n    if (doc.definitions[i].kind === Kind.OPERATION_DEFINITION) {\n      ++operationCount;\n    }\n  }\n\n  const directiveMatcher = getDirectiveMatcher(directives);\n  const shouldRemoveField = (nodeDirectives: FieldNode[\"directives\"]) =>\n    isNonEmptyArray(nodeDirectives) &&\n    nodeDirectives\n      .map(directiveMatcher)\n      .some(\n        (config: RemoveDirectiveConfig | undefined) => config && config.remove\n      );\n\n  const originalFragmentDefsByPath = new Map<string, FragmentDefinitionNode>();\n\n  // Any time the first traversal of the document below makes a change like\n  // removing a fragment (by returning null), this variable should be set to\n  // true. Once it becomes true, it should never be set to false again. If this\n  // variable remains false throughout the traversal, then we can return the\n  // original doc immediately without any modifications.\n  let firstVisitMadeChanges = false;\n\n  const fieldOrInlineFragmentVisitor: EnterLeaveVisitor<\n    FieldNode | InlineFragmentNode\n  > = {\n    enter(node) {\n      if (shouldRemoveField(node.directives)) {\n        firstVisitMadeChanges = true;\n        return null;\n      }\n    },\n  };\n\n  const docWithoutDirectiveSubtrees = visit(doc, {\n    // These two AST node types share the same implementation, defined above.\n    Field: fieldOrInlineFragmentVisitor,\n    InlineFragment: fieldOrInlineFragmentVisitor,\n\n    VariableDefinition: {\n      enter() {\n        // VariableDefinition nodes do not count as variables in use, though\n        // they do contain Variable nodes that might be visited below. To avoid\n        // counting variable declarations as usages, we skip visiting the\n        // contents of this VariableDefinition node by returning false.\n        return false;\n      },\n    },\n\n    Variable: {\n      enter(node, _key, _parent, _path, ancestors) {\n        const inUse = getInUse(ancestors);\n        if (inUse) {\n          inUse.variables.add(node.name.value);\n        }\n      },\n    },\n\n    FragmentSpread: {\n      enter(node, _key, _parent, _path, ancestors) {\n        if (shouldRemoveField(node.directives)) {\n          firstVisitMadeChanges = true;\n          return null;\n        }\n        const inUse = getInUse(ancestors);\n        if (inUse) {\n          inUse.fragmentSpreads.add(node.name.value);\n        }\n        // We might like to remove this FragmentSpread by returning null here if\n        // the corresponding FragmentDefinition node is also going to be removed\n        // by the logic below, but we can't control the relative order of those\n        // events, so we have to postpone the removal of dangling FragmentSpread\n        // nodes until after the current visit of the document has finished.\n      },\n    },\n\n    FragmentDefinition: {\n      enter(node, _key, _parent, path) {\n        originalFragmentDefsByPath.set(JSON.stringify(path), node);\n      },\n      leave(node, _key, _parent, path) {\n        const originalNode = originalFragmentDefsByPath.get(\n          JSON.stringify(path)\n        );\n        if (node === originalNode) {\n          // If the FragmentNode received by this leave function is identical to\n          // the one received by the corresponding enter function (above), then\n          // the visitor must not have made any changes within this\n          // FragmentDefinition node. This fragment definition may still be\n          // removed if there are no ...spread references to it, but it won't be\n          // removed just because it has only a __typename field.\n          return node;\n        }\n\n        if (\n          // This logic applies only if the document contains one or more\n          // operations, since removing all fragments from a document containing\n          // only fragments makes the document useless.\n          operationCount > 0 &&\n          node.selectionSet.selections.every(\n            (selection) =>\n              selection.kind === Kind.FIELD &&\n              selection.name.value === \"__typename\"\n          )\n        ) {\n          // This is a somewhat opinionated choice: if a FragmentDefinition ends\n          // up having no fields other than __typename, we remove the whole\n          // fragment definition, and later prune ...spread references to it.\n          getInUseByFragmentName(node.name.value).removed = true;\n          firstVisitMadeChanges = true;\n          return null;\n        }\n      },\n    },\n\n    Directive: {\n      leave(node) {\n        // If a matching directive is found, remove the directive itself. Note\n        // that this does not remove the target (field, argument, etc) of the\n        // directive, but only the directive itself.\n        if (directiveMatcher(node)) {\n          firstVisitMadeChanges = true;\n          return null;\n        }\n      },\n    },\n  });\n\n  if (!firstVisitMadeChanges) {\n    // If our first pass did not change anything about the document, then there\n    // is no cleanup we need to do, and we can return the original doc.\n    return doc;\n  }\n\n  // Utility for making sure inUse.transitiveVars is recursively populated.\n  // Because this logic assumes inUse.fragmentSpreads has been completely\n  // populated and inUse.removed has been set if appropriate,\n  // populateTransitiveVars must be called after that information has been\n  // collected by the first traversal of the document.\n  const populateTransitiveVars = (inUse: InternalInUseInfo) => {\n    if (!inUse.transitiveVars) {\n      inUse.transitiveVars = new Set(inUse.variables);\n      if (!inUse.removed) {\n        inUse.fragmentSpreads.forEach((childFragmentName) => {\n          populateTransitiveVars(\n            getInUseByFragmentName(childFragmentName)\n          ).transitiveVars!.forEach((varName) => {\n            inUse.transitiveVars!.add(varName);\n          });\n        });\n      }\n    }\n    return inUse;\n  };\n\n  // Since we've been keeping track of fragment spreads used by particular\n  // operations and fragment definitions, we now need to compute the set of all\n  // spreads used (transitively) by any operations in the document.\n  const allFragmentNamesUsed = new Set<string>();\n  docWithoutDirectiveSubtrees.definitions.forEach((def) => {\n    if (def.kind === Kind.OPERATION_DEFINITION) {\n      populateTransitiveVars(\n        getInUseByOperationName(def.name && def.name.value)\n      ).fragmentSpreads.forEach((childFragmentName) => {\n        allFragmentNamesUsed.add(childFragmentName);\n      });\n    } else if (\n      def.kind === Kind.FRAGMENT_DEFINITION &&\n      // If there are no operations in the document, then all fragment\n      // definitions count as usages of their own fragment names. This heuristic\n      // prevents accidentally removing all fragment definitions from the\n      // document just because it contains no operations that use the fragments.\n      operationCount === 0 &&\n      !getInUseByFragmentName(def.name.value).removed\n    ) {\n      allFragmentNamesUsed.add(def.name.value);\n    }\n  });\n  // Now that we have added all fragment spreads used by operations to the\n  // allFragmentNamesUsed set, we can complete the set by transitively adding\n  // all fragment spreads used by those fragments, and so on.\n  allFragmentNamesUsed.forEach((fragmentName) => {\n    // Once all the childFragmentName strings added here have been seen already,\n    // the top-level allFragmentNamesUsed.forEach loop will terminate.\n    populateTransitiveVars(\n      getInUseByFragmentName(fragmentName)\n    ).fragmentSpreads.forEach((childFragmentName) => {\n      allFragmentNamesUsed.add(childFragmentName);\n    });\n  });\n\n  const fragmentWillBeRemoved = (fragmentName: string) =>\n    !!(\n      // A fragment definition will be removed if there are no spreads that refer\n      // to it, or the fragment was explicitly removed because it had no fields\n      // other than __typename.\n      (\n        !allFragmentNamesUsed.has(fragmentName) ||\n        getInUseByFragmentName(fragmentName).removed\n      )\n    );\n\n  const enterVisitor: EnterLeaveVisitor<\n    FragmentSpreadNode | FragmentDefinitionNode\n  > = {\n    enter(node) {\n      if (fragmentWillBeRemoved(node.name.value)) {\n        return null;\n      }\n    },\n  };\n\n  return nullIfDocIsEmpty(\n    visit(docWithoutDirectiveSubtrees, {\n      // If the fragment is going to be removed, then leaving any dangling\n      // FragmentSpread nodes with the same name would be a mistake.\n      FragmentSpread: enterVisitor,\n\n      // This is where the fragment definition is actually removed.\n      FragmentDefinition: enterVisitor,\n\n      OperationDefinition: {\n        leave(node) {\n          // Upon leaving each operation in the depth-first AST traversal, prune\n          // any variables that are declared by the operation but unused within.\n          if (node.variableDefinitions) {\n            const usedVariableNames = populateTransitiveVars(\n              // If an operation is anonymous, we use the empty string as its key.\n              getInUseByOperationName(node.name && node.name.value)\n            ).transitiveVars!;\n\n            // According to the GraphQL spec, all variables declared by an\n            // operation must either be used by that operation or used by some\n            // fragment included transitively into that operation:\n            // https://spec.graphql.org/draft/#sec-All-Variables-Used\n            //\n            // To stay on the right side of this validation rule, if/when we\n            // remove the last $var references from an operation or its fragments,\n            // we must also remove the corresponding $var declaration from the\n            // enclosing operation. This pruning applies only to operations and\n            // not fragment definitions, at the moment. Fragments may be able to\n            // declare variables eventually, but today they can only consume them.\n            if (usedVariableNames.size < node.variableDefinitions.length) {\n              return {\n                ...node,\n                variableDefinitions: node.variableDefinitions.filter((varDef) =>\n                  usedVariableNames.has(varDef.variable.name.value)\n                ),\n              };\n            }\n          }\n        },\n      },\n    })\n  );\n}\n\nexport const addTypenameToDocument = Object.assign(\n  function <TNode extends ASTNode>(doc: TNode): TNode {\n    return visit(doc, {\n      SelectionSet: {\n        enter(node, _key, parent) {\n          // Don't add __typename to OperationDefinitions.\n          if (\n            parent &&\n            (parent as OperationDefinitionNode).kind ===\n              Kind.OPERATION_DEFINITION\n          ) {\n            return;\n          }\n\n          // No changes if no selections.\n          const { selections } = node;\n          if (!selections) {\n            return;\n          }\n\n          // If selections already have a __typename, or are part of an\n          // introspection query, do nothing.\n          const skip = selections.some((selection) => {\n            return (\n              isField(selection) &&\n              (selection.name.value === \"__typename\" ||\n                selection.name.value.lastIndexOf(\"__\", 0) === 0)\n            );\n          });\n          if (skip) {\n            return;\n          }\n\n          // If this SelectionSet is @export-ed as an input variable, it should\n          // not have a __typename field (see issue #4691).\n          const field = parent as FieldNode;\n          if (\n            isField(field) &&\n            field.directives &&\n            field.directives.some((d) => d.name.value === \"export\")\n          ) {\n            return;\n          }\n\n          // Create and return a new SelectionSet with a __typename Field.\n          return {\n            ...node,\n            selections: [...selections, TYPENAME_FIELD],\n          };\n        },\n      },\n    });\n  },\n  {\n    added(field: FieldNode): boolean {\n      return field === TYPENAME_FIELD;\n    },\n  }\n);\n\nconst connectionRemoveConfig = {\n  test: (directive: DirectiveNode) => {\n    const willRemove = directive.name.value === \"connection\";\n    if (willRemove) {\n      if (\n        !directive.arguments ||\n        !directive.arguments.some((arg) => arg.name.value === \"key\")\n      ) {\n        invariant.warn(\n          \"Removing an @connection directive even though it does not have a key. \" +\n            \"You may want to use the key parameter to specify a store key.\"\n        );\n      }\n    }\n\n    return willRemove;\n  },\n};\n\nexport function removeConnectionDirectiveFromDocument(doc: DocumentNode) {\n  return removeDirectivesFromDocument(\n    [connectionRemoveConfig],\n    checkDocument(doc)\n  );\n}\n\nfunction hasDirectivesInSelectionSet(\n  directives: GetDirectiveConfig[],\n  selectionSet: SelectionSetNode | undefined,\n  nestedCheck = true\n): boolean {\n  return (\n    !!selectionSet &&\n    selectionSet.selections &&\n    selectionSet.selections.some((selection) =>\n      hasDirectivesInSelection(directives, selection, nestedCheck)\n    )\n  );\n}\n\nfunction hasDirectivesInSelection(\n  directives: GetDirectiveConfig[],\n  selection: SelectionNode,\n  nestedCheck = true\n): boolean {\n  if (!isField(selection)) {\n    return true;\n  }\n\n  if (!selection.directives) {\n    return false;\n  }\n\n  return (\n    selection.directives.some(getDirectiveMatcher(directives)) ||\n    (nestedCheck &&\n      hasDirectivesInSelectionSet(\n        directives,\n        selection.selectionSet,\n        nestedCheck\n      ))\n  );\n}\n\nfunction getArgumentMatcher(config: RemoveArgumentsConfig[]) {\n  return function argumentMatcher(argument: ArgumentNode) {\n    return config.some(\n      (aConfig: RemoveArgumentsConfig) =>\n        argument.value &&\n        argument.value.kind === Kind.VARIABLE &&\n        argument.value.name &&\n        (aConfig.name === argument.value.name.value ||\n          (aConfig.test && aConfig.test(argument)))\n    );\n  };\n}\n\nexport function removeArgumentsFromDocument(\n  config: RemoveArgumentsConfig[],\n  doc: DocumentNode\n): DocumentNode | null {\n  const argMatcher = getArgumentMatcher(config);\n\n  return nullIfDocIsEmpty(\n    visit(doc, {\n      OperationDefinition: {\n        enter(node) {\n          return {\n            ...node,\n            // Remove matching top level variables definitions.\n            variableDefinitions:\n              node.variableDefinitions ?\n                node.variableDefinitions.filter(\n                  (varDef) =>\n                    !config.some(\n                      (arg) => arg.name === varDef.variable.name.value\n                    )\n                )\n              : [],\n          };\n        },\n      },\n\n      Field: {\n        enter(node) {\n          // If `remove` is set to true for an argument, and an argument match\n          // is found for a field, remove the field as well.\n          const shouldRemoveField = config.some(\n            (argConfig) => argConfig.remove\n          );\n\n          if (shouldRemoveField) {\n            let argMatchCount = 0;\n            if (node.arguments) {\n              node.arguments.forEach((arg) => {\n                if (argMatcher(arg)) {\n                  argMatchCount += 1;\n                }\n              });\n            }\n\n            if (argMatchCount === 1) {\n              return null;\n            }\n          }\n        },\n      },\n\n      Argument: {\n        enter(node) {\n          // Remove all matching arguments.\n          if (argMatcher(node)) {\n            return null;\n          }\n        },\n      },\n    })\n  );\n}\n\nexport function removeFragmentSpreadFromDocument(\n  config: RemoveFragmentSpreadConfig[],\n  doc: DocumentNode\n): DocumentNode | null {\n  function enter(\n    node: FragmentSpreadNode | FragmentDefinitionNode\n  ): null | void {\n    if (config.some((def) => def.name === node.name.value)) {\n      return null;\n    }\n  }\n\n  return nullIfDocIsEmpty(\n    visit(doc, {\n      FragmentSpread: { enter },\n      FragmentDefinition: { enter },\n    })\n  );\n}\n\n// If the incoming document is a query, return it as is. Otherwise, build a\n// new document containing a query operation based on the selection set\n// of the previous main operation.\nexport function buildQueryFromSelectionSet(\n  document: DocumentNode\n): DocumentNode {\n  const definition = getMainDefinition(document);\n  const definitionOperation = (<OperationDefinitionNode>definition).operation;\n\n  if (definitionOperation === \"query\") {\n    // Already a query, so return the existing document.\n    return document;\n  }\n\n  // Build a new query using the selection set of the main operation.\n  const modifiedDoc = visit(document, {\n    OperationDefinition: {\n      enter(node) {\n        return {\n          ...node,\n          operation: \"query\",\n        };\n      },\n    },\n  });\n  return modifiedDoc;\n}\n\n// Remove fields / selection sets that include an @client directive.\nexport function removeClientSetsFromDocument(\n  document: DocumentNode\n): DocumentNode | null {\n  checkDocument(document);\n\n  let modifiedDoc = removeDirectivesFromDocument(\n    [\n      {\n        test: (directive: DirectiveNode) => directive.name.value === \"client\",\n        remove: true,\n      },\n    ],\n    document\n  );\n\n  return modifiedDoc;\n}\n", "import { __rest } from \"tslib\";\n\nimport type { FieldPolicy, Reference } from \"../../cache/index.js\";\nimport { mergeDeep } from \"../common/mergeDeep.js\";\n\ntype KeyArgs = FieldPolicy<any>[\"keyArgs\"];\n\n// A very basic pagination field policy that always concatenates new\n// results onto the existing array, without examining options.args.\nexport function concatPagination<T = Reference>(\n  keyArgs: KeyArgs = false\n): FieldPolicy<T[]> {\n  return {\n    keyArgs,\n    merge(existing, incoming) {\n      return existing ? [...existing, ...incoming] : incoming;\n    },\n  };\n}\n\n// A basic field policy that uses options.args.{offset,limit} to splice\n// the incoming data into the existing array. If your arguments are called\n// something different (like args.{start,count}), feel free to copy/paste\n// this implementation and make the appropriate changes.\nexport function offsetLimitPagination<T = Reference>(\n  keyArgs: KeyArgs = false\n): FieldPolicy<T[]> {\n  return {\n    keyArgs,\n    merge(existing, incoming, { args }) {\n      const merged = existing ? existing.slice(0) : [];\n\n      if (incoming) {\n        if (args) {\n          // Assume an offset of 0 if args.offset omitted.\n          const { offset = 0 } = args;\n          for (let i = 0; i < incoming.length; ++i) {\n            merged[offset + i] = incoming[i];\n          }\n        } else {\n          // It's unusual (probably a mistake) for a paginated field not\n          // to receive any arguments, so you might prefer to throw an\n          // exception here, instead of recovering by appending incoming\n          // onto the existing array.\n          merged.push(...incoming);\n        }\n      }\n\n      return merged;\n    },\n  };\n}\n\n// Whether TRelayEdge<TNode> is a normalized Reference or a non-normalized\n// object, it needs a .cursor property where the relayStylePagination\n// merge function can store cursor strings taken from pageInfo. Storing an\n// extra reference.cursor property should be safe, and is easier than\n// attempting to update the cursor field of the normalized StoreObject\n// that the reference refers to, or managing edge wrapper objects\n// (something I attempted in #7023, but abandoned because of #7088).\nexport type TRelayEdge<TNode> =\n  | {\n      cursor?: string;\n      node: TNode;\n    }\n  | (Reference & { cursor?: string });\n\nexport type TRelayPageInfo = {\n  hasPreviousPage: boolean;\n  hasNextPage: boolean;\n  startCursor: string;\n  endCursor: string;\n};\n\nexport type TExistingRelay<TNode> = Readonly<{\n  edges: TRelayEdge<TNode>[];\n  pageInfo: TRelayPageInfo;\n}>;\n\nexport type TIncomingRelay<TNode> = {\n  edges?: TRelayEdge<TNode>[];\n  pageInfo?: TRelayPageInfo;\n};\n\nexport type RelayFieldPolicy<TNode> = FieldPolicy<\n  TExistingRelay<TNode> | null,\n  TIncomingRelay<TNode> | null,\n  TIncomingRelay<TNode> | null\n>;\n\n// As proof of the flexibility of field policies, this function generates\n// one that handles Relay-style pagination, without Apollo Client knowing\n// anything about connections, edges, cursors, or pageInfo objects.\nexport function relayStylePagination<TNode extends Reference = Reference>(\n  keyArgs: KeyArgs = false\n): RelayFieldPolicy<TNode> {\n  return {\n    keyArgs,\n\n    read(existing, { canRead, readField }) {\n      if (!existing) return existing;\n\n      const edges: TRelayEdge<TNode>[] = [];\n      let firstEdgeCursor = \"\";\n      let lastEdgeCursor = \"\";\n      existing.edges.forEach((edge) => {\n        // Edges themselves could be Reference objects, so it's important\n        // to use readField to access the edge.edge.node property.\n        if (canRead(readField(\"node\", edge))) {\n          edges.push(edge);\n          if (edge.cursor) {\n            firstEdgeCursor = firstEdgeCursor || edge.cursor || \"\";\n            lastEdgeCursor = edge.cursor || lastEdgeCursor;\n          }\n        }\n      });\n\n      if (edges.length > 1 && firstEdgeCursor === lastEdgeCursor) {\n        firstEdgeCursor = \"\";\n      }\n\n      const { startCursor, endCursor } = existing.pageInfo || {};\n\n      return {\n        // Some implementations return additional Connection fields, such\n        // as existing.totalCount. These fields are saved by the merge\n        // function, so the read function should also preserve them.\n        ...getExtras(existing),\n        edges,\n        pageInfo: {\n          ...existing.pageInfo,\n          // If existing.pageInfo.{start,end}Cursor are undefined or \"\", default\n          // to firstEdgeCursor and/or lastEdgeCursor.\n          startCursor: startCursor || firstEdgeCursor,\n          endCursor: endCursor || lastEdgeCursor,\n        },\n      };\n    },\n\n    merge(existing, incoming, { args, isReference, readField }) {\n      if (!existing) {\n        existing = makeEmptyData();\n      }\n\n      if (!incoming) {\n        return existing;\n      }\n\n      const incomingEdges =\n        incoming.edges ?\n          incoming.edges.map((edge) => {\n            if (isReference((edge = { ...edge }))) {\n              // In case edge is a Reference, we read out its cursor field and\n              // store it as an extra property of the Reference object.\n              edge.cursor = readField<string>(\"cursor\", edge);\n            }\n            return edge;\n          })\n        : [];\n\n      if (incoming.pageInfo) {\n        const { pageInfo } = incoming;\n        const { startCursor, endCursor } = pageInfo;\n        const firstEdge = incomingEdges[0];\n        const lastEdge = incomingEdges[incomingEdges.length - 1];\n        // In case we did not request the cursor field for edges in this\n        // query, we can still infer cursors from pageInfo.\n        if (firstEdge && startCursor) {\n          firstEdge.cursor = startCursor;\n        }\n        if (lastEdge && endCursor) {\n          lastEdge.cursor = endCursor;\n        }\n        // Cursors can also come from edges, so we default\n        // pageInfo.{start,end}Cursor to {first,last}Edge.cursor.\n        const firstCursor = firstEdge && firstEdge.cursor;\n        if (firstCursor && !startCursor) {\n          incoming = mergeDeep(incoming, {\n            pageInfo: {\n              startCursor: firstCursor,\n            },\n          });\n        }\n        const lastCursor = lastEdge && lastEdge.cursor;\n        if (lastCursor && !endCursor) {\n          incoming = mergeDeep(incoming, {\n            pageInfo: {\n              endCursor: lastCursor,\n            },\n          });\n        }\n      }\n\n      let prefix = existing.edges;\n      let suffix: typeof prefix = [];\n\n      if (args && args.after) {\n        // This comparison does not need to use readField(\"cursor\", edge),\n        // because we stored the cursor field of any Reference edges as an\n        // extra property of the Reference object.\n        const index = prefix.findIndex((edge) => edge.cursor === args.after);\n        if (index >= 0) {\n          prefix = prefix.slice(0, index + 1);\n          // suffix = []; // already true\n        }\n      } else if (args && args.before) {\n        const index = prefix.findIndex((edge) => edge.cursor === args.before);\n        suffix = index < 0 ? prefix : prefix.slice(index);\n        prefix = [];\n      } else if (incoming.edges) {\n        // If we have neither args.after nor args.before, the incoming\n        // edges cannot be spliced into the existing edges, so they must\n        // replace the existing edges. See #6592 for a motivating example.\n        prefix = [];\n      }\n\n      const edges = [...prefix, ...incomingEdges, ...suffix];\n\n      const pageInfo: TRelayPageInfo = {\n        // The ordering of these two ...spreads may be surprising, but it\n        // makes sense because we want to combine PageInfo properties with a\n        // preference for existing values, *unless* the existing values are\n        // overridden by the logic below, which is permitted only when the\n        // incoming page falls at the beginning or end of the data.\n        ...incoming.pageInfo,\n        ...existing.pageInfo,\n      };\n\n      if (incoming.pageInfo) {\n        const {\n          hasPreviousPage,\n          hasNextPage,\n          startCursor,\n          endCursor,\n          ...extras\n        } = incoming.pageInfo;\n\n        // If incoming.pageInfo had any extra non-standard properties,\n        // assume they should take precedence over any existing properties\n        // of the same name, regardless of where this page falls with\n        // respect to the existing data.\n        Object.assign(pageInfo, extras);\n\n        // Keep existing.pageInfo.has{Previous,Next}Page unless the\n        // placement of the incoming edges means incoming.hasPreviousPage\n        // or incoming.hasNextPage should become the new values for those\n        // properties in existing.pageInfo. Note that these updates are\n        // only permitted when the beginning or end of the incoming page\n        // coincides with the beginning or end of the existing data, as\n        // determined using prefix.length and suffix.length.\n        if (!prefix.length) {\n          if (void 0 !== hasPreviousPage)\n            pageInfo.hasPreviousPage = hasPreviousPage;\n          if (void 0 !== startCursor) pageInfo.startCursor = startCursor;\n        }\n        if (!suffix.length) {\n          if (void 0 !== hasNextPage) pageInfo.hasNextPage = hasNextPage;\n          if (void 0 !== endCursor) pageInfo.endCursor = endCursor;\n        }\n      }\n\n      return {\n        ...getExtras(existing),\n        ...getExtras(incoming),\n        edges,\n        pageInfo,\n      };\n    },\n  };\n}\n\n// Returns any unrecognized properties of the given object.\nconst getExtras = (obj: Record<string, any>) => __rest(obj, notExtras);\nconst notExtras = [\"edges\", \"pageInfo\"];\n\nfunction makeEmptyData(): TExistingRelay<any> {\n  return {\n    edges: [],\n    pageInfo: {\n      hasPreviousPage: false,\n      hasNextPage: true,\n      startCursor: \"\",\n      endCursor: \"\",\n    },\n  };\n}\n", "import { isNonNullObject } from \"./objects.js\";\n\nconst { hasOwnProperty } = Object.prototype;\n\n// These mergeDeep and mergeDeepArray utilities merge any number of objects\n// together, sharing as much memory as possible with the source objects, while\n// remaining careful to avoid modifying any source objects.\n\n// Logically, the return type of mergeDeep should be the intersection of\n// all the argument types. The binary call signature is by far the most\n// common, but we support 0- through 5-ary as well. After that, the\n// resulting type is just the inferred array element type. Note to nerds:\n// there is a more clever way of doing this that converts the tuple type\n// first to a union type (easy enough: T[number]) and then converts the\n// union to an intersection type using distributive conditional type\n// inference, but that approach has several fatal flaws (boolean becomes\n// true & false, and the inferred type ends up as unknown in many cases),\n// in addition to being nearly impossible to explain/understand.\nexport type TupleToIntersection<T extends any[]> =\n  T extends [infer A] ? A\n  : T extends [infer A, infer B] ? A & B\n  : T extends [infer A, infer B, infer C] ? A & B & C\n  : T extends [infer A, infer B, infer C, infer D] ? A & B & C & D\n  : T extends [infer A, infer B, infer C, infer D, infer E] ? A & B & C & D & E\n  : T extends (infer U)[] ? U\n  : any;\n\nexport function mergeDeep<T extends any[]>(\n  ...sources: T\n): TupleToIntersection<T> {\n  return mergeDeepArray(sources);\n}\n\n// In almost any situation where you could succeed in getting the\n// TypeScript compiler to infer a tuple type for the sources array, you\n// could just use mergeDeep instead of mergeDeepArray, so instead of\n// trying to convert T[] to an intersection type we just infer the array\n// element type, which works perfectly when the sources array has a\n// consistent element type.\nexport function mergeDeepArray<T>(sources: T[]): T {\n  let target = sources[0] || ({} as T);\n  const count = sources.length;\n  if (count > 1) {\n    const merger = new DeepMerger();\n    for (let i = 1; i < count; ++i) {\n      target = merger.merge(target, sources[i]);\n    }\n  }\n  return target;\n}\n\nexport type ReconcilerFunction<TContextArgs extends any[]> = (\n  this: DeepMerger<TContextArgs>,\n  target: Record<string | number, any>,\n  source: Record<string | number, any>,\n  property: string | number,\n  ...context: TContextArgs\n) => any;\n\nconst defaultReconciler: ReconcilerFunction<any[]> = function (\n  target,\n  source,\n  property\n) {\n  return this.merge(target[property], source[property]);\n};\n\nexport class DeepMerger<TContextArgs extends any[]> {\n  constructor(\n    private reconciler: ReconcilerFunction<TContextArgs> = defaultReconciler as any as ReconcilerFunction<TContextArgs>\n  ) {}\n\n  public merge(target: any, source: any, ...context: TContextArgs): any {\n    if (isNonNullObject(source) && isNonNullObject(target)) {\n      Object.keys(source).forEach((sourceKey) => {\n        if (hasOwnProperty.call(target, sourceKey)) {\n          const targetValue = target[sourceKey];\n          if (source[sourceKey] !== targetValue) {\n            const result = this.reconciler(\n              target,\n              source,\n              sourceKey,\n              ...context\n            );\n            // A well-implemented reconciler may return targetValue to indicate\n            // the merge changed nothing about the structure of the target.\n            if (result !== targetValue) {\n              target = this.shallowCopyForMerge(target);\n              target[sourceKey] = result;\n            }\n          }\n        } else {\n          // If there is no collision, the target can safely share memory with\n          // the source, and the recursion can terminate here.\n          target = this.shallowCopyForMerge(target);\n          target[sourceKey] = source[sourceKey];\n        }\n      });\n\n      return target;\n    }\n\n    // If source (or target) is not an object, let source replace target.\n    return source;\n  }\n\n  public isObject = isNonNullObject;\n\n  private pastCopies = new Set<any>();\n\n  public shallowCopyForMerge<T>(value: T): T {\n    if (isNonNullObject(value)) {\n      if (!this.pastCopies.has(value)) {\n        if (Array.isArray(value)) {\n          value = (value as any).slice(0);\n        } else {\n          value = {\n            __proto__: Object.getPrototypeOf(value),\n            ...value,\n          };\n        }\n        this.pastCopies.add(value);\n      }\n    }\n    return value;\n  }\n}\n", "function _createForOfIteratorHelperLoose(o, allowArrayLike) { var it = typeof Symbol !== \"undefined\" && o[Symbol.iterator] || o[\"@@iterator\"]; if (it) return (it = it.call(o)).next.bind(it); if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; return function () { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\n// === Symbol Support ===\nvar hasSymbols = function () {\n  return typeof Symbol === 'function';\n};\n\nvar hasSymbol = function (name) {\n  return hasSymbols() && Boolean(Symbol[name]);\n};\n\nvar getSymbol = function (name) {\n  return hasSymbol(name) ? Symbol[name] : '@@' + name;\n};\n\nif (hasSymbols() && !hasSymbol('observable')) {\n  Symbol.observable = Symbol('observable');\n}\n\nvar SymbolIterator = getSymbol('iterator');\nvar SymbolObservable = getSymbol('observable');\nvar SymbolSpecies = getSymbol('species'); // === Abstract Operations ===\n\nfunction getMethod(obj, key) {\n  var value = obj[key];\n  if (value == null) return undefined;\n  if (typeof value !== 'function') throw new TypeError(value + ' is not a function');\n  return value;\n}\n\nfunction getSpecies(obj) {\n  var ctor = obj.constructor;\n\n  if (ctor !== undefined) {\n    ctor = ctor[SymbolSpecies];\n\n    if (ctor === null) {\n      ctor = undefined;\n    }\n  }\n\n  return ctor !== undefined ? ctor : Observable;\n}\n\nfunction isObservable(x) {\n  return x instanceof Observable; // SPEC: Brand check\n}\n\nfunction hostReportError(e) {\n  if (hostReportError.log) {\n    hostReportError.log(e);\n  } else {\n    setTimeout(function () {\n      throw e;\n    });\n  }\n}\n\nfunction enqueue(fn) {\n  Promise.resolve().then(function () {\n    try {\n      fn();\n    } catch (e) {\n      hostReportError(e);\n    }\n  });\n}\n\nfunction cleanupSubscription(subscription) {\n  var cleanup = subscription._cleanup;\n  if (cleanup === undefined) return;\n  subscription._cleanup = undefined;\n\n  if (!cleanup) {\n    return;\n  }\n\n  try {\n    if (typeof cleanup === 'function') {\n      cleanup();\n    } else {\n      var unsubscribe = getMethod(cleanup, 'unsubscribe');\n\n      if (unsubscribe) {\n        unsubscribe.call(cleanup);\n      }\n    }\n  } catch (e) {\n    hostReportError(e);\n  }\n}\n\nfunction closeSubscription(subscription) {\n  subscription._observer = undefined;\n  subscription._queue = undefined;\n  subscription._state = 'closed';\n}\n\nfunction flushSubscription(subscription) {\n  var queue = subscription._queue;\n\n  if (!queue) {\n    return;\n  }\n\n  subscription._queue = undefined;\n  subscription._state = 'ready';\n\n  for (var i = 0; i < queue.length; ++i) {\n    notifySubscription(subscription, queue[i].type, queue[i].value);\n    if (subscription._state === 'closed') break;\n  }\n}\n\nfunction notifySubscription(subscription, type, value) {\n  subscription._state = 'running';\n  var observer = subscription._observer;\n\n  try {\n    var m = getMethod(observer, type);\n\n    switch (type) {\n      case 'next':\n        if (m) m.call(observer, value);\n        break;\n\n      case 'error':\n        closeSubscription(subscription);\n        if (m) m.call(observer, value);else throw value;\n        break;\n\n      case 'complete':\n        closeSubscription(subscription);\n        if (m) m.call(observer);\n        break;\n    }\n  } catch (e) {\n    hostReportError(e);\n  }\n\n  if (subscription._state === 'closed') cleanupSubscription(subscription);else if (subscription._state === 'running') subscription._state = 'ready';\n}\n\nfunction onNotify(subscription, type, value) {\n  if (subscription._state === 'closed') return;\n\n  if (subscription._state === 'buffering') {\n    subscription._queue.push({\n      type: type,\n      value: value\n    });\n\n    return;\n  }\n\n  if (subscription._state !== 'ready') {\n    subscription._state = 'buffering';\n    subscription._queue = [{\n      type: type,\n      value: value\n    }];\n    enqueue(function () {\n      return flushSubscription(subscription);\n    });\n    return;\n  }\n\n  notifySubscription(subscription, type, value);\n}\n\nvar Subscription = /*#__PURE__*/function () {\n  function Subscription(observer, subscriber) {\n    // ASSERT: observer is an object\n    // ASSERT: subscriber is callable\n    this._cleanup = undefined;\n    this._observer = observer;\n    this._queue = undefined;\n    this._state = 'initializing';\n    var subscriptionObserver = new SubscriptionObserver(this);\n\n    try {\n      this._cleanup = subscriber.call(undefined, subscriptionObserver);\n    } catch (e) {\n      subscriptionObserver.error(e);\n    }\n\n    if (this._state === 'initializing') this._state = 'ready';\n  }\n\n  var _proto = Subscription.prototype;\n\n  _proto.unsubscribe = function unsubscribe() {\n    if (this._state !== 'closed') {\n      closeSubscription(this);\n      cleanupSubscription(this);\n    }\n  };\n\n  _createClass(Subscription, [{\n    key: \"closed\",\n    get: function () {\n      return this._state === 'closed';\n    }\n  }]);\n\n  return Subscription;\n}();\n\nvar SubscriptionObserver = /*#__PURE__*/function () {\n  function SubscriptionObserver(subscription) {\n    this._subscription = subscription;\n  }\n\n  var _proto2 = SubscriptionObserver.prototype;\n\n  _proto2.next = function next(value) {\n    onNotify(this._subscription, 'next', value);\n  };\n\n  _proto2.error = function error(value) {\n    onNotify(this._subscription, 'error', value);\n  };\n\n  _proto2.complete = function complete() {\n    onNotify(this._subscription, 'complete');\n  };\n\n  _createClass(SubscriptionObserver, [{\n    key: \"closed\",\n    get: function () {\n      return this._subscription._state === 'closed';\n    }\n  }]);\n\n  return SubscriptionObserver;\n}();\n\nvar Observable = /*#__PURE__*/function () {\n  function Observable(subscriber) {\n    if (!(this instanceof Observable)) throw new TypeError('Observable cannot be called as a function');\n    if (typeof subscriber !== 'function') throw new TypeError('Observable initializer must be a function');\n    this._subscriber = subscriber;\n  }\n\n  var _proto3 = Observable.prototype;\n\n  _proto3.subscribe = function subscribe(observer) {\n    if (typeof observer !== 'object' || observer === null) {\n      observer = {\n        next: observer,\n        error: arguments[1],\n        complete: arguments[2]\n      };\n    }\n\n    return new Subscription(observer, this._subscriber);\n  };\n\n  _proto3.forEach = function forEach(fn) {\n    var _this = this;\n\n    return new Promise(function (resolve, reject) {\n      if (typeof fn !== 'function') {\n        reject(new TypeError(fn + ' is not a function'));\n        return;\n      }\n\n      function done() {\n        subscription.unsubscribe();\n        resolve();\n      }\n\n      var subscription = _this.subscribe({\n        next: function (value) {\n          try {\n            fn(value, done);\n          } catch (e) {\n            reject(e);\n            subscription.unsubscribe();\n          }\n        },\n        error: reject,\n        complete: resolve\n      });\n    });\n  };\n\n  _proto3.map = function map(fn) {\n    var _this2 = this;\n\n    if (typeof fn !== 'function') throw new TypeError(fn + ' is not a function');\n    var C = getSpecies(this);\n    return new C(function (observer) {\n      return _this2.subscribe({\n        next: function (value) {\n          try {\n            value = fn(value);\n          } catch (e) {\n            return observer.error(e);\n          }\n\n          observer.next(value);\n        },\n        error: function (e) {\n          observer.error(e);\n        },\n        complete: function () {\n          observer.complete();\n        }\n      });\n    });\n  };\n\n  _proto3.filter = function filter(fn) {\n    var _this3 = this;\n\n    if (typeof fn !== 'function') throw new TypeError(fn + ' is not a function');\n    var C = getSpecies(this);\n    return new C(function (observer) {\n      return _this3.subscribe({\n        next: function (value) {\n          try {\n            if (!fn(value)) return;\n          } catch (e) {\n            return observer.error(e);\n          }\n\n          observer.next(value);\n        },\n        error: function (e) {\n          observer.error(e);\n        },\n        complete: function () {\n          observer.complete();\n        }\n      });\n    });\n  };\n\n  _proto3.reduce = function reduce(fn) {\n    var _this4 = this;\n\n    if (typeof fn !== 'function') throw new TypeError(fn + ' is not a function');\n    var C = getSpecies(this);\n    var hasSeed = arguments.length > 1;\n    var hasValue = false;\n    var seed = arguments[1];\n    var acc = seed;\n    return new C(function (observer) {\n      return _this4.subscribe({\n        next: function (value) {\n          var first = !hasValue;\n          hasValue = true;\n\n          if (!first || hasSeed) {\n            try {\n              acc = fn(acc, value);\n            } catch (e) {\n              return observer.error(e);\n            }\n          } else {\n            acc = value;\n          }\n        },\n        error: function (e) {\n          observer.error(e);\n        },\n        complete: function () {\n          if (!hasValue && !hasSeed) return observer.error(new TypeError('Cannot reduce an empty sequence'));\n          observer.next(acc);\n          observer.complete();\n        }\n      });\n    });\n  };\n\n  _proto3.concat = function concat() {\n    var _this5 = this;\n\n    for (var _len = arguments.length, sources = new Array(_len), _key = 0; _key < _len; _key++) {\n      sources[_key] = arguments[_key];\n    }\n\n    var C = getSpecies(this);\n    return new C(function (observer) {\n      var subscription;\n      var index = 0;\n\n      function startNext(next) {\n        subscription = next.subscribe({\n          next: function (v) {\n            observer.next(v);\n          },\n          error: function (e) {\n            observer.error(e);\n          },\n          complete: function () {\n            if (index === sources.length) {\n              subscription = undefined;\n              observer.complete();\n            } else {\n              startNext(C.from(sources[index++]));\n            }\n          }\n        });\n      }\n\n      startNext(_this5);\n      return function () {\n        if (subscription) {\n          subscription.unsubscribe();\n          subscription = undefined;\n        }\n      };\n    });\n  };\n\n  _proto3.flatMap = function flatMap(fn) {\n    var _this6 = this;\n\n    if (typeof fn !== 'function') throw new TypeError(fn + ' is not a function');\n    var C = getSpecies(this);\n    return new C(function (observer) {\n      var subscriptions = [];\n\n      var outer = _this6.subscribe({\n        next: function (value) {\n          if (fn) {\n            try {\n              value = fn(value);\n            } catch (e) {\n              return observer.error(e);\n            }\n          }\n\n          var inner = C.from(value).subscribe({\n            next: function (value) {\n              observer.next(value);\n            },\n            error: function (e) {\n              observer.error(e);\n            },\n            complete: function () {\n              var i = subscriptions.indexOf(inner);\n              if (i >= 0) subscriptions.splice(i, 1);\n              completeIfDone();\n            }\n          });\n          subscriptions.push(inner);\n        },\n        error: function (e) {\n          observer.error(e);\n        },\n        complete: function () {\n          completeIfDone();\n        }\n      });\n\n      function completeIfDone() {\n        if (outer.closed && subscriptions.length === 0) observer.complete();\n      }\n\n      return function () {\n        subscriptions.forEach(function (s) {\n          return s.unsubscribe();\n        });\n        outer.unsubscribe();\n      };\n    });\n  };\n\n  _proto3[SymbolObservable] = function () {\n    return this;\n  };\n\n  Observable.from = function from(x) {\n    var C = typeof this === 'function' ? this : Observable;\n    if (x == null) throw new TypeError(x + ' is not an object');\n    var method = getMethod(x, SymbolObservable);\n\n    if (method) {\n      var observable = method.call(x);\n      if (Object(observable) !== observable) throw new TypeError(observable + ' is not an object');\n      if (isObservable(observable) && observable.constructor === C) return observable;\n      return new C(function (observer) {\n        return observable.subscribe(observer);\n      });\n    }\n\n    if (hasSymbol('iterator')) {\n      method = getMethod(x, SymbolIterator);\n\n      if (method) {\n        return new C(function (observer) {\n          enqueue(function () {\n            if (observer.closed) return;\n\n            for (var _iterator = _createForOfIteratorHelperLoose(method.call(x)), _step; !(_step = _iterator()).done;) {\n              var item = _step.value;\n              observer.next(item);\n              if (observer.closed) return;\n            }\n\n            observer.complete();\n          });\n        });\n      }\n    }\n\n    if (Array.isArray(x)) {\n      return new C(function (observer) {\n        enqueue(function () {\n          if (observer.closed) return;\n\n          for (var i = 0; i < x.length; ++i) {\n            observer.next(x[i]);\n            if (observer.closed) return;\n          }\n\n          observer.complete();\n        });\n      });\n    }\n\n    throw new TypeError(x + ' is not observable');\n  };\n\n  Observable.of = function of() {\n    for (var _len2 = arguments.length, items = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n      items[_key2] = arguments[_key2];\n    }\n\n    var C = typeof this === 'function' ? this : Observable;\n    return new C(function (observer) {\n      enqueue(function () {\n        if (observer.closed) return;\n\n        for (var i = 0; i < items.length; ++i) {\n          observer.next(items[i]);\n          if (observer.closed) return;\n        }\n\n        observer.complete();\n      });\n    });\n  };\n\n  _createClass(Observable, null, [{\n    key: SymbolSpecies,\n    get: function () {\n      return this;\n    }\n  }]);\n\n  return Observable;\n}();\n\nif (hasSymbols()) {\n  Object.defineProperty(Observable, Symbol('extensions'), {\n    value: {\n      symbol: SymbolObservable,\n      hostReportError: hostReportError\n    },\n    configurable: true\n  });\n}\n\nexport { Observable };\n", "export default function symbolObservablePonyfill(root) {\n\tvar result;\n\tvar Symbol = root.Symbol;\n\n\tif (typeof Symbol === 'function') {\n\t\tif (Symbol.observable) {\n\t\t\tresult = Symbol.observable;\n\t\t} else {\n\n\t\t\tif (typeof Symbol.for === 'function') {\n\t\t\t\t// This just needs to be something that won't trample other user's Symbol.for use\n\t\t\t\t// It also will guide people to the source of their issues, if this is problematic.\n\t\t\t\t// META: It's a resource locator!\n\t\t\t\tresult = Symbol.for('https://github.com/benlesh/symbol-observable');\n\t\t\t} else {\n\t\t\t\t// Symbol.for didn't exist! The best we can do at this point is a totally \n\t\t\t\t// unique symbol. Note that the string argument here is a descriptor, not\n\t\t\t\t// an identifier. This symbol is unique.\n\t\t\t\tresult = Symbol('https://github.com/benlesh/symbol-observable');\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tSymbol.observable = result;\n\t\t\t} catch (err) {\n\t\t\t\t// Do nothing. In some environments, users have frozen `Symbol` for security reasons,\n\t\t\t\t// if it is frozen assigning to it will throw. In this case, we don't care, because\n\t\t\t\t// they will need to use the returned value from the ponyfill.\n\t\t\t}\n\t\t}\n\t} else {\n\t\tresult = '@@observable';\n\t}\n\n\treturn result;\n};\n", "/* global window */\nimport ponyfill from './ponyfill.js';\n\nvar root;\n\nif (typeof self !== 'undefined') {\n  root = self;\n} else if (typeof window !== 'undefined') {\n  root = window;\n} else if (typeof global !== 'undefined') {\n  root = global;\n} else if (typeof module !== 'undefined') {\n  root = module;\n} else {\n  root = Function('return this')();\n}\n\nvar result = ponyfill(root);\nexport default result;\n", "import type {\n  Observer,\n  Subscription as ObservableSubscription,\n  Subscriber,\n} from \"zen-observable-ts\";\nimport { Observable } from \"zen-observable-ts\";\n\n// This simplified polyfill attempts to follow the ECMAScript Observable\n// proposal (https://github.com/zenparsing/es-observable)\nimport \"symbol-observable\";\n\nexport type { Observer, ObservableSubscription, Subscriber };\n\n// The zen-observable package defines Observable.prototype[Symbol.observable]\n// when Symbol is supported, but RxJS interop depends on also setting this fake\n// '@@observable' string as a polyfill for Symbol.observable.\nconst { prototype } = Observable;\nconst fakeObsSymbol = \"@@observable\" as keyof typeof prototype;\nif (!prototype[fakeObsSymbol]) {\n  // @ts-expect-error\n  prototype[fakeObsSymbol] = function () {\n    return this;\n  };\n}\n\nexport { Observable };\n", "const { toString } = Object.prototype;\n\n/**\n * Deeply clones a value to create a new instance.\n */\nexport function cloneDeep<T>(value: T): T {\n  return cloneDeepHelper(value);\n}\n\nfunction cloneDeepHelper<T>(val: T, seen?: Map<any, any>): T {\n  switch (toString.call(val)) {\n    case \"[object Array]\": {\n      seen = seen || new Map();\n      if (seen.has(val)) return seen.get(val);\n      const copy: T & any[] = (val as any).slice(0);\n      seen.set(val, copy);\n      copy.forEach(function (child, i) {\n        copy[i] = cloneDeepHelper(child, seen);\n      });\n      return copy;\n    }\n\n    case \"[object Object]\": {\n      seen = seen || new Map();\n      if (seen.has(val)) return seen.get(val);\n      // High fidelity polyfills of Object.create and Object.getPrototypeOf are\n      // possible in all JS environments, so we will assume they exist/work.\n      const copy = Object.create(Object.getPrototypeOf(val));\n      seen.set(val, copy);\n      Object.keys(val as T & Record<string, any>).forEach((key) => {\n        copy[key] = cloneDeepHelper((val as any)[key], seen);\n      });\n      return copy;\n    }\n\n    default:\n      return val;\n  }\n}\n", "import { isNonNullObject } from \"./objects.js\";\n\nfunction deepFreeze(value: any) {\n  const workSet = new Set([value]);\n  workSet.forEach((obj) => {\n    if (isNonNullObject(obj) && shallowFreeze(obj) === obj) {\n      Object.getOwnPropertyNames(obj).forEach((name) => {\n        if (isNonNullObject(obj[name])) workSet.add(obj[name]);\n      });\n    }\n  });\n  return value;\n}\n\nfunction shallowFreeze<T extends object>(obj: T): T | null {\n  if (__DEV__ && !Object.isFrozen(obj)) {\n    try {\n      Object.freeze(obj);\n    } catch (e) {\n      // Some types like Uint8Array and Node.js's Buffer cannot be frozen, but\n      // they all throw a TypeError when you try, so we re-throw any exceptions\n      // that are not TypeErrors, since that would be unexpected.\n      if (e instanceof TypeError) return null;\n      throw e;\n    }\n  }\n  return obj;\n}\n\nexport function maybeDeepFreeze<T>(obj: T): T {\n  if (__DEV__) {\n    deepFreeze(obj);\n  }\n  return obj;\n}\n", "import type { Observer } from \"./Observable.js\";\n\nexport function iterateObserversSafely<E, A>(\n  observers: Set<Observer<E>>,\n  method: keyof Observer<E>,\n  argument?: A\n) {\n  // In case observers is modified during iteration, we need to commit to the\n  // original elements, which also provides an opportunity to filter them down\n  // to just the observers with the given method.\n  const observersWithMethod: Observer<E>[] = [];\n  observers.forEach((obs) => obs[method] && observersWithMethod.push(obs));\n  observersWithMethod.forEach((obs) => (obs as any)[method](argument));\n}\n", "import type { Observer } from \"./Observable.js\";\nimport { Observable } from \"./Observable.js\";\n\n// Like Observable.prototype.map, except that the mapping function can\n// optionally return a Promise (or be async).\nexport function asyncMap<V, R>(\n  observable: Observable<V>,\n  mapFn: (value: V) => R | PromiseLike<R>,\n  catchFn?: (error: any) => R | PromiseLike<R>\n): Observable<R> {\n  return new Observable<R>((observer) => {\n    let promiseQueue = {\n      // Normally we would initialize promiseQueue to Promise.resolve(), but\n      // in this case, for backwards compatibility, we need to be careful to\n      // invoke the first callback synchronously.\n      then(callback: () => any) {\n        return new Promise((resolve) => resolve(callback()));\n      },\n    } as Promise<void>;\n\n    function makeCallback(\n      examiner: typeof mapFn | typeof catchFn,\n      key: \"next\" | \"error\"\n    ): (arg: any) => void {\n      return (arg) => {\n        if (examiner) {\n          const both = () =>\n            // If the observer is closed, we don't want to continue calling the\n            // mapping function - it's result will be swallowed anyways.\n            observer.closed ?\n              /* will be swallowed */ (0 as any)\n            : examiner(arg);\n\n          promiseQueue = promiseQueue.then(both, both).then(\n            (result) => observer.next(result),\n            (error) => observer.error(error)\n          );\n        } else {\n          observer[key](arg);\n        }\n      };\n    }\n\n    const handler: Observer<V> = {\n      next: makeCallback(mapFn, \"next\"),\n      error: makeCallback(catchFn, \"error\"),\n      complete() {\n        // no need to reassign `promiseQueue`, after `observer.complete`,\n        // the observer will be closed and short-circuit everything anyways\n        /*promiseQueue = */ promiseQueue.then(() => observer.complete());\n      },\n    };\n\n    const sub = observable.subscribe(handler);\n    return () => sub.unsubscribe();\n  });\n}\n", "import { Observable } from \"./Observable.js\";\nimport { canUseSymbol } from \"../common/canUse.js\";\n\n// Generic implementations of Observable.prototype methods like map and\n// filter need to know how to create a new Observable from an Observable\n// subclass (like Concast or ObservableQuery). Those methods assume\n// (perhaps unwisely?) that they can call the subtype's constructor with a\n// Subscriber function, even though the subclass constructor might expect\n// different parameters. Defining this static Symbol.species property on\n// the subclass is a hint to generic Observable code to use the default\n// constructor instead of trying to do `new Subclass(observer => ...)`.\nexport function fixObservableSubclass<\n  S extends new (...args: any[]) => Observable<any>,\n>(subclass: S): S {\n  function set(key: symbol | string) {\n    // Object.defineProperty is necessary because the Symbol.species\n    // property is a getter by default in modern JS environments, so we\n    // can't assign to it with a normal assignment expression.\n    Object.defineProperty(subclass, key, { value: Observable });\n  }\n  if (canUseSymbol && Symbol.species) {\n    set(Symbol.species);\n  }\n  // The \"@@species\" string is used as a fake Symbol.species value in some\n  // polyfill systems (including the SymbolSpecies variable used by\n  // zen-observable), so we should set it as well, to be safe.\n  set(\"@@species\");\n  return subclass;\n}\n", "import type {\n  Observer,\n  ObservableSubscription,\n  Subscriber,\n} from \"./Observable.js\";\nimport { Observable } from \"./Observable.js\";\nimport { iterateObserversSafely } from \"./iteration.js\";\nimport { fixObservableSubclass } from \"./subclassing.js\";\n\ntype MaybeAsync<T> = T | PromiseLike<T>;\n\nfunction isPromiseLike<T>(value: MaybeAsync<T>): value is PromiseLike<T> {\n  return value && typeof (value as any).then === \"function\";\n}\n\n// Any individual Source<T> can be an Observable<T> or a promise for one.\ntype Source<T> = MaybeAsync<Observable<T>>;\n\nexport type ConcastSourcesIterable<T> = Iterable<Source<T>>;\nexport type ConcastSourcesArray<T> = Array<Source<T>>;\n\n// A Concast<T> observable concatenates the given sources into a single\n// non-overlapping sequence of Ts, automatically unwrapping any promises,\n// and broadcasts the T elements of that sequence to any number of\n// subscribers, all without creating a bunch of intermediary Observable\n// wrapper objects.\n//\n// Even though any number of observers can subscribe to the Concast, each\n// source observable is guaranteed to receive at most one subscribe call,\n// and the results are multicast to all observers.\n//\n// In addition to broadcasting every next/error message to this.observers,\n// the Concast stores the most recent message using this.latest, so any\n// new observers can immediately receive the latest message, even if it\n// was originally delivered in the past. This behavior means we can assume\n// every active observer in this.observers has received the same most\n// recent message.\n//\n// With the exception of this.latest replay, a Concast is a \"hot\"\n// observable in the sense that it does not replay past results from the\n// beginning of time for each new observer.\n//\n// Could we have used some existing RxJS class instead? Concast<T> is\n// similar to a BehaviorSubject<T>, because it is multicast and redelivers\n// the latest next/error message to new subscribers. Unlike Subject<T>,\n// Concast<T> does not expose an Observer<T> interface (this.handlers is\n// intentionally private), since Concast<T> gets its inputs from the\n// concatenated sources. If we ever switch to RxJS, there may be some\n// value in reusing their code, but for now we use zen-observable, which\n// does not contain any Subject implementations.\nexport class Concast<T> extends Observable<T> {\n  // Active observers receiving broadcast messages. Thanks to this.latest,\n  // we can assume all observers in this Set have received the same most\n  // recent message, though possibly at different times in the past.\n  private observers = new Set<Observer<T>>();\n\n  // This property starts off undefined to indicate the initial\n  // subscription has not yet begun, then points to each source\n  // subscription in turn, and finally becomes null after the sources have\n  // been exhausted. After that, it stays null.\n  private sub?: ObservableSubscription | null;\n\n  // Not only can the individual elements of the iterable be promises, but\n  // also the iterable itself can be wrapped in a promise.\n  constructor(sources: MaybeAsync<ConcastSourcesIterable<T>> | Subscriber<T>) {\n    super((observer) => {\n      this.addObserver(observer);\n      return () => this.removeObserver(observer);\n    });\n\n    // Suppress rejection warnings for this.promise, since it's perfectly\n    // acceptable to pay no attention to this.promise if you're consuming\n    // the results through the normal observable API.\n    this.promise.catch((_) => {});\n\n    // If someone accidentally tries to create a Concast using a subscriber\n    // function, recover by creating an Observable from that subscriber and\n    // using it as the source.\n    if (typeof sources === \"function\") {\n      sources = [new Observable(sources)];\n    }\n\n    if (isPromiseLike(sources)) {\n      sources.then((iterable) => this.start(iterable), this.handlers.error);\n    } else {\n      this.start(sources);\n    }\n  }\n\n  // A consumable array of source observables, incrementally consumed each time\n  // this.handlers.complete is called. This private field is not initialized\n  // until the concast.start method is called, which can happen asynchronously\n  // if a Promise is passed to the Concast constructor, so undefined is a\n  // possible value for this.sources before concast.start is called.\n  private sources: Source<T>[] | undefined;\n\n  private start(sources: ConcastSourcesIterable<T>) {\n    if (this.sub !== void 0) return;\n\n    // In practice, sources is most often simply an Array of observables.\n    // TODO Consider using sources[Symbol.iterator]() to take advantage\n    // of the laziness of non-Array iterables.\n    this.sources = Array.from(sources);\n\n    // Calling this.handlers.complete() kicks off consumption of the first\n    // source observable. It's tempting to do this step lazily in\n    // addObserver, but this.promise can be accessed without calling\n    // addObserver, so consumption needs to begin eagerly.\n    this.handlers.complete();\n  }\n\n  private deliverLastMessage(observer: Observer<T>) {\n    if (this.latest) {\n      const nextOrError = this.latest[0];\n      const method = observer[nextOrError];\n      if (method) {\n        method.call(observer, this.latest[1]);\n      }\n      // If the subscription is already closed, and the last message was\n      // a 'next' message, simulate delivery of the final 'complete'\n      // message again.\n      if (this.sub === null && nextOrError === \"next\" && observer.complete) {\n        observer.complete();\n      }\n    }\n  }\n\n  public addObserver(observer: Observer<T>) {\n    if (!this.observers.has(observer)) {\n      // Immediately deliver the most recent message, so we can always\n      // be sure all observers have the latest information.\n      this.deliverLastMessage(observer);\n      this.observers.add(observer);\n    }\n  }\n\n  public removeObserver(observer: Observer<T>) {\n    if (this.observers.delete(observer) && this.observers.size < 1) {\n      // In case there are still any listeners in this.nextResultListeners, and\n      // no error or completion has been broadcast yet, make sure those\n      // observers have a chance to run and then remove themselves from\n      // this.observers.\n      this.handlers.complete();\n    }\n  }\n\n  // Any Concast object can be trivially converted to a Promise, without\n  // having to create a new wrapper Observable. This promise provides an\n  // easy way to observe the final state of the Concast.\n  private resolve!: (result?: T | PromiseLike<T>) => void;\n  private reject!: (reason: any) => void;\n  public readonly promise = new Promise<T | undefined>((resolve, reject) => {\n    this.resolve = resolve;\n    this.reject = reject;\n  });\n\n  // Name and argument of the most recently invoked observer method, used\n  // to deliver latest results immediately to new observers.\n  private latest?: [\"next\", T] | [\"error\", any];\n\n  // Bound handler functions that can be reused for every internal\n  // subscription.\n  private handlers = {\n    next: (result: T) => {\n      if (this.sub !== null) {\n        this.latest = [\"next\", result];\n        this.notify(\"next\", result);\n        iterateObserversSafely(this.observers, \"next\", result);\n      }\n    },\n\n    error: (error: any) => {\n      const { sub } = this;\n      if (sub !== null) {\n        // Delay unsubscribing from the underlying subscription slightly,\n        // so that immediately subscribing another observer can keep the\n        // subscription active.\n        if (sub) setTimeout(() => sub.unsubscribe());\n        this.sub = null;\n        this.latest = [\"error\", error];\n        this.reject(error);\n        this.notify(\"error\", error);\n        iterateObserversSafely(this.observers, \"error\", error);\n      }\n    },\n\n    complete: () => {\n      const { sub, sources = [] } = this;\n      if (sub !== null) {\n        // If complete is called before concast.start, this.sources may be\n        // undefined, so we use a default value of [] for sources. That works\n        // here because it falls into the if (!value) {...} block, which\n        // appropriately terminates the Concast, even if this.sources might\n        // eventually have been initialized to a non-empty array.\n        const value = sources.shift();\n        if (!value) {\n          if (sub) setTimeout(() => sub.unsubscribe());\n          this.sub = null;\n          if (this.latest && this.latest[0] === \"next\") {\n            this.resolve(this.latest[1]);\n          } else {\n            this.resolve();\n          }\n          this.notify(\"complete\");\n          // We do not store this.latest = [\"complete\"], because doing so\n          // discards useful information about the previous next (or\n          // error) message. Instead, if new observers subscribe after\n          // this Concast has completed, they will receive the final\n          // 'next' message (unless there was an error) immediately\n          // followed by a 'complete' message (see addObserver).\n          iterateObserversSafely(this.observers, \"complete\");\n        } else if (isPromiseLike(value)) {\n          value.then(\n            (obs) => (this.sub = obs.subscribe(this.handlers)),\n            this.handlers.error\n          );\n        } else {\n          this.sub = value.subscribe(this.handlers);\n        }\n      }\n    },\n  };\n\n  private nextResultListeners = new Set<NextResultListener>();\n\n  private notify(\n    method: Parameters<NextResultListener>[0],\n    arg?: Parameters<NextResultListener>[1]\n  ) {\n    const { nextResultListeners } = this;\n    if (nextResultListeners.size) {\n      // Replacing this.nextResultListeners first ensures it does not grow while\n      // we are iterating over it, potentially leading to infinite loops.\n      this.nextResultListeners = new Set();\n      nextResultListeners.forEach((listener) => listener(method, arg));\n    }\n  }\n\n  // We need a way to run callbacks just *before* the next result (or error or\n  // completion) is delivered by this Concast, so we can be sure any code that\n  // runs as a result of delivering that result/error observes the effects of\n  // running the callback(s). It was tempting to reuse the Observer type instead\n  // of introducing NextResultListener, but that messes with the sizing and\n  // maintenance of this.observers, and ends up being more code overall.\n  beforeNext(callback: NextResultListener) {\n    let called = false;\n    this.nextResultListeners.add((method, arg) => {\n      if (!called) {\n        called = true;\n        callback(method, arg);\n      }\n    });\n  }\n\n  // A public way to abort observation and broadcast.\n  public cancel = (reason: any) => {\n    this.reject(reason);\n    this.sources = [];\n    this.handlers.complete();\n  };\n}\n\ntype NextResultListener = (\n  method: \"next\" | \"error\" | \"complete\",\n  arg?: any\n) => any;\n\n// Necessary because the Concast constructor has a different signature\n// than the Observable constructor.\nfixObservableSubclass(Concast);\n", "import type {\n  ExecutionPatchIncrementalResult,\n  ExecutionPatchInitialResult,\n  ExecutionPatchResult,\n  ApolloPayloadResult,\n  FetchResult,\n} from \"../../link/core/index.js\";\nimport { isNonNullObject } from \"./objects.js\";\nimport { isNonEmptyArray } from \"./arrays.js\";\nimport { DeepMerger } from \"./mergeDeep.js\";\n\nexport function isExecutionPatchIncrementalResult<T>(\n  value: FetchResult<T>\n): value is ExecutionPatchIncrementalResult {\n  return \"incremental\" in value;\n}\n\nexport function isExecutionPatchInitialResult<T>(\n  value: FetchResult<T>\n): value is ExecutionPatchInitialResult<T> {\n  return \"hasNext\" in value && \"data\" in value;\n}\n\nexport function isExecutionPatchResult<T>(\n  value: FetchResult<T>\n): value is ExecutionPatchResult<T> {\n  return (\n    isExecutionPatchIncrementalResult(value) ||\n    isExecutionPatchInitialResult(value)\n  );\n}\n\n// This function detects an Apollo payload result before it is transformed\n// into a FetchResult via HttpLink; it cannot detect an ApolloPayloadResult\n// once it leaves the link chain.\nexport function isApolloPayloadResult(\n  value: unknown\n): value is ApolloPayloadResult {\n  return isNonNullObject(value) && \"payload\" in value;\n}\n\nexport function mergeIncrementalData<TData extends object>(\n  prevResult: TData,\n  result: ExecutionPatchResult<TData>\n) {\n  let mergedData = prevResult;\n  const merger = new DeepMerger();\n  if (\n    isExecutionPatchIncrementalResult(result) &&\n    isNonEmptyArray(result.incremental)\n  ) {\n    result.incremental.forEach(({ data, path }) => {\n      for (let i = path.length - 1; i >= 0; --i) {\n        const key = path[i];\n        const isNumericKey = !isNaN(+key);\n        const parent: Record<string | number, any> = isNumericKey ? [] : {};\n        parent[key] = data;\n        data = parent as typeof data;\n      }\n      mergedData = merger.merge(mergedData, data);\n    });\n  }\n  return mergedData as TData;\n}\n", "import type { FetchResult } from \"../../link/core/index.js\";\nimport { isNonEmptyArray } from \"./arrays.js\";\nimport { isExecutionPatchIncrementalResult } from \"./incrementalResult.js\";\n\nexport function graphQLResultHasError<T>(result: FetchResult<T>): boolean {\n  const errors = getGraphQLErrorsFromResult(result);\n  return isNonEmptyArray(errors);\n}\n\nexport function getGraphQLErrorsFromResult<T>(result: FetchResult<T>) {\n  const graphQLErrors =\n    isNonEmptyArray(result.errors) ? result.errors.slice(0) : [];\n\n  if (\n    isExecutionPatchIncrementalResult(result) &&\n    isNonEmptyArray(result.incremental)\n  ) {\n    result.incremental.forEach((incrementalResult) => {\n      if (incrementalResult.errors) {\n        graphQLErrors.push(...incrementalResult.errors);\n      }\n    });\n  }\n  return graphQLErrors;\n}\n", "import type { TupleToIntersection } from \"./mergeDeep.js\";\n\n/**\n * Merges the provided objects shallowly and removes\n * all properties with an `undefined` value\n */\nexport function compact<TArgs extends any[]>(\n  ...objects: TArgs\n): TupleToIntersection<TArgs> {\n  const result = Object.create(null);\n\n  objects.forEach((obj) => {\n    if (!obj) return;\n    Object.keys(obj).forEach((key) => {\n      const value = (obj as any)[key];\n      if (value !== void 0) {\n        result[key] = value;\n      }\n    });\n  });\n\n  return result;\n}\n", "import type {\n  QueryOptions,\n  WatchQueryOptions,\n  MutationOptions,\n  OperationVariables,\n} from \"../../core/index.js\";\n\nimport { compact } from \"./compact.js\";\n\ntype OptionsUnion<TData, TVariables extends OperationVariables, TContext> =\n  | WatchQueryOptions<TVariables, TData>\n  | QueryOptions<TVariables, TData>\n  | MutationOptions<TData, TVariables, TContext, any>;\n\nexport function mergeOptions<\n  TDefaultOptions extends Partial<OptionsUnion<any, any, any>>,\n  TOptions extends TDefaultOptions,\n>(\n  defaults: TDefaultOptions | Partial<TDefaultOptions> | undefined,\n  options: TOptions | Partial<TOptions>\n): TOptions & TDefaultOptions {\n  return compact(\n    defaults,\n    options,\n    options.variables && {\n      variables: compact({\n        ...(defaults && defaults.variables),\n        ...options.variables,\n      }),\n    }\n  );\n}\n", "const { toString, hasOwnProperty } = Object.prototype;\nconst fnToStr = Function.prototype.toString;\nconst previousComparisons = new Map<object, Set<object>>();\n\n/**\n * Performs a deep equality check on two JavaScript values, tolerating cycles.\n */\nexport function equal(a: any, b: any): boolean {\n  try {\n    return check(a, b);\n  } finally {\n    previousComparisons.clear();\n  }\n}\n\n// Allow default imports as well.\nexport default equal;\n\nfunction check(a: any, b: any): boolean {\n  // If the two values are strictly equal, our job is easy.\n  if (a === b) {\n    return true;\n  }\n\n  // Object.prototype.toString returns a representation of the runtime type of\n  // the given value that is considerably more precise than typeof.\n  const aTag = toString.call(a);\n  const bTag = toString.call(b);\n\n  // If the runtime types of a and b are different, they could maybe be equal\n  // under some interpretation of equality, but for simplicity and performance\n  // we just return false instead.\n  if (aTag !== bTag) {\n    return false;\n  }\n\n  switch (aTag) {\n    case '[object Array]':\n      // Arrays are a lot like other objects, but we can cheaply compare their\n      // lengths as a short-cut before comparing their elements.\n      if (a.length !== b.length) return false;\n      // Fall through to object case...\n    case '[object Object]': {\n      if (previouslyCompared(a, b)) return true;\n\n      const aKeys = definedKeys(a);\n      const bKeys = definedKeys(b);\n\n      // If `a` and `b` have a different number of enumerable keys, they\n      // must be different.\n      const keyCount = aKeys.length;\n      if (keyCount !== bKeys.length) return false;\n\n      // Now make sure they have the same keys.\n      for (let k = 0; k < keyCount; ++k) {\n        if (!hasOwnProperty.call(b, aKeys[k])) {\n          return false;\n        }\n      }\n\n      // Finally, check deep equality of all child properties.\n      for (let k = 0; k < keyCount; ++k) {\n        const key = aKeys[k];\n        if (!check(a[key], b[key])) {\n          return false;\n        }\n      }\n\n      return true;\n    }\n\n    case '[object Error]':\n      return a.name === b.name && a.message === b.message;\n\n    case '[object Number]':\n      // Handle NaN, which is !== itself.\n      if (a !== a) return b !== b;\n      // Fall through to shared +a === +b case...\n    case '[object Boolean]':\n    case '[object Date]':\n      return +a === +b;\n\n    case '[object RegExp]':\n    case '[object String]':\n      return a == `${b}`;\n\n    case '[object Map]':\n    case '[object Set]': {\n      if (a.size !== b.size) return false;\n      if (previouslyCompared(a, b)) return true;\n\n      const aIterator = a.entries();\n      const isMap = aTag === '[object Map]';\n\n      while (true) {\n        const info = aIterator.next();\n        if (info.done) break;\n\n        // If a instanceof Set, aValue === aKey.\n        const [aKey, aValue] = info.value;\n\n        // So this works the same way for both Set and Map.\n        if (!b.has(aKey)) {\n          return false;\n        }\n\n        // However, we care about deep equality of values only when dealing\n        // with Map structures.\n        if (isMap && !check(aValue, b.get(aKey))) {\n          return false;\n        }\n      }\n\n      return true;\n    }\n\n    case '[object Uint16Array]':\n    case '[object Uint8Array]': // Buffer, in Node.js.\n    case '[object Uint32Array]':\n    case '[object Int32Array]':\n    case '[object Int8Array]':\n    case '[object Int16Array]':\n    case '[object ArrayBuffer]':\n      // DataView doesn't need these conversions, but the equality check is\n      // otherwise the same.\n      a = new Uint8Array(a);\n      b = new Uint8Array(b);\n      // Fall through...\n    case '[object DataView]': {\n      let len = a.byteLength;\n      if (len === b.byteLength) {\n        while (len-- && a[len] === b[len]) {\n          // Keep looping as long as the bytes are equal.\n        }\n      }\n      return len === -1;\n    }\n\n    case '[object AsyncFunction]':\n    case '[object GeneratorFunction]':\n    case '[object AsyncGeneratorFunction]':\n    case '[object Function]': {\n      const aCode = fnToStr.call(a);\n      if (aCode !== fnToStr.call(b)) {\n        return false;\n      }\n\n      // We consider non-native functions equal if they have the same code\n      // (native functions require === because their code is censored).\n      // Note that this behavior is not entirely sound, since !== function\n      // objects with the same code can behave differently depending on\n      // their closure scope. However, any function can behave differently\n      // depending on the values of its input arguments (including this)\n      // and its calling context (including its closure scope), even\n      // though the function object is === to itself; and it is entirely\n      // possible for functions that are not === to behave exactly the\n      // same under all conceivable circumstances. Because none of these\n      // factors are statically decidable in JavaScript, JS function\n      // equality is not well-defined. This ambiguity allows us to\n      // consider the best possible heuristic among various imperfect\n      // options, and equating non-native functions that have the same\n      // code has enormous practical benefits, such as when comparing\n      // functions that are repeatedly passed as fresh function\n      // expressions within objects that are otherwise deeply equal. Since\n      // any function created from the same syntactic expression (in the\n      // same code location) will always stringify to the same code\n      // according to fnToStr.call, we can reasonably expect these\n      // repeatedly passed function expressions to have the same code, and\n      // thus behave \"the same\" (with all the caveats mentioned above),\n      // even though the runtime function objects are !== to one another.\n      return !endsWith(aCode, nativeCodeSuffix);\n    }\n  }\n\n  // Otherwise the values are not equal.\n  return false;\n}\n\nfunction definedKeys<TObject extends object>(obj: TObject) {\n  // Remember that the second argument to Array.prototype.filter will be\n  // used as `this` within the callback function.\n  return Object.keys(obj).filter(isDefinedKey, obj);\n}\nfunction isDefinedKey<TObject extends object>(\n  this: TObject,\n  key: keyof TObject,\n) {\n  return this[key] !== void 0;\n}\n\nconst nativeCodeSuffix = \"{ [native code] }\";\n\nfunction endsWith(full: string, suffix: string) {\n  const fromIndex = full.length - suffix.length;\n  return fromIndex >= 0 &&\n    full.indexOf(suffix, fromIndex) === fromIndex;\n}\n\nfunction previouslyCompared(a: object, b: object): boolean {\n  // Though cyclic references can make an object graph appear infinite from the\n  // perspective of a depth-first traversal, the graph still contains a finite\n  // number of distinct object references. We use the previousComparisons cache\n  // to avoid comparing the same pair of object references more than once, which\n  // guarantees termination (even if we end up comparing every object in one\n  // graph to every object in the other graph, which is extremely unlikely),\n  // while still allowing weird isomorphic structures (like rings with different\n  // lengths) a chance to pass the equality test.\n  let bSet = previousComparisons.get(a);\n  if (bSet) {\n    // Return true here because we can be sure false will be returned somewhere\n    // else if the objects are not equivalent.\n    if (bSet.has(b)) return true;\n  } else {\n    previousComparisons.set(a, bSet = new Set);\n  }\n  bSet.add(b);\n  return false;\n}\n", "import equal from \"@wry/equality\";\n\nimport type {\n  DirectiveNode,\n  DocumentNode,\n  FieldNode,\n  FragmentDefinitionNode,\n  FragmentSpreadNode,\n  InlineFragmentNode,\n  SelectionNode,\n  SelectionSetNode,\n} from \"graphql\";\n\nimport type { ApolloQueryResult, OperationVariables } from \"./types.js\";\n\nimport type { FragmentMap } from \"../utilities/index.js\";\nimport {\n  createFragmentMap,\n  getFragmentDefinitions,\n  getFragmentFromSelection,\n  getMainDefinition,\n  isField,\n  resultKeyNameFromField,\n  shouldInclude,\n} from \"../utilities/index.js\";\n\n// Returns true if aResult and bResult are deeply equal according to the fields\n// selected by the given query, ignoring any fields marked as @nonreactive.\nexport function equalByQuery(\n  query: DocumentNode,\n  { data: aData, ...aRest }: Partial<ApolloQueryResult<unknown>>,\n  { data: bData, ...bRest }: Partial<ApolloQueryResult<unknown>>,\n  variables?: OperationVariables\n): boolean {\n  return (\n    equal(aRest, bRest) &&\n    equalBySelectionSet(getMainDefinition(query).selectionSet, aData, bData, {\n      fragmentMap: createFragmentMap(getFragmentDefinitions(query)),\n      variables,\n    })\n  );\n}\n\n// Encapsulates the information used by equalBySelectionSet that does not change\n// during the recursion.\ninterface CompareContext<TVariables> {\n  fragmentMap: FragmentMap;\n  variables: TVariables | undefined;\n}\n\nfunction equalBySelectionSet(\n  selectionSet: SelectionSetNode,\n  aResult: any,\n  bResult: any,\n  context: CompareContext<OperationVariables>\n): boolean {\n  if (aResult === bResult) {\n    return true;\n  }\n\n  const seenSelections = new Set<SelectionNode>();\n\n  // Returning true from this Array.prototype.every callback function skips the\n  // current field/subtree. Returning false aborts the entire traversal\n  // immediately, causing equalBySelectionSet to return false.\n  return selectionSet.selections.every((selection) => {\n    // Avoid re-processing the same selection at the same level of recursion, in\n    // case the same field gets included via multiple indirect fragment spreads.\n    if (seenSelections.has(selection)) return true;\n    seenSelections.add(selection);\n\n    // Ignore @skip(if: true) and @include(if: false) fields.\n    if (!shouldInclude(selection, context.variables)) return true;\n\n    // If the field or (named) fragment spread has a @nonreactive directive on\n    // it, we don't care if it's different, so we pretend it's the same.\n    if (selectionHasNonreactiveDirective(selection)) return true;\n\n    if (isField(selection)) {\n      const resultKey = resultKeyNameFromField(selection);\n      const aResultChild = aResult && aResult[resultKey];\n      const bResultChild = bResult && bResult[resultKey];\n      const childSelectionSet = selection.selectionSet;\n\n      if (!childSelectionSet) {\n        // These are scalar values, so we can compare them with deep equal\n        // without redoing the main recursive work.\n        return equal(aResultChild, bResultChild);\n      }\n\n      const aChildIsArray = Array.isArray(aResultChild);\n      const bChildIsArray = Array.isArray(bResultChild);\n      if (aChildIsArray !== bChildIsArray) return false;\n      if (aChildIsArray && bChildIsArray) {\n        const length = aResultChild.length;\n        if (bResultChild.length !== length) {\n          return false;\n        }\n        for (let i = 0; i < length; ++i) {\n          if (\n            !equalBySelectionSet(\n              childSelectionSet,\n              aResultChild[i],\n              bResultChild[i],\n              context\n            )\n          ) {\n            return false;\n          }\n        }\n        return true;\n      }\n\n      return equalBySelectionSet(\n        childSelectionSet,\n        aResultChild,\n        bResultChild,\n        context\n      );\n    } else {\n      const fragment = getFragmentFromSelection(selection, context.fragmentMap);\n      if (fragment) {\n        // The fragment might === selection if it's an inline fragment, but\n        // could be !== if it's a named fragment ...spread.\n        if (selectionHasNonreactiveDirective(fragment)) return true;\n\n        return equalBySelectionSet(\n          fragment.selectionSet,\n          // Notice that we reuse the same aResult and bResult values here,\n          // since the fragment ...spread does not specify a field name, but\n          // consists of multiple fields (within the fragment's selection set)\n          // that should be applied to the current result value(s).\n          aResult,\n          bResult,\n          context\n        );\n      }\n    }\n  });\n}\n\nfunction selectionHasNonreactiveDirective(\n  selection:\n    | FieldNode\n    | InlineFragmentNode\n    | FragmentSpreadNode\n    | FragmentDefinitionNode\n): boolean {\n  return (\n    !!selection.directives && selection.directives.some(directiveIsNonreactive)\n  );\n}\n\nfunction directiveIsNonreactive(dir: DirectiveNode): boolean {\n  return dir.name.value === \"nonreactive\";\n}\n", "import type { DocumentNode } from \"graphql\";\nimport { wrap } from \"optimism\";\n\nimport type {\n  StoreObject,\n  Reference,\n  DeepPartial,\n} from \"../../utilities/index.js\";\nimport {\n  Observable,\n  cacheSizes,\n  defaultCacheSizes,\n  getFragmentQueryDocument,\n  mergeDeepArray,\n} from \"../../utilities/index.js\";\nimport type { DataProxy } from \"./types/DataProxy.js\";\nimport type { Cache } from \"./types/Cache.js\";\nimport { WeakCache } from \"@wry/caches\";\nimport { getApolloCacheMemoryInternals } from \"../../utilities/caching/getMemoryInternals.js\";\nimport type {\n  OperationVariables,\n  TypedDocumentNode,\n} from \"../../core/types.js\";\nimport type { MissingTree } from \"./types/common.js\";\nimport { equalByQuery } from \"../../core/equalByQuery.js\";\n\nexport type Transaction<T> = (c: ApolloCache<T>) => void;\n\n/**\n * Watched fragment options.\n */\nexport interface WatchFragmentOptions<TData, TVars> {\n  /**\n   * A GraphQL fragment document parsed into an AST with the `gql`\n   * template literal.\n   *\n   * @docGroup 1. Required options\n   */\n  fragment: DocumentNode | TypedDocumentNode<TData, TVars>;\n  /**\n   * An object containing a `__typename` and primary key fields\n   * (such as `id`) identifying the entity object from which the fragment will\n   * be retrieved, or a `{ __ref: \"...\" }` reference, or a `string` ID\n   * (uncommon).\n   *\n   * @docGroup 1. Required options\n   */\n  from: StoreObject | Reference | string;\n  /**\n   * Any variables that the GraphQL fragment may depend on.\n   *\n   * @docGroup 2. Cache options\n   */\n  variables?: TVars;\n  /**\n   * The name of the fragment defined in the fragment document.\n   *\n   * Required if the fragment document includes more than one fragment,\n   * optional otherwise.\n   *\n   * @docGroup 2. Cache options\n   */\n  fragmentName?: string;\n  /**\n   * If `true`, `watchFragment` returns optimistic results.\n   *\n   * The default value is `true`.\n   *\n   * @docGroup 2. Cache options\n   */\n  optimistic?: boolean;\n  /**\n   * @deprecated\n   * Using `canonizeResults` can result in memory leaks so we generally do not\n   * recommend using this option anymore.\n   * A future version of Apollo Client will contain a similar feature.\n   *\n   * Whether to canonize cache results before returning them. Canonization\n   * takes some extra time, but it speeds up future deep equality comparisons.\n   * Defaults to false.\n   */\n  canonizeResults?: boolean;\n}\n\n/**\n * Watched fragment results.\n */\nexport type WatchFragmentResult<TData> =\n  | {\n      data: TData;\n      complete: true;\n      missing?: never;\n    }\n  | {\n      data: DeepPartial<TData>;\n      complete: false;\n      missing: MissingTree;\n    };\n\nexport abstract class ApolloCache<TSerialized> implements DataProxy {\n  public readonly assumeImmutableResults: boolean = false;\n\n  // required to implement\n  // core API\n  public abstract read<TData = any, TVariables = any>(\n    query: Cache.ReadOptions<TVariables, TData>\n  ): TData | null;\n  public abstract write<TData = any, TVariables = any>(\n    write: Cache.WriteOptions<TData, TVariables>\n  ): Reference | undefined;\n  public abstract diff<T>(query: Cache.DiffOptions): Cache.DiffResult<T>;\n  public abstract watch<TData = any, TVariables = any>(\n    watch: Cache.WatchOptions<TData, TVariables>\n  ): () => void;\n\n  // Empty the cache and restart all current watches (unless\n  // options.discardWatches is true).\n  public abstract reset(options?: Cache.ResetOptions): Promise<void>;\n\n  // Remove whole objects from the cache by passing just options.id, or\n  // specific fields by passing options.field and/or options.args. If no\n  // options.args are provided, all fields matching options.field (even\n  // those with arguments) will be removed. Returns true iff any data was\n  // removed from the cache.\n  public abstract evict(options: Cache.EvictOptions): boolean;\n\n  // initializer / offline / ssr API\n  /**\n   * Replaces existing state in the cache (if any) with the values expressed by\n   * `serializedState`.\n   *\n   * Called when hydrating a cache (server side rendering, or offline storage),\n   * and also (potentially) during hot reloads.\n   */\n  public abstract restore(\n    serializedState: TSerialized\n  ): ApolloCache<TSerialized>;\n\n  /**\n   * Exposes the cache's complete state, in a serializable format for later restoration.\n   */\n  public abstract extract(optimistic?: boolean): TSerialized;\n\n  // Optimistic API\n\n  public abstract removeOptimistic(id: string): void;\n\n  // Transactional API\n\n  // The batch method is intended to replace/subsume both performTransaction\n  // and recordOptimisticTransaction, but performTransaction came first, so we\n  // provide a default batch implementation that's just another way of calling\n  // performTransaction. Subclasses of ApolloCache (such as InMemoryCache) can\n  // override the batch method to do more interesting things with its options.\n  public batch<U>(options: Cache.BatchOptions<this, U>): U {\n    const optimisticId =\n      typeof options.optimistic === \"string\" ? options.optimistic\n      : options.optimistic === false ? null\n      : void 0;\n    let updateResult: U;\n    this.performTransaction(\n      () => (updateResult = options.update(this)),\n      optimisticId\n    );\n    return updateResult!;\n  }\n\n  public abstract performTransaction(\n    transaction: Transaction<TSerialized>,\n    // Although subclasses may implement recordOptimisticTransaction\n    // however they choose, the default implementation simply calls\n    // performTransaction with a string as the second argument, allowing\n    // performTransaction to handle both optimistic and non-optimistic\n    // (broadcast-batching) transactions. Passing null for optimisticId is\n    // also allowed, and indicates that performTransaction should apply\n    // the transaction non-optimistically (ignoring optimistic data).\n    optimisticId?: string | null\n  ): void;\n\n  public recordOptimisticTransaction(\n    transaction: Transaction<TSerialized>,\n    optimisticId: string\n  ) {\n    this.performTransaction(transaction, optimisticId);\n  }\n\n  // Optional API\n\n  // Called once per input document, allowing the cache to make static changes\n  // to the query, such as adding __typename fields.\n  public transformDocument(document: DocumentNode): DocumentNode {\n    return document;\n  }\n\n  // Called before each ApolloLink request, allowing the cache to make dynamic\n  // changes to the query, such as filling in missing fragment definitions.\n  public transformForLink(document: DocumentNode): DocumentNode {\n    return document;\n  }\n\n  public identify(object: StoreObject | Reference): string | undefined {\n    return;\n  }\n\n  public gc(): string[] {\n    return [];\n  }\n\n  public modify<Entity extends Record<string, any> = Record<string, any>>(\n    options: Cache.ModifyOptions<Entity>\n  ): boolean {\n    return false;\n  }\n\n  // DataProxy API\n  public readQuery<QueryType, TVariables = any>(\n    options: Cache.ReadQueryOptions<QueryType, TVariables>,\n    optimistic = !!options.optimistic\n  ): QueryType | null {\n    return this.read({\n      ...options,\n      rootId: options.id || \"ROOT_QUERY\",\n      optimistic,\n    });\n  }\n\n  /** {@inheritDoc @apollo/client!ApolloClient#watchFragment:member(1)} */\n  public watchFragment<TData = any, TVars = OperationVariables>(\n    options: WatchFragmentOptions<TData, TVars>\n  ): Observable<WatchFragmentResult<TData>> {\n    const { fragment, fragmentName, from, optimistic = true } = options;\n    const query = this.getFragmentDoc(fragment, fragmentName);\n\n    const diffOptions: Cache.DiffOptions<TData, TVars> = {\n      returnPartialData: true,\n      id: typeof from === \"string\" ? from : this.identify(from),\n      query,\n      optimistic,\n    };\n\n    let latestDiff: DataProxy.DiffResult<TData> | undefined;\n\n    return new Observable((observer) => {\n      return this.watch<TData, TVars>({\n        ...diffOptions,\n        immediate: true,\n        callback(diff) {\n          if (\n            // Always ensure we deliver the first result\n            latestDiff &&\n            equalByQuery(\n              query,\n              { data: latestDiff?.result },\n              { data: diff.result }\n            )\n          ) {\n            return;\n          }\n\n          const result = {\n            data: diff.result as DeepPartial<TData>,\n            complete: !!diff.complete,\n          } as WatchFragmentResult<TData>;\n\n          if (diff.missing) {\n            result.missing = mergeDeepArray(\n              diff.missing.map((error) => error.missing)\n            );\n          }\n\n          latestDiff = diff;\n          observer.next(result);\n        },\n      });\n    });\n  }\n\n  // Make sure we compute the same (===) fragment query document every\n  // time we receive the same fragment in readFragment.\n  private getFragmentDoc = wrap(getFragmentQueryDocument, {\n    max:\n      cacheSizes[\"cache.fragmentQueryDocuments\"] ||\n      defaultCacheSizes[\"cache.fragmentQueryDocuments\"],\n    cache: WeakCache,\n  });\n\n  public readFragment<FragmentType, TVariables = any>(\n    options: Cache.ReadFragmentOptions<FragmentType, TVariables>,\n    optimistic = !!options.optimistic\n  ): FragmentType | null {\n    return this.read({\n      ...options,\n      query: this.getFragmentDoc(options.fragment, options.fragmentName),\n      rootId: options.id,\n      optimistic,\n    });\n  }\n\n  public writeQuery<TData = any, TVariables = any>({\n    id,\n    data,\n    ...options\n  }: Cache.WriteQueryOptions<TData, TVariables>): Reference | undefined {\n    return this.write(\n      Object.assign(options, {\n        dataId: id || \"ROOT_QUERY\",\n        result: data,\n      })\n    );\n  }\n\n  public writeFragment<TData = any, TVariables = any>({\n    id,\n    data,\n    fragment,\n    fragmentName,\n    ...options\n  }: Cache.WriteFragmentOptions<TData, TVariables>): Reference | undefined {\n    return this.write(\n      Object.assign(options, {\n        query: this.getFragmentDoc(fragment, fragmentName),\n        dataId: id,\n        result: data,\n      })\n    );\n  }\n\n  public updateQuery<TData = any, TVariables = any>(\n    options: Cache.UpdateQueryOptions<TData, TVariables>,\n    update: (data: TData | null) => TData | null | void\n  ): TData | null {\n    return this.batch({\n      update(cache) {\n        const value = cache.readQuery<TData, TVariables>(options);\n        const data = update(value);\n        if (data === void 0 || data === null) return value;\n        cache.writeQuery<TData, TVariables>({ ...options, data });\n        return data;\n      },\n    });\n  }\n\n  public updateFragment<TData = any, TVariables = any>(\n    options: Cache.UpdateFragmentOptions<TData, TVariables>,\n    update: (data: TData | null) => TData | null | void\n  ): TData | null {\n    return this.batch({\n      update(cache) {\n        const value = cache.readFragment<TData, TVariables>(options);\n        const data = update(value);\n        if (data === void 0 || data === null) return value;\n        cache.writeFragment<TData, TVariables>({ ...options, data });\n        return data;\n      },\n    });\n  }\n\n  /**\n   * @experimental\n   * @internal\n   * This is not a stable API - it is used in development builds to expose\n   * information to the DevTools.\n   * Use at your own risk!\n   */\n  public getMemoryInternals?: typeof getApolloCacheMemoryInternals;\n}\n\nif (__DEV__) {\n  ApolloCache.prototype.getMemoryInternals = getApolloCacheMemoryInternals;\n}\n", "import { DataProxy } from \"./DataProxy.js\";\nimport type { AllFieldsModifier, Modifiers } from \"./common.js\";\nimport type { ApolloCache } from \"../cache.js\";\n\nexport namespace Cache {\n  export type WatchCallback<TData = any> = (\n    diff: Cache.DiffResult<TData>,\n    lastDiff?: Cache.DiffResult<TData>\n  ) => void;\n\n  export interface ReadOptions<TVariables = any, TData = any>\n    extends DataProxy.Query<TVariables, TData> {\n    rootId?: string;\n    previousResult?: any;\n    optimistic: boolean;\n    returnPartialData?: boolean;\n    /**\n     * @deprecated\n     * Using `canonizeResults` can result in memory leaks so we generally do not\n     * recommend using this option anymore.\n     * A future version of Apollo Client will contain a similar feature without\n     * the risk of memory leaks.\n     */\n    canonizeResults?: boolean;\n  }\n\n  export interface WriteOptions<TResult = any, TVariables = any>\n    extends Omit<DataProxy.Query<TVariables, TResult>, \"id\">,\n      Omit<DataProxy.WriteOptions<TResult>, \"data\"> {\n    dataId?: string;\n    result: TResult;\n  }\n\n  export interface DiffOptions<TData = any, TVariables = any>\n    extends Omit<ReadOptions<TVariables, TData>, \"rootId\"> {\n    // The DiffOptions interface is currently just an alias for\n    // ReadOptions, though DiffOptions used to be responsible for\n    // declaring the returnPartialData option.\n  }\n\n  export interface WatchOptions<TData = any, TVariables = any>\n    extends DiffOptions<TData, TVariables> {\n    watcher?: object;\n    immediate?: boolean;\n    callback: WatchCallback<TData>;\n    lastDiff?: DiffResult<TData>;\n  }\n\n  export interface EvictOptions {\n    id?: string;\n    fieldName?: string;\n    args?: Record<string, any>;\n    broadcast?: boolean;\n  }\n\n  // Although you can call cache.reset() without options, its behavior can be\n  // configured by passing a Cache.ResetOptions object.\n  export interface ResetOptions {\n    discardWatches?: boolean;\n  }\n\n  export interface ModifyOptions<\n    Entity extends Record<string, any> = Record<string, any>,\n  > {\n    id?: string;\n    fields: Modifiers<Entity> | AllFieldsModifier<Entity>;\n    optimistic?: boolean;\n    broadcast?: boolean;\n  }\n\n  export interface BatchOptions<\n    TCache extends ApolloCache<any>,\n    TUpdateResult = void,\n  > {\n    // Same as the first parameter of performTransaction, except the cache\n    // argument will have the subclass type rather than ApolloCache.\n    update(cache: TCache): TUpdateResult;\n\n    // Passing a string for this option creates a new optimistic layer, with the\n    // given string as its layer.id, just like passing a string for the\n    // optimisticId parameter of performTransaction. Passing true is the same as\n    // passing undefined to performTransaction (running the batch operation\n    // against the current top layer of the cache), and passing false is the\n    // same as passing null (running the operation against root/non-optimistic\n    // cache data).\n    optimistic?: string | boolean;\n\n    // If you specify the ID of an optimistic layer using this option, that\n    // layer will be removed as part of the batch transaction, triggering at\n    // most one broadcast for both the transaction and the removal of the layer.\n    // Note: this option is needed because calling cache.removeOptimistic during\n    // the transaction function may not be not safe, since any modifications to\n    // cache layers may be discarded after the transaction finishes.\n    removeOptimistic?: string;\n\n    // If you want to find out which watched queries were invalidated during\n    // this batch operation, pass this optional callback function. Returning\n    // false from the callback will prevent broadcasting this result.\n    onWatchUpdated?: (\n      this: TCache,\n      watch: Cache.WatchOptions,\n      diff: Cache.DiffResult<any>,\n      lastDiff?: Cache.DiffResult<any> | undefined\n    ) => any;\n  }\n\n  export import DiffResult = DataProxy.DiffResult;\n  export import ReadQueryOptions = DataProxy.ReadQueryOptions;\n  export import ReadFragmentOptions = DataProxy.ReadFragmentOptions;\n  export import WriteQueryOptions = DataProxy.WriteQueryOptions;\n  export import WriteFragmentOptions = DataProxy.WriteFragmentOptions;\n  export import UpdateQueryOptions = DataProxy.UpdateQueryOptions;\n  export import UpdateFragmentOptions = DataProxy.UpdateFragmentOptions;\n  export import Fragment = DataProxy.Fragment;\n}\n", "import type { DocumentNode, FieldNode } from \"graphql\";\n\nimport type {\n  Reference,\n  StoreObject,\n  StoreValue,\n  isReference,\n  AsStoreObject,\n} from \"../../../utilities/index.js\";\n\nimport type { StorageType } from \"../../inmemory/policies.js\";\n\n// The Readonly<T> type only really works for object types, since it marks\n// all of the object's properties as readonly, but there are many cases when\n// a generic type parameter like TExisting might be a string or some other\n// primitive type, in which case we need to avoid wrapping it with Readonly.\n// SafeReadonly<string> collapses to just string, which makes string\n// assignable to SafeReadonly<any>, whereas string is not assignable to\n// Readonly<any>, somewhat surprisingly.\nexport type SafeReadonly<T> = T extends object ? Readonly<T> : T;\n\nexport type MissingTree =\n  | string\n  | {\n      readonly [key: string]: MissingTree;\n    };\n\nexport class MissingFieldError extends Error {\n  constructor(\n    public readonly message: string,\n    public readonly path: MissingTree | Array<string | number>,\n    public readonly query: DocumentNode,\n    public readonly variables?: Record<string, any>\n  ) {\n    // 'Error' breaks prototype chain here\n    super(message);\n\n    if (Array.isArray(this.path)) {\n      this.missing = this.message;\n      for (let i = this.path.length - 1; i >= 0; --i) {\n        this.missing = { [this.path[i]]: this.missing };\n      }\n    } else {\n      this.missing = this.path;\n    }\n\n    // We're not using `Object.setPrototypeOf` here as it isn't fully supported\n    // on Android (see issue #3236).\n    (this as any).__proto__ = MissingFieldError.prototype;\n  }\n\n  public readonly missing: MissingTree;\n}\n\nexport interface FieldSpecifier {\n  typename?: string;\n  fieldName: string;\n  field?: FieldNode;\n  args?: Record<string, any>;\n  variables?: Record<string, any>;\n}\n\nexport interface ReadFieldOptions extends FieldSpecifier {\n  from?: StoreObject | Reference;\n}\n\nexport interface ReadFieldFunction {\n  <V = StoreValue>(options: ReadFieldOptions): SafeReadonly<V> | undefined;\n  <V = StoreValue>(\n    fieldName: string,\n    from?: StoreObject | Reference\n  ): SafeReadonly<V> | undefined;\n}\n\nexport type ToReferenceFunction = (\n  objOrIdOrRef: StoreObject | string | Reference,\n  mergeIntoStore?: boolean\n) => Reference | undefined;\n\nexport type CanReadFunction = (value: StoreValue) => boolean;\n\ndeclare const _deleteModifier: unique symbol;\nexport interface DeleteModifier {\n  [_deleteModifier]: true;\n}\ndeclare const _invalidateModifier: unique symbol;\nexport interface InvalidateModifier {\n  [_invalidateModifier]: true;\n}\ndeclare const _ignoreModifier: unique symbol;\nexport interface IgnoreModifier {\n  [_ignoreModifier]: true;\n}\n\nexport type ModifierDetails = {\n  DELETE: DeleteModifier;\n  INVALIDATE: InvalidateModifier;\n  fieldName: string;\n  storeFieldName: string;\n  readField: ReadFieldFunction;\n  canRead: CanReadFunction;\n  isReference: typeof isReference;\n  toReference: ToReferenceFunction;\n  storage: StorageType;\n};\n\nexport type Modifier<T> = (\n  value: T,\n  details: ModifierDetails\n) => T | DeleteModifier | InvalidateModifier | undefined;\n\ntype StoreObjectValueMaybeReference<StoreVal> =\n  StoreVal extends Array<Record<string, any>> ?\n    StoreVal extends Array<infer Item> ?\n      Item extends Record<string, any> ?\n        ReadonlyArray<AsStoreObject<Item> | Reference>\n      : never\n    : never\n  : StoreVal extends Record<string, any> ? AsStoreObject<StoreVal> | Reference\n  : StoreVal;\n\nexport type AllFieldsModifier<Entity extends Record<string, any>> = Modifier<\n  Entity[keyof Entity] extends infer Value ?\n    StoreObjectValueMaybeReference<Exclude<Value, undefined>>\n  : never\n>;\n\nexport type Modifiers<T extends Record<string, any> = Record<string, unknown>> =\n  Partial<{\n    [FieldName in keyof T]: Modifier<\n      StoreObjectValueMaybeReference<Exclude<T[FieldName], undefined>>\n    >;\n  }>;\n", "import type {\n  DocumentNode,\n  FragmentDefinitionNode,\n  SelectionSetNode,\n} from \"graphql\";\n\nimport type { NormalizedCache, InMemoryCacheConfig } from \"./types.js\";\n\nimport type { KeyFieldsContext } from \"./policies.js\";\nimport type { FragmentRegistryAPI } from \"./fragmentRegistry.js\";\n\nimport type {\n  Reference,\n  StoreValue,\n  StoreObject,\n  FragmentMap,\n  FragmentMapFunction,\n} from \"../../utilities/index.js\";\nimport {\n  isReference,\n  isField,\n  DeepMerger,\n  resultKeyNameFromField,\n  shouldInclude,\n  isNonNullObject,\n  compact,\n  createFragmentMap,\n  getFragmentDefinitions,\n  isArray,\n} from \"../../utilities/index.js\";\n\nexport const { hasOwnProperty: hasOwn } = Object.prototype;\n\nexport function isNullish(value: any): value is null | undefined {\n  return value === null || value === void 0;\n}\n\nexport { isArray };\n\nexport function defaultDataIdFromObject(\n  { __typename, id, _id }: Readonly<StoreObject>,\n  context?: KeyFieldsContext\n): string | undefined {\n  if (typeof __typename === \"string\") {\n    if (context) {\n      context.keyObject =\n        !isNullish(id) ? { id }\n        : !isNullish(_id) ? { _id }\n        : void 0;\n    }\n\n    // If there is no object.id, fall back to object._id.\n    if (isNullish(id) && !isNullish(_id)) {\n      id = _id;\n    }\n\n    if (!isNullish(id)) {\n      return `${__typename}:${\n        typeof id === \"number\" || typeof id === \"string\" ?\n          id\n        : JSON.stringify(id)\n      }`;\n    }\n  }\n}\n\nconst defaultConfig = {\n  dataIdFromObject: defaultDataIdFromObject,\n  addTypename: true,\n  resultCaching: true,\n  // Thanks to the shouldCanonizeResults helper, this should be the only line\n  // you have to change to reenable canonization by default in the future.\n  canonizeResults: false,\n};\n\nexport function normalizeConfig(config: InMemoryCacheConfig) {\n  return compact(defaultConfig, config);\n}\n\nexport function shouldCanonizeResults(\n  config: Pick<InMemoryCacheConfig, \"canonizeResults\">\n): boolean {\n  const value = config.canonizeResults;\n  return value === void 0 ? defaultConfig.canonizeResults : value;\n}\n\nexport function getTypenameFromStoreObject(\n  store: NormalizedCache,\n  objectOrReference: StoreObject | Reference\n): string | undefined {\n  return isReference(objectOrReference) ?\n      (store.get(objectOrReference.__ref, \"__typename\") as string)\n    : objectOrReference && objectOrReference.__typename;\n}\n\nexport const TypeOrFieldNameRegExp = /^[_a-z][_0-9a-z]*/i;\n\nexport function fieldNameFromStoreName(storeFieldName: string): string {\n  const match = storeFieldName.match(TypeOrFieldNameRegExp);\n  return match ? match[0] : storeFieldName;\n}\n\nexport function selectionSetMatchesResult(\n  selectionSet: SelectionSetNode,\n  result: Record<string, any>,\n  variables?: Record<string, any>\n): boolean {\n  if (isNonNullObject(result)) {\n    return isArray(result) ?\n        result.every((item) =>\n          selectionSetMatchesResult(selectionSet, item, variables)\n        )\n      : selectionSet.selections.every((field) => {\n          if (isField(field) && shouldInclude(field, variables)) {\n            const key = resultKeyNameFromField(field);\n            return (\n              hasOwn.call(result, key) &&\n              (!field.selectionSet ||\n                selectionSetMatchesResult(\n                  field.selectionSet,\n                  result[key],\n                  variables\n                ))\n            );\n          }\n          // If the selection has been skipped with @skip(true) or\n          // @include(false), it should not count against the matching. If\n          // the selection is not a field, it must be a fragment (inline or\n          // named). We will determine if selectionSetMatchesResult for that\n          // fragment when we get to it, so for now we return true.\n          return true;\n        });\n  }\n  return false;\n}\n\nexport function storeValueIsStoreObject(\n  value: StoreValue\n): value is StoreObject {\n  return isNonNullObject(value) && !isReference(value) && !isArray(value);\n}\n\nexport function makeProcessedFieldsMerger() {\n  return new DeepMerger();\n}\n\nexport function extractFragmentContext(\n  document: DocumentNode,\n  fragments?: FragmentRegistryAPI\n): {\n  fragmentMap: FragmentMap;\n  lookupFragment: FragmentMapFunction;\n} {\n  // FragmentMap consisting only of fragments defined directly in document, not\n  // including other fragments registered in the FragmentRegistry.\n  const fragmentMap = createFragmentMap(getFragmentDefinitions(document));\n  return {\n    fragmentMap,\n    lookupFragment(name) {\n      let def: FragmentDefinitionNode | null = fragmentMap[name];\n      if (!def && fragments) {\n        def = fragments.lookup(name);\n      }\n      return def || null;\n    },\n  };\n}\n", "import { invariant } from \"../../utilities/globals/index.js\";\nimport type { OptimisticDependencyFunction } from \"optimism\";\nimport { dep } from \"optimism\";\nimport { equal } from \"@wry/equality\";\nimport { Trie } from \"@wry/trie\";\n\nimport type {\n  StoreValue,\n  StoreObject,\n  Reference,\n} from \"../../utilities/index.js\";\nimport {\n  isReference,\n  makeReference,\n  DeepMerger,\n  maybeDeepFreeze,\n  canUseWeakMap,\n  isNonNullObject,\n} from \"../../utilities/index.js\";\nimport type { NormalizedCache, NormalizedCacheObject } from \"./types.js\";\nimport { hasOwn, fieldNameFromStoreName } from \"./helpers.js\";\nimport type { Policies, StorageType } from \"./policies.js\";\nimport type { Cache } from \"../core/types/Cache.js\";\nimport type {\n  SafeReadonly,\n  Modifier,\n  Modifiers,\n  ReadFieldOptions,\n  ToReferenceFunction,\n  CanReadFunction,\n  InvalidateModifier,\n  DeleteModifier,\n  ModifierDetails,\n} from \"../core/types/common.js\";\nimport type { DocumentNode, FieldNode, SelectionSetNode } from \"graphql\";\n\nconst DELETE: DeleteModifier = Object.create(null);\nconst delModifier: Modifier<any> = () => DELETE;\nconst INVALIDATE: InvalidateModifier = Object.create(null);\n\nexport abstract class EntityStore implements NormalizedCache {\n  protected data: NormalizedCacheObject = Object.create(null);\n\n  constructor(\n    public readonly policies: Policies,\n    public readonly group: CacheGroup\n  ) {}\n\n  public abstract addLayer(\n    layerId: string,\n    replay: (layer: EntityStore) => any\n  ): Layer;\n\n  public abstract removeLayer(layerId: string): EntityStore;\n\n  // Although the EntityStore class is abstract, it contains concrete\n  // implementations of the various NormalizedCache interface methods that\n  // are inherited by the Root and Layer subclasses.\n\n  public toObject(): NormalizedCacheObject {\n    return { ...this.data };\n  }\n\n  public has(dataId: string): boolean {\n    return this.lookup(dataId, true) !== void 0;\n  }\n\n  public get(dataId: string, fieldName: string): StoreValue {\n    this.group.depend(dataId, fieldName);\n    if (hasOwn.call(this.data, dataId)) {\n      const storeObject = this.data[dataId];\n      if (storeObject && hasOwn.call(storeObject, fieldName)) {\n        return storeObject[fieldName];\n      }\n    }\n    if (\n      fieldName === \"__typename\" &&\n      hasOwn.call(this.policies.rootTypenamesById, dataId)\n    ) {\n      return this.policies.rootTypenamesById[dataId];\n    }\n    if (this instanceof Layer) {\n      return this.parent.get(dataId, fieldName);\n    }\n  }\n\n  protected lookup(\n    dataId: string,\n    dependOnExistence?: boolean\n  ): StoreObject | undefined {\n    // The has method (above) calls lookup with dependOnExistence = true, so\n    // that it can later be invalidated when we add or remove a StoreObject for\n    // this dataId. Any consumer who cares about the contents of the StoreObject\n    // should not rely on this dependency, since the contents could change\n    // without the object being added or removed.\n    if (dependOnExistence) this.group.depend(dataId, \"__exists\");\n\n    if (hasOwn.call(this.data, dataId)) {\n      return this.data[dataId];\n    }\n\n    if (this instanceof Layer) {\n      return this.parent.lookup(dataId, dependOnExistence);\n    }\n\n    if (this.policies.rootTypenamesById[dataId]) {\n      return Object.create(null);\n    }\n  }\n\n  public merge(older: string | StoreObject, newer: StoreObject | string): void {\n    let dataId: string | undefined;\n\n    // Convert unexpected references to ID strings.\n    if (isReference(older)) older = older.__ref;\n    if (isReference(newer)) newer = newer.__ref;\n\n    const existing: StoreObject | undefined =\n      typeof older === \"string\" ? this.lookup((dataId = older)) : older;\n\n    const incoming: StoreObject | undefined =\n      typeof newer === \"string\" ? this.lookup((dataId = newer)) : newer;\n\n    // If newer was a string ID, but that ID was not defined in this store,\n    // then there are no fields to be merged, so we're done.\n    if (!incoming) return;\n\n    invariant(typeof dataId === \"string\", \"store.merge expects a string ID\");\n\n    const merged: StoreObject = new DeepMerger(storeObjectReconciler).merge(\n      existing,\n      incoming\n    );\n\n    // Even if merged === existing, existing may have come from a lower\n    // layer, so we always need to set this.data[dataId] on this level.\n    this.data[dataId] = merged;\n\n    if (merged !== existing) {\n      delete this.refs[dataId];\n      if (this.group.caching) {\n        const fieldsToDirty: Record<string, 1> = Object.create(null);\n\n        // If we added a new StoreObject where there was previously none, dirty\n        // anything that depended on the existence of this dataId, such as the\n        // EntityStore#has method.\n        if (!existing) fieldsToDirty.__exists = 1;\n\n        // Now invalidate dependents who called getFieldValue for any fields\n        // that are changing as a result of this merge.\n        Object.keys(incoming).forEach((storeFieldName) => {\n          if (\n            !existing ||\n            existing[storeFieldName] !== merged[storeFieldName]\n          ) {\n            // Always dirty the full storeFieldName, which may include\n            // serialized arguments following the fieldName prefix.\n            fieldsToDirty[storeFieldName] = 1;\n\n            // Also dirty fieldNameFromStoreName(storeFieldName) if it's\n            // different from storeFieldName and this field does not have\n            // keyArgs configured, because that means the cache can't make\n            // any assumptions about how field values with the same field\n            // name but different arguments might be interrelated, so it\n            // must err on the side of invalidating all field values that\n            // share the same short fieldName, regardless of arguments.\n            const fieldName = fieldNameFromStoreName(storeFieldName);\n            if (\n              fieldName !== storeFieldName &&\n              !this.policies.hasKeyArgs(merged.__typename, fieldName)\n            ) {\n              fieldsToDirty[fieldName] = 1;\n            }\n\n            // If merged[storeFieldName] has become undefined, and this is the\n            // Root layer, actually delete the property from the merged object,\n            // which is guaranteed to have been created fresh in this method.\n            if (merged[storeFieldName] === void 0 && !(this instanceof Layer)) {\n              delete merged[storeFieldName];\n            }\n          }\n        });\n\n        if (\n          fieldsToDirty.__typename &&\n          !(existing && existing.__typename) &&\n          // Since we return default root __typename strings\n          // automatically from store.get, we don't need to dirty the\n          // ROOT_QUERY.__typename field if merged.__typename is equal\n          // to the default string (usually \"Query\").\n          this.policies.rootTypenamesById[dataId] === merged.__typename\n        ) {\n          delete fieldsToDirty.__typename;\n        }\n\n        Object.keys(fieldsToDirty).forEach((fieldName) =>\n          this.group.dirty(dataId as string, fieldName)\n        );\n      }\n    }\n  }\n\n  public modify(\n    dataId: string,\n    fields: Modifier<any> | Modifiers<Record<string, any>>\n  ): boolean {\n    const storeObject = this.lookup(dataId);\n\n    if (storeObject) {\n      const changedFields: Record<string, any> = Object.create(null);\n      let needToMerge = false;\n      let allDeleted = true;\n\n      const sharedDetails = {\n        DELETE,\n        INVALIDATE,\n        isReference,\n        toReference: this.toReference,\n        canRead: this.canRead,\n        readField: <V = StoreValue>(\n          fieldNameOrOptions: string | ReadFieldOptions,\n          from?: StoreObject | Reference\n        ) =>\n          this.policies.readField<V>(\n            typeof fieldNameOrOptions === \"string\" ?\n              {\n                fieldName: fieldNameOrOptions,\n                from: from || makeReference(dataId),\n              }\n            : fieldNameOrOptions,\n            { store: this }\n          ),\n      } satisfies Partial<ModifierDetails>;\n\n      Object.keys(storeObject).forEach((storeFieldName) => {\n        const fieldName = fieldNameFromStoreName(storeFieldName);\n        let fieldValue = storeObject[storeFieldName];\n        if (fieldValue === void 0) return;\n        const modify: Modifier<StoreValue> | undefined =\n          typeof fields === \"function\" ? fields : (\n            fields[storeFieldName] || fields[fieldName]\n          );\n        if (modify) {\n          let newValue =\n            modify === delModifier ? DELETE : (\n              modify(maybeDeepFreeze(fieldValue), {\n                ...sharedDetails,\n                fieldName,\n                storeFieldName,\n                storage: this.getStorage(dataId, storeFieldName),\n              })\n            );\n          if (newValue === INVALIDATE) {\n            this.group.dirty(dataId, storeFieldName);\n          } else {\n            if (newValue === DELETE) newValue = void 0;\n            if (newValue !== fieldValue) {\n              changedFields[storeFieldName] = newValue;\n              needToMerge = true;\n              fieldValue = newValue;\n\n              if (__DEV__) {\n                const checkReference = (ref: Reference) => {\n                  if (this.lookup(ref.__ref) === undefined) {\n                    invariant.warn(\n                      \"cache.modify: You are trying to write a Reference that is not part of the store: %o\\n\" +\n                        \"Please make sure to set the `mergeIntoStore` parameter to `true` when creating a Reference that is not part of the store yet:\\n\" +\n                        \"`toReference(object, true)`\",\n                      ref\n                    );\n                    return true;\n                  }\n                };\n                if (isReference(newValue)) {\n                  checkReference(newValue);\n                } else if (Array.isArray(newValue)) {\n                  // Warn about writing \"mixed\" arrays of Reference and non-Reference objects\n                  let seenReference: boolean = false;\n                  let someNonReference: unknown;\n                  for (const value of newValue) {\n                    if (isReference(value)) {\n                      seenReference = true;\n                      if (checkReference(value)) break;\n                    } else {\n                      // Do not warn on primitive values, since those could never be represented\n                      // by a reference. This is a valid (albeit uncommon) use case.\n                      if (typeof value === \"object\" && !!value) {\n                        const [id] = this.policies.identify(value);\n                        // check if object could even be referenced, otherwise we are not interested in it for this warning\n                        if (id) {\n                          someNonReference = value;\n                        }\n                      }\n                    }\n                    if (seenReference && someNonReference !== undefined) {\n                      invariant.warn(\n                        \"cache.modify: Writing an array with a mix of both References and Objects will not result in the Objects being normalized correctly.\\n\" +\n                          \"Please convert the object instance %o to a Reference before writing it to the cache by calling `toReference(object, true)`.\",\n                        someNonReference\n                      );\n                      break;\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n        if (fieldValue !== void 0) {\n          allDeleted = false;\n        }\n      });\n\n      if (needToMerge) {\n        this.merge(dataId, changedFields);\n\n        if (allDeleted) {\n          if (this instanceof Layer) {\n            this.data[dataId] = void 0;\n          } else {\n            delete this.data[dataId];\n          }\n          this.group.dirty(dataId, \"__exists\");\n        }\n\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  // If called with only one argument, removes the entire entity\n  // identified by dataId. If called with a fieldName as well, removes all\n  // fields of that entity whose names match fieldName according to the\n  // fieldNameFromStoreName helper function. If called with a fieldName\n  // and variables, removes all fields of that entity whose names match fieldName\n  // and whose arguments when cached exactly match the variables passed.\n  public delete(\n    dataId: string,\n    fieldName?: string,\n    args?: Record<string, any>\n  ) {\n    const storeObject = this.lookup(dataId);\n    if (storeObject) {\n      const typename = this.getFieldValue<string>(storeObject, \"__typename\");\n      const storeFieldName =\n        fieldName && args ?\n          this.policies.getStoreFieldName({ typename, fieldName, args })\n        : fieldName;\n      return this.modify(\n        dataId,\n        storeFieldName ?\n          {\n            [storeFieldName]: delModifier,\n          }\n        : delModifier\n      );\n    }\n    return false;\n  }\n\n  public evict(options: Cache.EvictOptions, limit: EntityStore): boolean {\n    let evicted = false;\n    if (options.id) {\n      if (hasOwn.call(this.data, options.id)) {\n        evicted = this.delete(options.id, options.fieldName, options.args);\n      }\n      if (this instanceof Layer && this !== limit) {\n        evicted = this.parent.evict(options, limit) || evicted;\n      }\n      // Always invalidate the field to trigger rereading of watched\n      // queries, even if no cache data was modified by the eviction,\n      // because queries may depend on computed fields with custom read\n      // functions, whose values are not stored in the EntityStore.\n      if (options.fieldName || evicted) {\n        this.group.dirty(options.id, options.fieldName || \"__exists\");\n      }\n    }\n    return evicted;\n  }\n\n  public clear(): void {\n    this.replace(null);\n  }\n\n  public extract(): NormalizedCacheObject {\n    const obj = this.toObject();\n    const extraRootIds: string[] = [];\n    this.getRootIdSet().forEach((id) => {\n      if (!hasOwn.call(this.policies.rootTypenamesById, id)) {\n        extraRootIds.push(id);\n      }\n    });\n    if (extraRootIds.length) {\n      obj.__META = { extraRootIds: extraRootIds.sort() };\n    }\n    return obj;\n  }\n\n  public replace(newData: NormalizedCacheObject | null): void {\n    Object.keys(this.data).forEach((dataId) => {\n      if (!(newData && hasOwn.call(newData, dataId))) {\n        this.delete(dataId);\n      }\n    });\n    if (newData) {\n      const { __META, ...rest } = newData;\n      Object.keys(rest).forEach((dataId) => {\n        this.merge(dataId, rest[dataId] as StoreObject);\n      });\n      if (__META) {\n        __META.extraRootIds.forEach(this.retain, this);\n      }\n    }\n  }\n\n  public abstract getStorage(\n    idOrObj: string | StoreObject,\n    ...storeFieldNames: (string | number)[]\n  ): StorageType;\n\n  // Maps root entity IDs to the number of times they have been retained, minus\n  // the number of times they have been released. Retained entities keep other\n  // entities they reference (even indirectly) from being garbage collected.\n  private rootIds: {\n    [rootId: string]: number;\n  } = Object.create(null);\n\n  public retain(rootId: string): number {\n    return (this.rootIds[rootId] = (this.rootIds[rootId] || 0) + 1);\n  }\n\n  public release(rootId: string): number {\n    if (this.rootIds[rootId] > 0) {\n      const count = --this.rootIds[rootId];\n      if (!count) delete this.rootIds[rootId];\n      return count;\n    }\n    return 0;\n  }\n\n  // Return a Set<string> of all the ID strings that have been retained by\n  // this layer/root *and* any layers/roots beneath it.\n  public getRootIdSet(ids = new Set<string>()) {\n    Object.keys(this.rootIds).forEach(ids.add, ids);\n    if (this instanceof Layer) {\n      this.parent.getRootIdSet(ids);\n    } else {\n      // Official singleton IDs like ROOT_QUERY and ROOT_MUTATION are\n      // always considered roots for garbage collection, regardless of\n      // their retainment counts in this.rootIds.\n      Object.keys(this.policies.rootTypenamesById).forEach(ids.add, ids);\n    }\n    return ids;\n  }\n\n  // The goal of garbage collection is to remove IDs from the Root layer of the\n  // store that are no longer reachable starting from any IDs that have been\n  // explicitly retained (see retain and release, above). Returns an array of\n  // dataId strings that were removed from the store.\n  public gc() {\n    const ids = this.getRootIdSet();\n    const snapshot = this.toObject();\n    ids.forEach((id) => {\n      if (hasOwn.call(snapshot, id)) {\n        // Because we are iterating over an ECMAScript Set, the IDs we add here\n        // will be visited in later iterations of the forEach loop only if they\n        // were not previously contained by the Set.\n        Object.keys(this.findChildRefIds(id)).forEach(ids.add, ids);\n        // By removing IDs from the snapshot object here, we protect them from\n        // getting removed from the root store layer below.\n        delete snapshot[id];\n      }\n    });\n    const idsToRemove = Object.keys(snapshot);\n    if (idsToRemove.length) {\n      let root: EntityStore = this;\n      while (root instanceof Layer) root = root.parent;\n      idsToRemove.forEach((id) => root.delete(id));\n    }\n    return idsToRemove;\n  }\n\n  // Lazily tracks { __ref: <dataId> } strings contained by this.data[dataId].\n  private refs: {\n    [dataId: string]: Record<string, true>;\n  } = Object.create(null);\n\n  public findChildRefIds(dataId: string): Record<string, true> {\n    if (!hasOwn.call(this.refs, dataId)) {\n      const found = (this.refs[dataId] = Object.create(null));\n      const root = this.data[dataId];\n      if (!root) return found;\n\n      const workSet = new Set<Record<string | number, any>>([root]);\n      // Within the store, only arrays and objects can contain child entity\n      // references, so we can prune the traversal using this predicate:\n      workSet.forEach((obj) => {\n        if (isReference(obj)) {\n          found[obj.__ref] = true;\n          // In rare cases, a { __ref } Reference object may have other fields.\n          // This often indicates a mismerging of References with StoreObjects,\n          // but garbage collection should not be fooled by a stray __ref\n          // property in a StoreObject (ignoring all the other fields just\n          // because the StoreObject looks like a Reference). To avoid this\n          // premature termination of findChildRefIds recursion, we fall through\n          // to the code below, which will handle any other properties of obj.\n        }\n        if (isNonNullObject(obj)) {\n          Object.keys(obj).forEach((key) => {\n            const child = obj[key];\n            // No need to add primitive values to the workSet, since they cannot\n            // contain reference objects.\n            if (isNonNullObject(child)) {\n              workSet.add(child);\n            }\n          });\n        }\n      });\n    }\n    return this.refs[dataId];\n  }\n\n  // Used to compute cache keys specific to this.group.\n  /** overload for `InMemoryCache.maybeBroadcastWatch` */\n  public makeCacheKey(\n    document: DocumentNode,\n    callback: Cache.WatchCallback<any>,\n    details: string\n  ): object;\n  /** overload for `StoreReader.executeSelectionSet` */\n  public makeCacheKey(\n    selectionSet: SelectionSetNode,\n    parent: string /* = ( Reference.__ref ) */ | StoreObject,\n    varString: string | undefined,\n    canonizeResults: boolean\n  ): object;\n  /** overload for `StoreReader.executeSubSelectedArray` */\n  public makeCacheKey(\n    field: FieldNode,\n    array: readonly any[],\n    varString: string | undefined\n  ): object;\n  /** @deprecated This is only meant for internal usage,\n   * in your own code please use a `Trie` instance instead. */\n  public makeCacheKey(...args: any[]): object;\n  public makeCacheKey() {\n    return this.group.keyMaker.lookupArray(arguments);\n  }\n\n  // Bound function that can be passed around to provide easy access to fields\n  // of Reference objects as well as ordinary objects.\n  public getFieldValue = <T = StoreValue>(\n    objectOrReference: StoreObject | Reference | undefined,\n    storeFieldName: string\n  ) =>\n    maybeDeepFreeze(\n      isReference(objectOrReference) ?\n        this.get(objectOrReference.__ref, storeFieldName)\n      : objectOrReference && objectOrReference[storeFieldName]\n    ) as SafeReadonly<T>;\n\n  // Returns true for non-normalized StoreObjects and non-dangling\n  // References, indicating that readField(name, objOrRef) has a chance of\n  // working. Useful for filtering out dangling references from lists.\n  public canRead: CanReadFunction = (objOrRef) => {\n    return isReference(objOrRef) ?\n        this.has(objOrRef.__ref)\n      : typeof objOrRef === \"object\";\n  };\n\n  // Bound function that converts an id or an object with a __typename and\n  // primary key fields to a Reference object. If called with a Reference object,\n  // that same Reference object is returned. Pass true for mergeIntoStore to persist\n  // an object into the store.\n  public toReference: ToReferenceFunction = (objOrIdOrRef, mergeIntoStore) => {\n    if (typeof objOrIdOrRef === \"string\") {\n      return makeReference(objOrIdOrRef);\n    }\n\n    if (isReference(objOrIdOrRef)) {\n      return objOrIdOrRef;\n    }\n\n    const [id] = this.policies.identify(objOrIdOrRef);\n\n    if (id) {\n      const ref = makeReference(id);\n      if (mergeIntoStore) {\n        this.merge(id, objOrIdOrRef);\n      }\n      return ref;\n    }\n  };\n}\n\nexport type FieldValueGetter = EntityStore[\"getFieldValue\"];\n\n// A single CacheGroup represents a set of one or more EntityStore objects,\n// typically the Root store in a CacheGroup by itself, and all active Layer\n// stores in a group together. A single EntityStore object belongs to only\n// one CacheGroup, store.group. The CacheGroup is responsible for tracking\n// dependencies, so store.group is helpful for generating unique keys for\n// cached results that need to be invalidated when/if those dependencies\n// change. If we used the EntityStore objects themselves as cache keys (that\n// is, store rather than store.group), the cache would become unnecessarily\n// fragmented by all the different Layer objects. Instead, the CacheGroup\n// approach allows all optimistic Layer objects in the same linked list to\n// belong to one CacheGroup, with the non-optimistic Root object belonging\n// to another CacheGroup, allowing resultCaching dependencies to be tracked\n// separately for optimistic and non-optimistic entity data.\nclass CacheGroup {\n  private d: OptimisticDependencyFunction<string> | null = null;\n\n  // Used by the EntityStore#makeCacheKey method to compute cache keys\n  // specific to this CacheGroup.\n  public keyMaker!: Trie<object>;\n\n  constructor(\n    public readonly caching: boolean,\n    private parent: CacheGroup | null = null\n  ) {\n    this.resetCaching();\n  }\n\n  public resetCaching() {\n    this.d = this.caching ? dep<string>() : null;\n    this.keyMaker = new Trie(canUseWeakMap);\n  }\n\n  public depend(dataId: string, storeFieldName: string) {\n    if (this.d) {\n      this.d(makeDepKey(dataId, storeFieldName));\n      const fieldName = fieldNameFromStoreName(storeFieldName);\n      if (fieldName !== storeFieldName) {\n        // Fields with arguments that contribute extra identifying\n        // information to the fieldName (thus forming the storeFieldName)\n        // depend not only on the full storeFieldName but also on the\n        // short fieldName, so the field can be invalidated using either\n        // level of specificity.\n        this.d(makeDepKey(dataId, fieldName));\n      }\n      if (this.parent) {\n        this.parent.depend(dataId, storeFieldName);\n      }\n    }\n  }\n\n  public dirty(dataId: string, storeFieldName: string) {\n    if (this.d) {\n      this.d.dirty(\n        makeDepKey(dataId, storeFieldName),\n        // When storeFieldName === \"__exists\", that means the entity identified\n        // by dataId has either disappeared from the cache or was newly added,\n        // so the result caching system would do well to \"forget everything it\n        // knows\" about that object. To achieve that kind of invalidation, we\n        // not only dirty the associated result cache entry, but also remove it\n        // completely from the dependency graph. For the optimism implementation\n        // details, see https://github.com/benjamn/optimism/pull/195.\n        storeFieldName === \"__exists\" ? \"forget\" : \"setDirty\"\n      );\n    }\n  }\n}\n\nfunction makeDepKey(dataId: string, storeFieldName: string) {\n  // Since field names cannot have '#' characters in them, this method\n  // of joining the field name and the ID should be unambiguous, and much\n  // cheaper than JSON.stringify([dataId, fieldName]).\n  return storeFieldName + \"#\" + dataId;\n}\n\nexport function maybeDependOnExistenceOfEntity(\n  store: NormalizedCache,\n  entityId: string\n) {\n  if (supportsResultCaching(store)) {\n    // We use this pseudo-field __exists elsewhere in the EntityStore code to\n    // represent changes in the existence of the entity object identified by\n    // entityId. This dependency gets reliably dirtied whenever an object with\n    // this ID is deleted (or newly created) within this group, so any result\n    // cache entries (for example, StoreReader#executeSelectionSet results) that\n    // depend on __exists for this entityId will get dirtied as well, leading to\n    // the eventual recomputation (instead of reuse) of those result objects the\n    // next time someone reads them from the cache.\n    store.group.depend(entityId, \"__exists\");\n  }\n}\n\nexport namespace EntityStore {\n  // Refer to this class as EntityStore.Root outside this namespace.\n  export class Root extends EntityStore {\n    constructor({\n      policies,\n      resultCaching = true,\n      seed,\n    }: {\n      policies: Policies;\n      resultCaching?: boolean;\n      seed?: NormalizedCacheObject;\n    }) {\n      super(policies, new CacheGroup(resultCaching));\n      if (seed) this.replace(seed);\n    }\n\n    public readonly stump = new Stump(this);\n\n    public addLayer(\n      layerId: string,\n      replay: (layer: EntityStore) => any\n    ): Layer {\n      // Adding an optimistic Layer on top of the Root actually adds the Layer\n      // on top of the Stump, so the Stump always comes between the Root and\n      // any Layer objects that we've added.\n      return this.stump.addLayer(layerId, replay);\n    }\n\n    public removeLayer(): Root {\n      // Never remove the root layer.\n      return this;\n    }\n\n    public readonly storageTrie = new Trie<StorageType>(canUseWeakMap);\n    public getStorage(): StorageType {\n      return this.storageTrie.lookupArray(arguments);\n    }\n  }\n}\n\n// Not exported, since all Layer instances are created by the addLayer method\n// of the EntityStore.Root class.\nclass Layer extends EntityStore {\n  constructor(\n    public readonly id: string,\n    public readonly parent: EntityStore,\n    public readonly replay: (layer: EntityStore) => any,\n    public readonly group: CacheGroup\n  ) {\n    super(parent.policies, group);\n    replay(this);\n  }\n\n  public addLayer(layerId: string, replay: (layer: EntityStore) => any): Layer {\n    return new Layer(layerId, this, replay, this.group);\n  }\n\n  public removeLayer(layerId: string): EntityStore {\n    // Remove all instances of the given id, not just the first one.\n    const parent = this.parent.removeLayer(layerId);\n\n    if (layerId === this.id) {\n      if (this.group.caching) {\n        // Dirty every ID we're removing. Technically we might be able to avoid\n        // dirtying fields that have values in higher layers, but we don't have\n        // easy access to higher layers here, and we're about to recreate those\n        // layers anyway (see parent.addLayer below).\n        Object.keys(this.data).forEach((dataId) => {\n          const ownStoreObject = this.data[dataId];\n          const parentStoreObject = parent[\"lookup\"](dataId);\n          if (!parentStoreObject) {\n            // The StoreObject identified by dataId was defined in this layer\n            // but will be undefined in the parent layer, so we can delete the\n            // whole entity using this.delete(dataId). Since we're about to\n            // throw this layer away, the only goal of this deletion is to dirty\n            // the removed fields.\n            this.delete(dataId);\n          } else if (!ownStoreObject) {\n            // This layer had an entry for dataId but it was undefined, which\n            // means the entity was deleted in this layer, and it's about to\n            // become undeleted when we remove this layer, so we need to dirty\n            // all fields that are about to be reexposed.\n            this.group.dirty(dataId, \"__exists\");\n            Object.keys(parentStoreObject).forEach((storeFieldName) => {\n              this.group.dirty(dataId, storeFieldName);\n            });\n          } else if (ownStoreObject !== parentStoreObject) {\n            // If ownStoreObject is not exactly the same as parentStoreObject,\n            // dirty any fields whose values will change as a result of this\n            // removal.\n            Object.keys(ownStoreObject).forEach((storeFieldName) => {\n              if (\n                !equal(\n                  ownStoreObject[storeFieldName],\n                  parentStoreObject[storeFieldName]\n                )\n              ) {\n                this.group.dirty(dataId, storeFieldName);\n              }\n            });\n          }\n        });\n      }\n\n      return parent;\n    }\n\n    // No changes are necessary if the parent chain remains identical.\n    if (parent === this.parent) return this;\n\n    // Recreate this layer on top of the new parent.\n    return parent.addLayer(this.id, this.replay);\n  }\n\n  public toObject(): NormalizedCacheObject {\n    return {\n      ...this.parent.toObject(),\n      ...this.data,\n    };\n  }\n\n  public findChildRefIds(dataId: string): Record<string, true> {\n    const fromParent = this.parent.findChildRefIds(dataId);\n    return hasOwn.call(this.data, dataId) ?\n        {\n          ...fromParent,\n          ...super.findChildRefIds(dataId),\n        }\n      : fromParent;\n  }\n\n  public getStorage(): StorageType {\n    let p: EntityStore = this.parent;\n    while ((p as Layer).parent) p = (p as Layer).parent;\n    return p.getStorage.apply(\n      p,\n      // @ts-expect-error\n      arguments\n    );\n  }\n}\n\n// Represents a Layer permanently installed just above the Root, which allows\n// reading optimistically (and registering optimistic dependencies) even when\n// no optimistic layers are currently active. The stump.group CacheGroup object\n// is shared by any/all Layer objects added on top of the Stump.\nclass Stump extends Layer {\n  constructor(root: EntityStore.Root) {\n    super(\n      \"EntityStore.Stump\",\n      root,\n      () => {},\n      new CacheGroup(root.group.caching, root.group)\n    );\n  }\n\n  public removeLayer() {\n    // Never remove the Stump layer.\n    return this;\n  }\n\n  public merge(older: string | StoreObject, newer: string | StoreObject) {\n    // We never want to write any data into the Stump, so we forward any merge\n    // calls to the Root instead. Another option here would be to throw an\n    // exception, but the toReference(object, true) function can sometimes\n    // trigger Stump writes (which used to be Root writes, before the Stump\n    // concept was introduced).\n    return this.parent.merge(older, newer);\n  }\n}\n\nfunction storeObjectReconciler(\n  existingObject: StoreObject,\n  incomingObject: StoreObject,\n  property: string | number\n): StoreValue {\n  const existingValue = existingObject[property];\n  const incomingValue = incomingObject[property];\n  // Wherever there is a key collision, prefer the incoming value, unless\n  // it is deeply equal to the existing value. It's worth checking deep\n  // equality here (even though blindly returning incoming would be\n  // logically correct) because preserving the referential identity of\n  // existing data can prevent needless rereading and rerendering.\n  return equal(existingValue, incomingValue) ? existingValue : incomingValue;\n}\n\nexport function supportsResultCaching(store: any): store is EntityStore {\n  // When result caching is disabled, store.depend will be null.\n  return !!(store instanceof EntityStore && store.group.caching);\n}\n", "import { Trie } from \"@wry/trie\";\nimport {\n  canUseWeakMap,\n  canUseWeakSet,\n  isNonNullObject as isObjectOrArray,\n} from \"../../utilities/index.js\";\nimport { isArray } from \"./helpers.js\";\n\nfunction shallowCopy<T>(value: T): T {\n  if (isObjectOrArray(value)) {\n    return isArray(value) ?\n        (value.slice(0) as any as T)\n      : { __proto__: Object.getPrototypeOf(value), ...value };\n  }\n  return value;\n}\n\n// When programmers talk about the \"canonical form\" of an object, they\n// usually have the following meaning in mind, which I've copied from\n// https://en.wiktionary.org/wiki/canonical_form:\n//\n// 1. A standard or normal presentation of a mathematical entity [or\n//    object]. A canonical form is an element of a set of representatives\n//    of equivalence classes of forms such that there is a function or\n//    procedure which projects every element of each equivalence class\n//    onto that one element, the canonical form of that equivalence\n//    class. The canonical form is expected to be simpler than the rest of\n//    the forms in some way.\n//\n// That's a long-winded way of saying any two objects that have the same\n// canonical form may be considered equivalent, even if they are !==,\n// which usually means the objects are structurally equivalent (deeply\n// equal), but don't necessarily use the same memory.\n//\n// Like a literary or musical canon, this ObjectCanon class represents a\n// collection of unique canonical items (JavaScript objects), with the\n// important property that canon.admit(a) === canon.admit(b) if a and b\n// are deeply equal to each other. In terms of the definition above, the\n// canon.admit method is the \"function or procedure which projects every\"\n// object \"onto that one element, the canonical form.\"\n//\n// In the worst case, the canonicalization process may involve looking at\n// every property in the provided object tree, so it takes the same order\n// of time as deep equality checking. Fortunately, already-canonicalized\n// objects are returned immediately from canon.admit, so the presence of\n// canonical subtrees tends to speed up canonicalization.\n//\n// Since consumers of canonical objects can check for deep equality in\n// constant time, canonicalizing cache results can massively improve the\n// performance of application code that skips re-rendering unchanged\n// results, such as \"pure\" UI components in a framework like React.\n//\n// Of course, since canonical objects may be shared widely between\n// unrelated consumers, it's important to think of them as immutable, even\n// though they are not actually frozen with Object.freeze in production,\n// due to the extra performance overhead that comes with frozen objects.\n//\n// Custom scalar objects whose internal class name is neither Array nor\n// Object can be included safely in the admitted tree, but they will not\n// be replaced with a canonical version (to put it another way, they are\n// assumed to be canonical already).\n//\n// If we ignore custom objects, no detection of cycles or repeated object\n// references is currently required by the StoreReader class, since\n// GraphQL result objects are JSON-serializable trees (and thus contain\n// neither cycles nor repeated subtrees), so we can avoid the complexity\n// of keeping track of objects we've already seen during the recursion of\n// the admit method.\n//\n// In the future, we may consider adding additional cases to the switch\n// statement to handle other common object types, such as \"[object Date]\"\n// objects, as needed.\nexport class ObjectCanon {\n  // Set of all canonical objects this ObjectCanon has admitted, allowing\n  // canon.admit to return previously-canonicalized objects immediately.\n  private known = new (canUseWeakSet ? WeakSet : Set)<object>();\n\n  // Efficient storage/lookup structure for canonical objects.\n  private pool = new Trie<{\n    array?: any[];\n    object?: Record<string, any>;\n    keys?: SortedKeysInfo;\n  }>(canUseWeakMap);\n\n  public isKnown(value: any): boolean {\n    return isObjectOrArray(value) && this.known.has(value);\n  }\n\n  // Make the ObjectCanon assume this value has already been\n  // canonicalized.\n  private passes = new WeakMap<object, object>();\n  public pass<T>(value: T): T;\n  public pass(value: any) {\n    if (isObjectOrArray(value)) {\n      const copy = shallowCopy(value);\n      this.passes.set(copy, value);\n      return copy;\n    }\n    return value;\n  }\n\n  // Returns the canonical version of value.\n  public admit<T>(value: T): T;\n  public admit(value: any) {\n    if (isObjectOrArray(value)) {\n      const original = this.passes.get(value);\n      if (original) return original;\n\n      const proto = Object.getPrototypeOf(value);\n      switch (proto) {\n        case Array.prototype: {\n          if (this.known.has(value)) return value;\n          const array: any[] = (value as any[]).map(this.admit, this);\n          // Arrays are looked up in the Trie using their recursively\n          // canonicalized elements, and the known version of the array is\n          // preserved as node.array.\n          const node = this.pool.lookupArray(array);\n          if (!node.array) {\n            this.known.add((node.array = array));\n            // Since canonical arrays may be shared widely between\n            // unrelated consumers, it's important to regard them as\n            // immutable, even if they are not frozen in production.\n            if (__DEV__) {\n              Object.freeze(array);\n            }\n          }\n          return node.array;\n        }\n\n        case null:\n        case Object.prototype: {\n          if (this.known.has(value)) return value;\n          const proto = Object.getPrototypeOf(value);\n          const array = [proto];\n          const keys = this.sortedKeys(value);\n          array.push(keys.json);\n          const firstValueIndex = array.length;\n          keys.sorted.forEach((key) => {\n            array.push(this.admit((value as any)[key]));\n          });\n          // Objects are looked up in the Trie by their prototype (which\n          // is *not* recursively canonicalized), followed by a JSON\n          // representation of their (sorted) keys, followed by the\n          // sequence of recursively canonicalized values corresponding to\n          // those keys. To keep the final results unambiguous with other\n          // sequences (such as arrays that just happen to contain [proto,\n          // keys.json, value1, value2, ...]), the known version of the\n          // object is stored as node.object.\n          const node = this.pool.lookupArray(array);\n          if (!node.object) {\n            const obj = (node.object = Object.create(proto));\n            this.known.add(obj);\n            keys.sorted.forEach((key, i) => {\n              obj[key] = array[firstValueIndex + i];\n            });\n            // Since canonical objects may be shared widely between\n            // unrelated consumers, it's important to regard them as\n            // immutable, even if they are not frozen in production.\n            if (__DEV__) {\n              Object.freeze(obj);\n            }\n          }\n          return node.object;\n        }\n      }\n    }\n    return value;\n  }\n\n  // It's worthwhile to cache the sorting of arrays of strings, since the\n  // same initial unsorted arrays tend to be encountered many times.\n  // Fortunately, we can reuse the Trie machinery to look up the sorted\n  // arrays in linear time (which is faster than sorting large arrays).\n  private sortedKeys(obj: object) {\n    const keys = Object.keys(obj);\n    const node = this.pool.lookupArray(keys);\n    if (!node.keys) {\n      keys.sort();\n      const json = JSON.stringify(keys);\n      if (!(node.keys = this.keysByJSON.get(json))) {\n        this.keysByJSON.set(json, (node.keys = { sorted: keys, json }));\n      }\n    }\n    return node.keys;\n  }\n  // Arrays that contain the same elements in a different order can share\n  // the same SortedKeysInfo object, to save memory.\n  private keysByJSON = new Map<string, SortedKeysInfo>();\n\n  // This has to come last because it depends on keysByJSON.\n  public readonly empty = this.admit({});\n}\n\ntype SortedKeysInfo = {\n  sorted: string[];\n  json: string;\n};\n", "import { invariant, newInvariantError } from \"../../utilities/globals/index.js\";\n\nimport type { DocumentNode, FieldNode, SelectionSetNode } from \"graphql\";\nimport { Kind } from \"graphql\";\nimport type { OptimisticWrapperFunction } from \"optimism\";\nimport { wrap } from \"optimism\";\n\nimport type {\n  Reference,\n  StoreObject,\n  FragmentMap,\n  FragmentMapFunction,\n} from \"../../utilities/index.js\";\nimport {\n  isField,\n  resultKeyNameFromField,\n  isReference,\n  makeReference,\n  shouldInclude,\n  addTypenameToDocument,\n  getDefaultValues,\n  getMainDefinition,\n  getQueryDefinition,\n  getFragmentFromSelection,\n  maybeDeepFreeze,\n  mergeDeepArray,\n  DeepMerger,\n  isNonNullObject,\n  canUseWeakMap,\n  compact,\n  canonicalStringify,\n  cacheSizes,\n  defaultCacheSizes,\n} from \"../../utilities/index.js\";\nimport type { Cache } from \"../core/types/Cache.js\";\nimport type {\n  DiffQueryAgainstStoreOptions,\n  InMemoryCacheConfig,\n  NormalizedCache,\n  ReadMergeModifyContext,\n} from \"./types.js\";\nimport {\n  maybeDependOnExistenceOfEntity,\n  supportsResultCaching,\n} from \"./entityStore.js\";\nimport {\n  isArray,\n  extractFragmentContext,\n  getTypenameFromStoreObject,\n  shouldCanonizeResults,\n} from \"./helpers.js\";\nimport type { Policies } from \"./policies.js\";\nimport type { InMemoryCache } from \"./inMemoryCache.js\";\nimport type { MissingTree } from \"../core/types/common.js\";\nimport { MissingFieldError } from \"../core/types/common.js\";\nimport { ObjectCanon } from \"./object-canon.js\";\n\nexport type VariableMap = { [name: string]: any };\n\ninterface ReadContext extends ReadMergeModifyContext {\n  query: DocumentNode;\n  policies: Policies;\n  canonizeResults: boolean;\n  fragmentMap: FragmentMap;\n  lookupFragment: FragmentMapFunction;\n}\n\nexport type ExecResult<R = any> = {\n  result: R;\n  missing?: MissingTree;\n};\n\ntype ExecSelectionSetOptions = {\n  selectionSet: SelectionSetNode;\n  objectOrReference: StoreObject | Reference;\n  enclosingRef: Reference;\n  context: ReadContext;\n};\n\ntype ExecSubSelectedArrayOptions = {\n  field: FieldNode;\n  array: readonly any[];\n  enclosingRef: Reference;\n  context: ReadContext;\n};\n\nexport interface StoreReaderConfig {\n  cache: InMemoryCache;\n  addTypename?: boolean;\n  resultCacheMaxSize?: number;\n  canonizeResults?: boolean;\n  canon?: ObjectCanon;\n  fragments?: InMemoryCacheConfig[\"fragments\"];\n}\n\n// Arguments type after keyArgs translation.\ntype ExecSelectionSetKeyArgs = [\n  SelectionSetNode,\n  StoreObject | Reference,\n  ReadMergeModifyContext,\n  boolean,\n];\n\nfunction execSelectionSetKeyArgs(\n  options: ExecSelectionSetOptions\n): ExecSelectionSetKeyArgs {\n  return [\n    options.selectionSet,\n    options.objectOrReference,\n    options.context,\n    // We split out this property so we can pass different values\n    // independently without modifying options.context itself.\n    options.context.canonizeResults,\n  ];\n}\n\nexport class StoreReader {\n  // cached version of executeSelectionSet\n  private executeSelectionSet: OptimisticWrapperFunction<\n    [ExecSelectionSetOptions], // Actual arguments tuple type.\n    ExecResult, // Actual return type.\n    ExecSelectionSetKeyArgs\n  >;\n\n  // cached version of executeSubSelectedArray\n  private executeSubSelectedArray: OptimisticWrapperFunction<\n    [ExecSubSelectedArrayOptions],\n    ExecResult<any>,\n    [ExecSubSelectedArrayOptions]\n  >;\n\n  private config: {\n    cache: InMemoryCache;\n    addTypename: boolean;\n    resultCacheMaxSize?: number;\n    canonizeResults: boolean;\n    fragments?: InMemoryCacheConfig[\"fragments\"];\n  };\n\n  private knownResults = new (canUseWeakMap ? WeakMap : Map)<\n    Record<string, any>,\n    SelectionSetNode\n  >();\n\n  public canon: ObjectCanon;\n  public resetCanon() {\n    this.canon = new ObjectCanon();\n  }\n\n  constructor(config: StoreReaderConfig) {\n    this.config = compact(config, {\n      addTypename: config.addTypename !== false,\n      canonizeResults: shouldCanonizeResults(config),\n    });\n\n    this.canon = config.canon || new ObjectCanon();\n\n    // memoized functions in this class will be \"garbage-collected\"\n    // by recreating the whole `StoreReader` in\n    // `InMemoryCache.resetResultsCache`\n    // (triggered from `InMemoryCache.gc` with `resetResultCache: true`)\n    this.executeSelectionSet = wrap(\n      (options) => {\n        const { canonizeResults } = options.context;\n\n        const peekArgs = execSelectionSetKeyArgs(options);\n\n        // Negate this boolean option so we can find out if we've already read\n        // this result using the other boolean value.\n        peekArgs[3] = !canonizeResults;\n\n        const other = this.executeSelectionSet.peek(...peekArgs);\n\n        if (other) {\n          if (canonizeResults) {\n            return {\n              ...other,\n              // If we previously read this result without canonizing it, we can\n              // reuse that result simply by canonizing it now.\n              result: this.canon.admit(other.result),\n            };\n          }\n          // If we previously read this result with canonization enabled, we can\n          // return that canonized result as-is.\n          return other;\n        }\n\n        maybeDependOnExistenceOfEntity(\n          options.context.store,\n          options.enclosingRef.__ref\n        );\n\n        // Finally, if we didn't find any useful previous results, run the real\n        // execSelectionSetImpl method with the given options.\n        return this.execSelectionSetImpl(options);\n      },\n      {\n        max:\n          this.config.resultCacheMaxSize ||\n          cacheSizes[\"inMemoryCache.executeSelectionSet\"] ||\n          defaultCacheSizes[\"inMemoryCache.executeSelectionSet\"],\n        keyArgs: execSelectionSetKeyArgs,\n        // Note that the parameters of makeCacheKey are determined by the\n        // array returned by keyArgs.\n        makeCacheKey(selectionSet, parent, context, canonizeResults) {\n          if (supportsResultCaching(context.store)) {\n            return context.store.makeCacheKey(\n              selectionSet,\n              isReference(parent) ? parent.__ref : parent,\n              context.varString,\n              canonizeResults\n            );\n          }\n        },\n      }\n    );\n\n    this.executeSubSelectedArray = wrap(\n      (options: ExecSubSelectedArrayOptions) => {\n        maybeDependOnExistenceOfEntity(\n          options.context.store,\n          options.enclosingRef.__ref\n        );\n        return this.execSubSelectedArrayImpl(options);\n      },\n      {\n        max:\n          this.config.resultCacheMaxSize ||\n          cacheSizes[\"inMemoryCache.executeSubSelectedArray\"] ||\n          defaultCacheSizes[\"inMemoryCache.executeSubSelectedArray\"],\n        makeCacheKey({ field, array, context }) {\n          if (supportsResultCaching(context.store)) {\n            return context.store.makeCacheKey(field, array, context.varString);\n          }\n        },\n      }\n    );\n  }\n\n  /**\n   * Given a store and a query, return as much of the result as possible and\n   * identify if any data was missing from the store.\n   */\n  public diffQueryAgainstStore<T>({\n    store,\n    query,\n    rootId = \"ROOT_QUERY\",\n    variables,\n    returnPartialData = true,\n    canonizeResults = this.config.canonizeResults,\n  }: DiffQueryAgainstStoreOptions): Cache.DiffResult<T> {\n    const policies = this.config.cache.policies;\n\n    variables = {\n      ...getDefaultValues(getQueryDefinition(query)),\n      ...variables!,\n    };\n\n    const rootRef = makeReference(rootId);\n    const execResult = this.executeSelectionSet({\n      selectionSet: getMainDefinition(query).selectionSet,\n      objectOrReference: rootRef,\n      enclosingRef: rootRef,\n      context: {\n        store,\n        query,\n        policies,\n        variables,\n        varString: canonicalStringify(variables),\n        canonizeResults,\n        ...extractFragmentContext(query, this.config.fragments),\n      },\n    });\n\n    let missing: MissingFieldError[] | undefined;\n    if (execResult.missing) {\n      // For backwards compatibility we still report an array of\n      // MissingFieldError objects, even though there will only ever be at most\n      // one of them, now that all missing field error messages are grouped\n      // together in the execResult.missing tree.\n      missing = [\n        new MissingFieldError(\n          firstMissing(execResult.missing)!,\n          execResult.missing,\n          query,\n          variables\n        ),\n      ];\n      if (!returnPartialData) {\n        throw missing[0];\n      }\n    }\n\n    return {\n      result: execResult.result,\n      complete: !missing,\n      missing,\n    };\n  }\n\n  public isFresh(\n    result: Record<string, any>,\n    parent: StoreObject | Reference,\n    selectionSet: SelectionSetNode,\n    context: ReadMergeModifyContext\n  ): boolean {\n    if (\n      supportsResultCaching(context.store) &&\n      this.knownResults.get(result) === selectionSet\n    ) {\n      const latest = this.executeSelectionSet.peek(\n        selectionSet,\n        parent,\n        context,\n        // If result is canonical, then it could only have been previously\n        // cached by the canonizing version of executeSelectionSet, so we can\n        // avoid checking both possibilities here.\n        this.canon.isKnown(result)\n      );\n      if (latest && result === latest.result) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  // Uncached version of executeSelectionSet.\n  private execSelectionSetImpl({\n    selectionSet,\n    objectOrReference,\n    enclosingRef,\n    context,\n  }: ExecSelectionSetOptions): ExecResult {\n    if (\n      isReference(objectOrReference) &&\n      !context.policies.rootTypenamesById[objectOrReference.__ref] &&\n      !context.store.has(objectOrReference.__ref)\n    ) {\n      return {\n        result: this.canon.empty,\n        missing: `Dangling reference to missing ${objectOrReference.__ref} object`,\n      };\n    }\n\n    const { variables, policies, store } = context;\n    const typename = store.getFieldValue<string>(\n      objectOrReference,\n      \"__typename\"\n    );\n\n    const objectsToMerge: Record<string, any>[] = [];\n    let missing: MissingTree | undefined;\n    const missingMerger = new DeepMerger();\n\n    if (\n      this.config.addTypename &&\n      typeof typename === \"string\" &&\n      !policies.rootIdsByTypename[typename]\n    ) {\n      // Ensure we always include a default value for the __typename\n      // field, if we have one, and this.config.addTypename is true. Note\n      // that this field can be overridden by other merged objects.\n      objectsToMerge.push({ __typename: typename });\n    }\n\n    function handleMissing<T>(result: ExecResult<T>, resultName: string): T {\n      if (result.missing) {\n        missing = missingMerger.merge(missing, {\n          [resultName]: result.missing,\n        });\n      }\n      return result.result;\n    }\n\n    const workSet = new Set(selectionSet.selections);\n\n    workSet.forEach((selection) => {\n      // Omit fields with directives @skip(if: <truthy value>) or\n      // @include(if: <falsy value>).\n      if (!shouldInclude(selection, variables)) return;\n\n      if (isField(selection)) {\n        let fieldValue = policies.readField(\n          {\n            fieldName: selection.name.value,\n            field: selection,\n            variables: context.variables,\n            from: objectOrReference,\n          },\n          context\n        );\n\n        const resultName = resultKeyNameFromField(selection);\n\n        if (fieldValue === void 0) {\n          if (!addTypenameToDocument.added(selection)) {\n            missing = missingMerger.merge(missing, {\n              [resultName]: `Can't find field '${selection.name.value}' on ${\n                isReference(objectOrReference) ?\n                  objectOrReference.__ref + \" object\"\n                : \"object \" + JSON.stringify(objectOrReference, null, 2)\n              }`,\n            });\n          }\n        } else if (isArray(fieldValue)) {\n          if (fieldValue.length > 0) {\n            fieldValue = handleMissing(\n              this.executeSubSelectedArray({\n                field: selection,\n                array: fieldValue,\n                enclosingRef,\n                context,\n              }),\n              resultName\n            );\n          }\n        } else if (!selection.selectionSet) {\n          // If the field does not have a selection set, then we handle it\n          // as a scalar value. To keep this.canon from canonicalizing\n          // this value, we use this.canon.pass to wrap fieldValue in a\n          // Pass object that this.canon.admit will later unwrap as-is.\n          if (context.canonizeResults) {\n            fieldValue = this.canon.pass(fieldValue);\n          }\n        } else if (fieldValue != null) {\n          // In this case, because we know the field has a selection set,\n          // it must be trying to query a GraphQLObjectType, which is why\n          // fieldValue must be != null.\n          fieldValue = handleMissing(\n            this.executeSelectionSet({\n              selectionSet: selection.selectionSet,\n              objectOrReference: fieldValue as StoreObject | Reference,\n              enclosingRef: isReference(fieldValue) ? fieldValue : enclosingRef,\n              context,\n            }),\n            resultName\n          );\n        }\n\n        if (fieldValue !== void 0) {\n          objectsToMerge.push({ [resultName]: fieldValue });\n        }\n      } else {\n        const fragment = getFragmentFromSelection(\n          selection,\n          context.lookupFragment\n        );\n\n        if (!fragment && selection.kind === Kind.FRAGMENT_SPREAD) {\n          throw newInvariantError(`No fragment named %s`, selection.name.value);\n        }\n\n        if (fragment && policies.fragmentMatches(fragment, typename)) {\n          fragment.selectionSet.selections.forEach(workSet.add, workSet);\n        }\n      }\n    });\n\n    const result = mergeDeepArray(objectsToMerge);\n    const finalResult: ExecResult = { result, missing };\n    const frozen =\n      context.canonizeResults ?\n        this.canon.admit(finalResult)\n        // Since this.canon is normally responsible for freezing results (only in\n        // development), freeze them manually if canonization is disabled.\n      : maybeDeepFreeze(finalResult);\n\n    // Store this result with its selection set so that we can quickly\n    // recognize it again in the StoreReader#isFresh method.\n    if (frozen.result) {\n      this.knownResults.set(frozen.result, selectionSet);\n    }\n\n    return frozen;\n  }\n\n  // Uncached version of executeSubSelectedArray.\n  private execSubSelectedArrayImpl({\n    field,\n    array,\n    enclosingRef,\n    context,\n  }: ExecSubSelectedArrayOptions): ExecResult {\n    let missing: MissingTree | undefined;\n    let missingMerger = new DeepMerger<MissingTree[]>();\n\n    function handleMissing<T>(childResult: ExecResult<T>, i: number): T {\n      if (childResult.missing) {\n        missing = missingMerger.merge(missing, { [i]: childResult.missing });\n      }\n      return childResult.result;\n    }\n\n    if (field.selectionSet) {\n      array = array.filter(context.store.canRead);\n    }\n\n    array = array.map((item, i) => {\n      // null value in array\n      if (item === null) {\n        return null;\n      }\n\n      // This is a nested array, recurse\n      if (isArray(item)) {\n        return handleMissing(\n          this.executeSubSelectedArray({\n            field,\n            array: item,\n            enclosingRef,\n            context,\n          }),\n          i\n        );\n      }\n\n      // This is an object, run the selection set on it\n      if (field.selectionSet) {\n        return handleMissing(\n          this.executeSelectionSet({\n            selectionSet: field.selectionSet,\n            objectOrReference: item,\n            enclosingRef: isReference(item) ? item : enclosingRef,\n            context,\n          }),\n          i\n        );\n      }\n\n      if (__DEV__) {\n        assertSelectionSetForIdValue(context.store, field, item);\n      }\n\n      return item;\n    });\n\n    return {\n      result: context.canonizeResults ? this.canon.admit(array) : array,\n      missing,\n    };\n  }\n}\n\nfunction firstMissing(tree: MissingTree): string | undefined {\n  try {\n    JSON.stringify(tree, (_, value) => {\n      if (typeof value === \"string\") throw value;\n      return value;\n    });\n  } catch (result) {\n    return result as string;\n  }\n}\n\nfunction assertSelectionSetForIdValue(\n  store: NormalizedCache,\n  field: FieldNode,\n  fieldValue: any\n) {\n  if (!field.selectionSet) {\n    const workSet = new Set([fieldValue]);\n    workSet.forEach((value) => {\n      if (isNonNullObject(value)) {\n        invariant(\n          !isReference(value),\n          `Missing selection set for object of type %s returned for query field %s`,\n          getTypenameFromStoreObject(store, value),\n          field.name.value\n        );\n        Object.values(value).forEach(workSet.add, workSet);\n      }\n    });\n  }\n}\n", "import type { OptimisticDependencyFunction } from \"optimism\";\nimport { dep, Slot } from \"optimism\";\nimport type { InMemoryCache } from \"./inMemoryCache.js\";\nimport type { ApolloCache } from \"../../core/index.js\";\n\nexport interface ReactiveVar<T> {\n  (newValue?: T): T;\n  onNextChange(listener: ReactiveListener<T>): () => void;\n  attachCache(cache: ApolloCache<any>): this;\n  forgetCache(cache: ApolloCache<any>): boolean;\n}\n\nexport type ReactiveListener<T> = (value: T) => any;\n\n// Contextual Slot that acquires its value when custom read functions are\n// called in Policies#readField.\nexport const cacheSlot = new Slot<ApolloCache<any>>();\n\nconst cacheInfoMap = new WeakMap<\n  ApolloCache<any>,\n  {\n    vars: Set<ReactiveVar<any>>;\n    dep: OptimisticDependencyFunction<ReactiveVar<any>>;\n  }\n>();\n\nfunction getCacheInfo(cache: ApolloCache<any>) {\n  let info = cacheInfoMap.get(cache)!;\n  if (!info) {\n    cacheInfoMap.set(\n      cache,\n      (info = {\n        vars: new Set(),\n        dep: dep(),\n      })\n    );\n  }\n  return info;\n}\n\nexport function forgetCache(cache: ApolloCache<any>) {\n  getCacheInfo(cache).vars.forEach((rv) => rv.forgetCache(cache));\n}\n\n// Calling forgetCache(cache) serves to silence broadcasts and allows the\n// cache to be garbage collected. However, the varsByCache WeakMap\n// preserves the set of reactive variables that were previously associated\n// with this cache, which makes it possible to \"recall\" the cache at a\n// later time, by reattaching it to those variables. If the cache has been\n// garbage collected in the meantime, because it is no longer reachable,\n// you won't be able to call recallCache(cache), and the cache will\n// automatically disappear from the varsByCache WeakMap.\nexport function recallCache(cache: ApolloCache<any>) {\n  getCacheInfo(cache).vars.forEach((rv) => rv.attachCache(cache));\n}\n\nexport function makeVar<T>(value: T): ReactiveVar<T> {\n  const caches = new Set<ApolloCache<any>>();\n  const listeners = new Set<ReactiveListener<T>>();\n\n  const rv: ReactiveVar<T> = function (newValue) {\n    if (arguments.length > 0) {\n      if (value !== newValue) {\n        value = newValue!;\n        caches.forEach((cache) => {\n          // Invalidate any fields with custom read functions that\n          // consumed this variable, so query results involving those\n          // fields will be recomputed the next time we read them.\n          getCacheInfo(cache).dep.dirty(rv);\n          // Broadcast changes to any caches that have previously read\n          // from this variable.\n          broadcast(cache);\n        });\n        // Finally, notify any listeners added via rv.onNextChange.\n        const oldListeners = Array.from(listeners);\n        listeners.clear();\n        oldListeners.forEach((listener) => listener(value));\n      }\n    } else {\n      // When reading from the variable, obtain the current cache from\n      // context via cacheSlot. This isn't entirely foolproof, but it's\n      // the same system that powers varDep.\n      const cache = cacheSlot.getValue();\n      if (cache) {\n        attach(cache);\n        getCacheInfo(cache).dep(rv);\n      }\n    }\n\n    return value;\n  };\n\n  rv.onNextChange = (listener) => {\n    listeners.add(listener);\n    return () => {\n      listeners.delete(listener);\n    };\n  };\n\n  const attach = (rv.attachCache = (cache) => {\n    caches.add(cache);\n    getCacheInfo(cache).vars.add(rv);\n    return rv;\n  });\n\n  rv.forgetCache = (cache) => caches.delete(cache);\n\n  return rv;\n}\n\ntype Broadcastable = ApolloCache<any> & {\n  // This method is protected in InMemoryCache, which we are ignoring, but\n  // we still want some semblance of type safety when we call it.\n  broadcastWatches?: InMemoryCache[\"broadcastWatches\"];\n};\n\nfunction broadcast(cache: Broadcastable) {\n  if (cache.broadcastWatches) {\n    cache.broadcastWatches();\n  }\n}\n", "import { invariant } from \"../../utilities/globals/index.js\";\n\nimport {\n  argumentsObjectFromField,\n  DeepMerger,\n  isNonEmptyArray,\n  isNonNullObject,\n} from \"../../utilities/index.js\";\n\nimport { hasOwn, isArray } from \"./helpers.js\";\nimport type {\n  KeySpecifier,\n  KeyFieldsFunction,\n  KeyArgsFunction,\n} from \"./policies.js\";\n\n// Mapping from JSON-encoded KeySpecifier strings to associated information.\nconst specifierInfoCache: Record<\n  string,\n  {\n    paths?: string[][];\n    keyFieldsFn?: KeyFieldsFunction;\n    keyArgsFn?: KeyArgsFunction;\n  }\n> = Object.create(null);\n\nfunction lookupSpecifierInfo(spec: KeySpecifier) {\n  // It's safe to encode KeySpecifier arrays with JSON.stringify, since they're\n  // just arrays of strings or nested KeySpecifier arrays, and the order of the\n  // array elements is important (and suitably preserved by JSON.stringify).\n  const cacheKey = JSON.stringify(spec);\n  return (\n    specifierInfoCache[cacheKey] ||\n    (specifierInfoCache[cacheKey] = Object.create(null))\n  );\n}\n\nexport function keyFieldsFnFromSpecifier(\n  specifier: KeySpecifier\n): KeyFieldsFunction {\n  const info = lookupSpecifierInfo(specifier);\n\n  return (\n    info.keyFieldsFn ||\n    (info.keyFieldsFn = (object, context) => {\n      const extract: typeof extractKey = (from, key) =>\n        context.readField(key, from);\n\n      const keyObject = (context.keyObject = collectSpecifierPaths(\n        specifier,\n        (schemaKeyPath) => {\n          let extracted = extractKeyPath(\n            context.storeObject,\n            schemaKeyPath,\n            // Using context.readField to extract paths from context.storeObject\n            // allows the extraction to see through Reference objects and respect\n            // custom read functions.\n            extract\n          );\n\n          if (\n            extracted === void 0 &&\n            object !== context.storeObject &&\n            hasOwn.call(object, schemaKeyPath[0])\n          ) {\n            // If context.storeObject fails to provide a value for the requested\n            // path, fall back to the raw result object, if it has a top-level key\n            // matching the first key in the path (schemaKeyPath[0]). This allows\n            // key fields included in the written data to be saved in the cache\n            // even if they are not selected explicitly in context.selectionSet.\n            // Not being mentioned by context.selectionSet is convenient here,\n            // since it means these extra fields cannot be affected by field\n            // aliasing, which is why we can use extractKey instead of\n            // context.readField for this extraction.\n            extracted = extractKeyPath(object, schemaKeyPath, extractKey);\n          }\n\n          invariant(\n            extracted !== void 0,\n            `Missing field '%s' while extracting keyFields from %s`,\n            schemaKeyPath.join(\".\"),\n            object\n          );\n\n          return extracted;\n        }\n      ));\n\n      return `${context.typename}:${JSON.stringify(keyObject)}`;\n    })\n  );\n}\n\n// The keyArgs extraction process is roughly analogous to keyFields extraction,\n// but there are no aliases involved, missing fields are tolerated (by merely\n// omitting them from the key), and drawing from field.directives or variables\n// is allowed (in addition to drawing from the field's arguments object).\n// Concretely, these differences mean passing a different key path extractor\n// function to collectSpecifierPaths, reusing the shared extractKeyPath helper\n// wherever possible.\nexport function keyArgsFnFromSpecifier(\n  specifier: KeySpecifier\n): KeyArgsFunction {\n  const info = lookupSpecifierInfo(specifier);\n\n  return (\n    info.keyArgsFn ||\n    (info.keyArgsFn = (args, { field, variables, fieldName }) => {\n      const collected = collectSpecifierPaths(specifier, (keyPath) => {\n        const firstKey = keyPath[0];\n        const firstChar = firstKey.charAt(0);\n\n        if (firstChar === \"@\") {\n          if (field && isNonEmptyArray(field.directives)) {\n            const directiveName = firstKey.slice(1);\n            // If the directive appears multiple times, only the first\n            // occurrence's arguments will be used. TODO Allow repetition?\n            // TODO Cache this work somehow, a la aliasMap?\n            const d = field.directives.find(\n              (d) => d.name.value === directiveName\n            );\n            // Fortunately argumentsObjectFromField works for DirectiveNode!\n            const directiveArgs = d && argumentsObjectFromField(d, variables);\n            // For directives without arguments (d defined, but directiveArgs ===\n            // null), the presence or absence of the directive still counts as\n            // part of the field key, so we return null in those cases. If no\n            // directive with this name was found for this field (d undefined and\n            // thus directiveArgs undefined), we return undefined, which causes\n            // this value to be omitted from the key object returned by\n            // collectSpecifierPaths.\n            return (\n              directiveArgs &&\n              extractKeyPath(\n                directiveArgs,\n                // If keyPath.length === 1, this code calls extractKeyPath with an\n                // empty path, which works because it uses directiveArgs as the\n                // extracted value.\n                keyPath.slice(1)\n              )\n            );\n          }\n          // If the key started with @ but there was no corresponding directive,\n          // we want to omit this value from the key object, not fall through to\n          // treating @whatever as a normal argument name.\n          return;\n        }\n\n        if (firstChar === \"$\") {\n          const variableName = firstKey.slice(1);\n          if (variables && hasOwn.call(variables, variableName)) {\n            const varKeyPath = keyPath.slice(0);\n            varKeyPath[0] = variableName;\n            return extractKeyPath(variables, varKeyPath);\n          }\n          // If the key started with $ but there was no corresponding variable, we\n          // want to omit this value from the key object, not fall through to\n          // treating $whatever as a normal argument name.\n          return;\n        }\n\n        if (args) {\n          return extractKeyPath(args, keyPath);\n        }\n      });\n\n      const suffix = JSON.stringify(collected);\n\n      // If no arguments were passed to this field, and it didn't have any other\n      // field key contributions from directives or variables, hide the empty\n      // :{} suffix from the field key. However, a field passed no arguments can\n      // still end up with a non-empty :{...} suffix if its key configuration\n      // refers to directives or variables.\n      if (args || suffix !== \"{}\") {\n        fieldName += \":\" + suffix;\n      }\n\n      return fieldName;\n    })\n  );\n}\n\nexport function collectSpecifierPaths(\n  specifier: KeySpecifier,\n  extractor: (path: string[]) => any\n): Record<string, any> {\n  // For each path specified by specifier, invoke the extractor, and repeatedly\n  // merge the results together, with appropriate ancestor context.\n  const merger = new DeepMerger();\n  return getSpecifierPaths(specifier).reduce((collected, path) => {\n    let toMerge = extractor(path);\n    if (toMerge !== void 0) {\n      // This path is not expected to contain array indexes, so the toMerge\n      // reconstruction will not contain arrays. TODO Fix this?\n      for (let i = path.length - 1; i >= 0; --i) {\n        toMerge = { [path[i]]: toMerge };\n      }\n      collected = merger.merge(collected, toMerge);\n    }\n    return collected;\n  }, Object.create(null));\n}\n\nexport function getSpecifierPaths(spec: KeySpecifier): string[][] {\n  const info = lookupSpecifierInfo(spec);\n\n  if (!info.paths) {\n    const paths: string[][] = (info.paths = []);\n    const currentPath: string[] = [];\n\n    spec.forEach((s, i) => {\n      if (isArray(s)) {\n        getSpecifierPaths(s).forEach((p) => paths.push(currentPath.concat(p)));\n        currentPath.length = 0;\n      } else {\n        currentPath.push(s);\n        if (!isArray(spec[i + 1])) {\n          paths.push(currentPath.slice(0));\n          currentPath.length = 0;\n        }\n      }\n    });\n  }\n\n  return info.paths!;\n}\n\nfunction extractKey<TObj extends Record<string, any>, TKey extends string>(\n  object: TObj,\n  key: TKey\n): TObj[TKey] | undefined {\n  return object[key];\n}\n\nexport function extractKeyPath(\n  object: Record<string, any>,\n  path: string[],\n  extract?: typeof extractKey\n): any {\n  // For each key in path, extract the corresponding child property from obj,\n  // flattening arrays if encountered (uncommon for keyFields and keyArgs, but\n  // possible). The final result of path.reduce is normalized so unexpected leaf\n  // objects have their keys safely sorted. That final result is difficult to\n  // type as anything other than any. You're welcome to try to improve the\n  // return type, but keep in mind extractKeyPath is not a public function\n  // (exported only for testing), so the effort may not be worthwhile unless the\n  // limited set of actual callers (see above) pass arguments that TypeScript\n  // can statically type. If we know only that path is some array of strings\n  // (and not, say, a specific tuple of statically known strings), any (or\n  // possibly unknown) is the honest answer.\n  extract = extract || extractKey;\n  return normalize(\n    path.reduce(function reducer(obj, key): any {\n      return isArray(obj) ?\n          obj.map((child) => reducer(child, key))\n        : obj && extract!(obj, key);\n    }, object)\n  );\n}\n\nfunction normalize<T>(value: T): T {\n  // Usually the extracted value will be a scalar value, since most primary\n  // key fields are scalar, but just in case we get an object or an array, we\n  // need to do some normalization of the order of (nested) keys.\n  if (isNonNullObject(value)) {\n    if (isArray(value)) {\n      return value.map(normalize) as any;\n    }\n    return collectSpecifierPaths(Object.keys(value).sort(), (path) =>\n      extractKeyPath(value, path)\n    ) as T;\n  }\n  return value;\n}\n", "import { invariant, newInvariantError } from \"../../utilities/globals/index.js\";\n\nimport type {\n  InlineFragmentNode,\n  FragmentDefinitionNode,\n  SelectionSetNode,\n  FieldNode,\n} from \"graphql\";\n\nimport type {\n  FragmentMap,\n  StoreValue,\n  StoreObject,\n  Reference,\n} from \"../../utilities/index.js\";\nimport {\n  storeKeyNameFromField,\n  argumentsObjectFromField,\n  isReference,\n  getStoreKeyName,\n  isNonNullObject,\n  stringifyForDisplay,\n} from \"../../utilities/index.js\";\nimport type {\n  IdGetter,\n  MergeInfo,\n  NormalizedCache,\n  ReadMergeModifyContext,\n} from \"./types.js\";\nimport {\n  hasOwn,\n  fieldNameFromStoreName,\n  storeValueIsStoreObject,\n  selectionSetMatchesResult,\n  TypeOrFieldNameRegExp,\n  defaultDataIdFromObject,\n  isArray,\n} from \"./helpers.js\";\nimport { cacheSlot } from \"./reactiveVars.js\";\nimport type { InMemoryCache } from \"./inMemoryCache.js\";\nimport type {\n  SafeReadonly,\n  FieldSpecifier,\n  ToReferenceFunction,\n  ReadFieldFunction,\n  ReadFieldOptions,\n  CanReadFunction,\n} from \"../core/types/common.js\";\nimport type { WriteContext } from \"./writeToStore.js\";\n\nimport {\n  keyArgsFnFromSpecifier,\n  keyFieldsFnFromSpecifier,\n} from \"./key-extractor.js\";\n\nexport type TypePolicies = {\n  [__typename: string]: TypePolicy;\n};\n\n// TypeScript 3.7 will allow recursive type aliases, so this should work:\n// type KeySpecifier = (string | KeySpecifier)[]\nexport type KeySpecifier = ReadonlyArray<string | KeySpecifier>;\n\nexport type KeyFieldsContext = {\n  // The __typename of the incoming object, even if the __typename field was\n  // aliased to another name in the raw result object. May be undefined when\n  // dataIdFromObject is called for objects without __typename fields.\n  typename: string | undefined;\n\n  // The object to be identified, after processing to remove aliases and\n  // normalize identifiable child objects with references.\n  storeObject: StoreObject;\n\n  // Handy tool for reading additional fields from context.storeObject, either\n  // readField(\"fieldName\") to read storeObject[fieldName], or readField(\"name\",\n  // objectOrReference) to read from another object or Reference. If you read a\n  // field with a read function, that function will be invoked.\n  readField: ReadFieldFunction;\n\n  // If you are writing a custom keyFields function, and you plan to use the raw\n  // result object passed as the first argument, you may also need access to the\n  // selection set and available fragments for this object, just in case any\n  // fields have aliases. Since this logic is tricky to get right, and these\n  // context properties are not even always provided (for example, they are\n  // omitted when calling cache.identify(object), where object is assumed to be\n  // a StoreObject), we recommend you use context.storeObject (which has already\n  // been de-aliased) and context.readField (which can read from references as\n  // well as objects) instead of the raw result object in your keyFields\n  // functions, or just rely on the internal implementation of keyFields:[...]\n  // syntax to get these details right for you.\n  selectionSet?: SelectionSetNode;\n  fragmentMap?: FragmentMap;\n\n  // Internal. May be set by the KeyFieldsFunction to report fields that were\n  // involved in computing the ID. Never passed in by the caller.\n  keyObject?: Record<string, any>;\n};\n\nexport type KeyFieldsFunction = (\n  object: Readonly<StoreObject>,\n  context: KeyFieldsContext\n) => KeySpecifier | false | ReturnType<IdGetter>;\n\ntype KeyFieldsResult = Exclude<ReturnType<KeyFieldsFunction>, KeySpecifier>;\n\n// TODO Should TypePolicy be a generic type, with a TObject or TEntity\n// type parameter?\nexport type TypePolicy = {\n  // Allows defining the primary key fields for this type, either using an\n  // array of field names or a function that returns an arbitrary string.\n  keyFields?: KeySpecifier | KeyFieldsFunction | false;\n\n  // Allows defining a merge function (or merge:true/false shorthand) to\n  // be used for merging objects of this type wherever they appear, unless\n  // the parent field also defines a merge function/boolean (that is,\n  // parent field merge functions take precedence over type policy merge\n  // functions). In many cases, defining merge:true for a given type\n  // policy can save you from specifying merge:true for all the field\n  // policies where that type might be encountered.\n  merge?: FieldMergeFunction | boolean;\n\n  // In the rare event that your schema happens to use a different\n  // __typename for the root Query, Mutation, and/or Schema types, you can\n  // express your deviant preferences by enabling one of these options.\n  queryType?: true;\n  mutationType?: true;\n  subscriptionType?: true;\n\n  fields?: {\n    [fieldName: string]: FieldPolicy<any> | FieldReadFunction<any>;\n  };\n};\n\nexport type KeyArgsFunction = (\n  args: Record<string, any> | null,\n  context: {\n    typename: string;\n    fieldName: string;\n    field: FieldNode | null;\n    variables?: Record<string, any>;\n  }\n) => KeySpecifier | false | ReturnType<IdGetter>;\n\nexport type FieldPolicy<\n  // The internal representation used to store the field's data in the\n  // cache. Must be JSON-serializable if you plan to serialize the result\n  // of cache.extract() using JSON.\n  TExisting = any,\n  // The type of the incoming parameter passed to the merge function,\n  // typically matching the GraphQL response format, but with Reference\n  // objects substituted for any identifiable child objects. Often the\n  // same as TExisting, but not necessarily.\n  TIncoming = TExisting,\n  // The type that the read function actually returns, using TExisting\n  // data and options.args as input. Usually the same as TIncoming.\n  TReadResult = TIncoming,\n  // Allows FieldFunctionOptions definition to be overwritten by the\n  // developer\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions,\n> = {\n  keyArgs?: KeySpecifier | KeyArgsFunction | false;\n  read?: FieldReadFunction<TExisting, TReadResult, TOptions>;\n  merge?: FieldMergeFunction<TExisting, TIncoming, TOptions> | boolean;\n};\n\nexport type StorageType = Record<string, any>;\n\nfunction argsFromFieldSpecifier(spec: FieldSpecifier) {\n  return (\n    spec.args !== void 0 ? spec.args\n    : spec.field ? argumentsObjectFromField(spec.field, spec.variables)\n    : null\n  );\n}\n\nexport interface FieldFunctionOptions<\n  TArgs = Record<string, any>,\n  TVars = Record<string, any>,\n> {\n  args: TArgs | null;\n\n  // The name of the field, equal to options.field.name.value when\n  // options.field is available. Useful if you reuse the same function for\n  // multiple fields, and you need to know which field you're currently\n  // processing. Always a string, even when options.field is null.\n  fieldName: string;\n\n  // The full field key used internally, including serialized key arguments.\n  storeFieldName: string;\n\n  // The FieldNode object used to read this field. Useful if you need to\n  // know about other attributes of the field, such as its directives. This\n  // option will be null when a string was passed to options.readField.\n  field: FieldNode | null;\n\n  variables?: TVars;\n\n  // Utilities for dealing with { __ref } objects.\n  isReference: typeof isReference;\n  toReference: ToReferenceFunction;\n\n  // A handy place to put field-specific data that you want to survive\n  // across multiple read function calls. Useful for field-level caching,\n  // if your read function does any expensive work.\n  storage: StorageType;\n\n  cache: InMemoryCache;\n\n  // Helper function for reading other fields within the current object.\n  // If a foreign object or reference is provided, the field will be read\n  // from that object instead of the current object, so this function can\n  // be used (together with isReference) to examine the cache outside the\n  // current object. If a FieldNode is passed instead of a string, and\n  // that FieldNode has arguments, the same options.variables will be used\n  // to compute the argument values. Note that this function will invoke\n  // custom read functions for other fields, if defined. Always returns\n  // immutable data (enforced with Object.freeze in development).\n  readField: ReadFieldFunction;\n\n  // Returns true for non-normalized StoreObjects and non-dangling\n  // References, indicating that readField(name, objOrRef) has a chance of\n  // working. Useful for filtering out dangling references from lists.\n  canRead: CanReadFunction;\n\n  // Instead of just merging objects with { ...existing, ...incoming }, this\n  // helper function can be used to merge objects in a way that respects any\n  // custom merge functions defined for their fields.\n  mergeObjects: MergeObjectsFunction;\n}\n\ntype MergeObjectsFunction = <T extends StoreObject | Reference>(\n  existing: T,\n  incoming: T\n) => T;\n\nexport type FieldReadFunction<\n  TExisting = any,\n  TReadResult = TExisting,\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions,\n> = (\n  // When reading a field, one often needs to know about any existing\n  // value stored for that field. If the field is read before any value\n  // has been written to the cache, this existing parameter will be\n  // undefined, which makes it easy to use a default parameter expression\n  // to supply the initial value. This parameter is positional (rather\n  // than one of the named options) because that makes it possible for the\n  // developer to annotate it with a type, without also having to provide\n  // a whole new type for the options object.\n  existing: SafeReadonly<TExisting> | undefined,\n  options: TOptions\n) => TReadResult | undefined;\n\nexport type FieldMergeFunction<\n  TExisting = any,\n  TIncoming = TExisting,\n  // Passing the whole FieldFunctionOptions makes the current definition\n  // independent from its implementation\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions,\n> = (\n  existing: SafeReadonly<TExisting> | undefined,\n  // The incoming parameter needs to be positional as well, for the same\n  // reasons discussed in FieldReadFunction above.\n  incoming: SafeReadonly<TIncoming>,\n  options: TOptions\n) => SafeReadonly<TExisting>;\n\nconst nullKeyFieldsFn: KeyFieldsFunction = () => void 0;\nconst simpleKeyArgsFn: KeyArgsFunction = (_args, context) => context.fieldName;\n\n// These merge functions can be selected by specifying merge:true or\n// merge:false in a field policy.\nconst mergeTrueFn: FieldMergeFunction<any> = (\n  existing,\n  incoming,\n  { mergeObjects }\n) => mergeObjects(existing, incoming);\nconst mergeFalseFn: FieldMergeFunction<any> = (_, incoming) => incoming;\n\nexport type PossibleTypesMap = {\n  [supertype: string]: string[];\n};\n\nexport class Policies {\n  private typePolicies: {\n    [__typename: string]: {\n      keyFn?: KeyFieldsFunction;\n      merge?: FieldMergeFunction<any>;\n      fields: {\n        [fieldName: string]: {\n          keyFn?: KeyArgsFunction;\n          read?: FieldReadFunction<any>;\n          merge?: FieldMergeFunction<any>;\n        };\n      };\n    };\n  } = Object.create(null);\n\n  private toBeAdded: {\n    [__typename: string]: TypePolicy[];\n  } = Object.create(null);\n\n  // Map from subtype names to sets of supertype names. Note that this\n  // representation inverts the structure of possibleTypes (whose keys are\n  // supertypes and whose values are arrays of subtypes) because it tends\n  // to be much more efficient to search upwards than downwards.\n  private supertypeMap = new Map<string, Set<string>>();\n\n  // Any fuzzy subtypes specified by possibleTypes will be converted to\n  // RegExp objects and recorded here. Every key of this map can also be\n  // found in supertypeMap. In many cases this Map will be empty, which\n  // means no fuzzy subtype checking will happen in fragmentMatches.\n  private fuzzySubtypes = new Map<string, RegExp>();\n\n  public readonly cache: InMemoryCache;\n\n  public readonly rootIdsByTypename: Record<string, string> =\n    Object.create(null);\n  public readonly rootTypenamesById: Record<string, string> =\n    Object.create(null);\n\n  public readonly usingPossibleTypes = false;\n\n  constructor(\n    private config: {\n      cache: InMemoryCache;\n      dataIdFromObject?: KeyFieldsFunction;\n      possibleTypes?: PossibleTypesMap;\n      typePolicies?: TypePolicies;\n    }\n  ) {\n    this.config = {\n      dataIdFromObject: defaultDataIdFromObject,\n      ...config,\n    };\n\n    this.cache = this.config.cache;\n\n    this.setRootTypename(\"Query\");\n    this.setRootTypename(\"Mutation\");\n    this.setRootTypename(\"Subscription\");\n\n    if (config.possibleTypes) {\n      this.addPossibleTypes(config.possibleTypes);\n    }\n\n    if (config.typePolicies) {\n      this.addTypePolicies(config.typePolicies);\n    }\n  }\n\n  public identify(\n    object: StoreObject,\n    partialContext?: Partial<KeyFieldsContext>\n  ): [string?, StoreObject?] {\n    const policies = this;\n\n    const typename =\n      (partialContext &&\n        (partialContext.typename || partialContext.storeObject?.__typename)) ||\n      object.__typename;\n\n    // It should be possible to write root Query fields with writeFragment,\n    // using { __typename: \"Query\", ... } as the data, but it does not make\n    // sense to allow the same identification behavior for the Mutation and\n    // Subscription types, since application code should never be writing\n    // directly to (or reading directly from) those root objects.\n    if (typename === this.rootTypenamesById.ROOT_QUERY) {\n      return [\"ROOT_QUERY\"];\n    }\n\n    // Default context.storeObject to object if not otherwise provided.\n    const storeObject =\n      (partialContext && partialContext.storeObject) || object;\n\n    const context: KeyFieldsContext = {\n      ...partialContext,\n      typename,\n      storeObject,\n      readField:\n        (partialContext && partialContext.readField) ||\n        function () {\n          const options = normalizeReadFieldOptions(arguments, storeObject);\n          return policies.readField(options, {\n            store: policies.cache[\"data\"],\n            variables: options.variables,\n          });\n        },\n    };\n\n    let id: KeyFieldsResult;\n\n    const policy = typename && this.getTypePolicy(typename);\n    let keyFn = (policy && policy.keyFn) || this.config.dataIdFromObject;\n    while (keyFn) {\n      const specifierOrId = keyFn({ ...object, ...storeObject }, context);\n      if (isArray(specifierOrId)) {\n        keyFn = keyFieldsFnFromSpecifier(specifierOrId);\n      } else {\n        id = specifierOrId;\n        break;\n      }\n    }\n\n    id = id ? String(id) : void 0;\n    return context.keyObject ? [id, context.keyObject] : [id];\n  }\n\n  public addTypePolicies(typePolicies: TypePolicies) {\n    Object.keys(typePolicies).forEach((typename) => {\n      const { queryType, mutationType, subscriptionType, ...incoming } =\n        typePolicies[typename];\n\n      // Though {query,mutation,subscription}Type configurations are rare,\n      // it's important to call setRootTypename as early as possible,\n      // since these configurations should apply consistently for the\n      // entire lifetime of the cache. Also, since only one __typename can\n      // qualify as one of these root types, these three properties cannot\n      // be inherited, unlike the rest of the incoming properties. That\n      // restriction is convenient, because the purpose of this.toBeAdded\n      // is to delay the processing of type/field policies until the first\n      // time they're used, allowing policies to be added in any order as\n      // long as all relevant policies (including policies for supertypes)\n      // have been added by the time a given policy is used for the first\n      // time. In other words, since inheritance doesn't matter for these\n      // properties, there's also no need to delay their processing using\n      // the this.toBeAdded queue.\n      if (queryType) this.setRootTypename(\"Query\", typename);\n      if (mutationType) this.setRootTypename(\"Mutation\", typename);\n      if (subscriptionType) this.setRootTypename(\"Subscription\", typename);\n\n      if (hasOwn.call(this.toBeAdded, typename)) {\n        this.toBeAdded[typename].push(incoming);\n      } else {\n        this.toBeAdded[typename] = [incoming];\n      }\n    });\n  }\n\n  private updateTypePolicy(typename: string, incoming: TypePolicy) {\n    const existing = this.getTypePolicy(typename);\n    const { keyFields, fields } = incoming;\n\n    function setMerge(\n      existing: { merge?: FieldMergeFunction | boolean },\n      merge?: FieldMergeFunction | boolean\n    ) {\n      existing.merge =\n        typeof merge === \"function\" ? merge\n          // Pass merge:true as a shorthand for a merge implementation\n          // that returns options.mergeObjects(existing, incoming).\n        : merge === true ? mergeTrueFn\n          // Pass merge:false to make incoming always replace existing\n          // without any warnings about data clobbering.\n        : merge === false ? mergeFalseFn\n        : existing.merge;\n    }\n\n    // Type policies can define merge functions, as an alternative to\n    // using field policies to merge child objects.\n    setMerge(existing, incoming.merge);\n\n    existing.keyFn =\n      // Pass false to disable normalization for this typename.\n      keyFields === false ? nullKeyFieldsFn\n        // Pass an array of strings to use those fields to compute a\n        // composite ID for objects of this typename.\n      : isArray(keyFields) ? keyFieldsFnFromSpecifier(keyFields)\n        // Pass a function to take full control over identification.\n      : typeof keyFields === \"function\" ? keyFields\n        // Leave existing.keyFn unchanged if above cases fail.\n      : existing.keyFn;\n\n    if (fields) {\n      Object.keys(fields).forEach((fieldName) => {\n        const existing = this.getFieldPolicy(typename, fieldName, true)!;\n        const incoming = fields[fieldName];\n\n        if (typeof incoming === \"function\") {\n          existing.read = incoming;\n        } else {\n          const { keyArgs, read, merge } = incoming;\n\n          existing.keyFn =\n            // Pass false to disable argument-based differentiation of\n            // field identities.\n            keyArgs === false ? simpleKeyArgsFn\n              // Pass an array of strings to use named arguments to\n              // compute a composite identity for the field.\n            : isArray(keyArgs) ? keyArgsFnFromSpecifier(keyArgs)\n              // Pass a function to take full control over field identity.\n            : typeof keyArgs === \"function\" ? keyArgs\n              // Leave existing.keyFn unchanged if above cases fail.\n            : existing.keyFn;\n\n          if (typeof read === \"function\") {\n            existing.read = read;\n          }\n\n          setMerge(existing, merge);\n        }\n\n        if (existing.read && existing.merge) {\n          // If we have both a read and a merge function, assume\n          // keyArgs:false, because read and merge together can take\n          // responsibility for interpreting arguments in and out. This\n          // default assumption can always be overridden by specifying\n          // keyArgs explicitly in the FieldPolicy.\n          existing.keyFn = existing.keyFn || simpleKeyArgsFn;\n        }\n      });\n    }\n  }\n\n  private setRootTypename(\n    which: \"Query\" | \"Mutation\" | \"Subscription\",\n    typename: string = which\n  ) {\n    const rootId = \"ROOT_\" + which.toUpperCase();\n    const old = this.rootTypenamesById[rootId];\n    if (typename !== old) {\n      invariant(\n        !old || old === which,\n        `Cannot change root %s __typename more than once`,\n        which\n      );\n      // First, delete any old __typename associated with this rootId from\n      // rootIdsByTypename.\n      if (old) delete this.rootIdsByTypename[old];\n      // Now make this the only __typename that maps to this rootId.\n      this.rootIdsByTypename[typename] = rootId;\n      // Finally, update the __typename associated with this rootId.\n      this.rootTypenamesById[rootId] = typename;\n    }\n  }\n\n  public addPossibleTypes(possibleTypes: PossibleTypesMap) {\n    (this.usingPossibleTypes as boolean) = true;\n    Object.keys(possibleTypes).forEach((supertype) => {\n      // Make sure all types have an entry in this.supertypeMap, even if\n      // their supertype set is empty, so we can return false immediately\n      // from policies.fragmentMatches for unknown supertypes.\n      this.getSupertypeSet(supertype, true);\n\n      possibleTypes[supertype].forEach((subtype) => {\n        this.getSupertypeSet(subtype, true)!.add(supertype);\n        const match = subtype.match(TypeOrFieldNameRegExp);\n        if (!match || match[0] !== subtype) {\n          // TODO Don't interpret just any invalid typename as a RegExp.\n          this.fuzzySubtypes.set(subtype, new RegExp(subtype));\n        }\n      });\n    });\n  }\n\n  private getTypePolicy(typename: string): Policies[\"typePolicies\"][string] {\n    if (!hasOwn.call(this.typePolicies, typename)) {\n      const policy: Policies[\"typePolicies\"][string] = (this.typePolicies[\n        typename\n      ] = Object.create(null));\n      policy.fields = Object.create(null);\n\n      // When the TypePolicy for typename is first accessed, instead of\n      // starting with an empty policy object, inherit any properties or\n      // fields from the type policies of the supertypes of typename.\n      //\n      // Any properties or fields defined explicitly within the TypePolicy\n      // for typename will take precedence, and if there are multiple\n      // supertypes, the properties of policies whose types were added\n      // later via addPossibleTypes will take precedence over those of\n      // earlier supertypes. TODO Perhaps we should warn about these\n      // conflicts in development, and recommend defining the property\n      // explicitly in the subtype policy?\n      //\n      // Field policy inheritance is atomic/shallow: you can't inherit a\n      // field policy and then override just its read function, since read\n      // and merge functions often need to cooperate, so changing only one\n      // of them would be a recipe for inconsistency.\n      //\n      // Once the TypePolicy for typename has been accessed, its properties can\n      // still be updated directly using addTypePolicies, but future changes to\n      // inherited supertype policies will not be reflected in this subtype\n      // policy, because this code runs at most once per typename.\n      let supertypes = this.supertypeMap.get(typename);\n      if (!supertypes && this.fuzzySubtypes.size) {\n        // To make the inheritance logic work for unknown typename strings that\n        // may have fuzzy supertypes, we give this typename an empty supertype\n        // set and then populate it with any fuzzy supertypes that match.\n        supertypes = this.getSupertypeSet(typename, true)!;\n        // This only works for typenames that are directly matched by a fuzzy\n        // supertype. What if there is an intermediate chain of supertypes?\n        // While possible, that situation can only be solved effectively by\n        // specifying the intermediate relationships via possibleTypes, manually\n        // and in a non-fuzzy way.\n        this.fuzzySubtypes.forEach((regExp, fuzzy) => {\n          if (regExp.test(typename)) {\n            // The fuzzy parameter is just the original string version of regExp\n            // (not a valid __typename string), but we can look up the\n            // associated supertype(s) in this.supertypeMap.\n            const fuzzySupertypes = this.supertypeMap.get(fuzzy);\n            if (fuzzySupertypes) {\n              fuzzySupertypes.forEach((supertype) =>\n                supertypes!.add(supertype)\n              );\n            }\n          }\n        });\n      }\n      if (supertypes && supertypes.size) {\n        supertypes.forEach((supertype) => {\n          const { fields, ...rest } = this.getTypePolicy(supertype);\n          Object.assign(policy, rest);\n          Object.assign(policy.fields, fields);\n        });\n      }\n    }\n\n    const inbox = this.toBeAdded[typename];\n    if (inbox && inbox.length) {\n      // Merge the pending policies into this.typePolicies, in the order they\n      // were originally passed to addTypePolicy.\n      inbox.splice(0).forEach((policy) => {\n        this.updateTypePolicy(typename, policy);\n      });\n    }\n\n    return this.typePolicies[typename];\n  }\n\n  private getFieldPolicy(\n    typename: string | undefined,\n    fieldName: string,\n    createIfMissing: boolean\n  ):\n    | {\n        keyFn?: KeyArgsFunction;\n        read?: FieldReadFunction<any>;\n        merge?: FieldMergeFunction<any>;\n      }\n    | undefined {\n    if (typename) {\n      const fieldPolicies = this.getTypePolicy(typename).fields;\n      return (\n        fieldPolicies[fieldName] ||\n        (createIfMissing && (fieldPolicies[fieldName] = Object.create(null)))\n      );\n    }\n  }\n\n  private getSupertypeSet(\n    subtype: string,\n    createIfMissing: boolean\n  ): Set<string> | undefined {\n    let supertypeSet = this.supertypeMap.get(subtype);\n    if (!supertypeSet && createIfMissing) {\n      this.supertypeMap.set(subtype, (supertypeSet = new Set<string>()));\n    }\n    return supertypeSet;\n  }\n\n  public fragmentMatches(\n    fragment: InlineFragmentNode | FragmentDefinitionNode,\n    typename: string | undefined,\n    result?: Record<string, any>,\n    variables?: Record<string, any>\n  ): boolean {\n    if (!fragment.typeCondition) return true;\n\n    // If the fragment has a type condition but the object we're matching\n    // against does not have a __typename, the fragment cannot match.\n    if (!typename) return false;\n\n    const supertype = fragment.typeCondition.name.value;\n    // Common case: fragment type condition and __typename are the same.\n    if (typename === supertype) return true;\n\n    if (this.usingPossibleTypes && this.supertypeMap.has(supertype)) {\n      const typenameSupertypeSet = this.getSupertypeSet(typename, true)!;\n      const workQueue = [typenameSupertypeSet];\n      const maybeEnqueue = (subtype: string) => {\n        const supertypeSet = this.getSupertypeSet(subtype, false);\n        if (\n          supertypeSet &&\n          supertypeSet.size &&\n          workQueue.indexOf(supertypeSet) < 0\n        ) {\n          workQueue.push(supertypeSet);\n        }\n      };\n\n      // We need to check fuzzy subtypes only if we encountered fuzzy\n      // subtype strings in addPossibleTypes, and only while writing to\n      // the cache, since that's when selectionSetMatchesResult gives a\n      // strong signal of fragment matching. The StoreReader class calls\n      // policies.fragmentMatches without passing a result object, so\n      // needToCheckFuzzySubtypes is always false while reading.\n      let needToCheckFuzzySubtypes = !!(result && this.fuzzySubtypes.size);\n      let checkingFuzzySubtypes = false;\n\n      // It's important to keep evaluating workQueue.length each time through\n      // the loop, because the queue can grow while we're iterating over it.\n      for (let i = 0; i < workQueue.length; ++i) {\n        const supertypeSet = workQueue[i];\n\n        if (supertypeSet.has(supertype)) {\n          if (!typenameSupertypeSet.has(supertype)) {\n            if (checkingFuzzySubtypes) {\n              invariant.warn(\n                `Inferring subtype %s of supertype %s`,\n                typename,\n                supertype\n              );\n            }\n            // Record positive results for faster future lookup.\n            // Unfortunately, we cannot safely cache negative results,\n            // because new possibleTypes data could always be added to the\n            // Policies class.\n            typenameSupertypeSet.add(supertype);\n          }\n          return true;\n        }\n\n        supertypeSet.forEach(maybeEnqueue);\n\n        if (\n          needToCheckFuzzySubtypes &&\n          // Start checking fuzzy subtypes only after exhausting all\n          // non-fuzzy subtypes (after the final iteration of the loop).\n          i === workQueue.length - 1 &&\n          // We could wait to compare fragment.selectionSet to result\n          // after we verify the supertype, but this check is often less\n          // expensive than that search, and we will have to do the\n          // comparison anyway whenever we find a potential match.\n          selectionSetMatchesResult(fragment.selectionSet, result!, variables)\n        ) {\n          // We don't always need to check fuzzy subtypes (if no result\n          // was provided, or !this.fuzzySubtypes.size), but, when we do,\n          // we only want to check them once.\n          needToCheckFuzzySubtypes = false;\n          checkingFuzzySubtypes = true;\n\n          // If we find any fuzzy subtypes that match typename, extend the\n          // workQueue to search through the supertypes of those fuzzy\n          // subtypes. Otherwise the for-loop will terminate and we'll\n          // return false below.\n          this.fuzzySubtypes.forEach((regExp, fuzzyString) => {\n            const match = typename.match(regExp);\n            if (match && match[0] === typename) {\n              maybeEnqueue(fuzzyString);\n            }\n          });\n        }\n      }\n    }\n\n    return false;\n  }\n\n  public hasKeyArgs(typename: string | undefined, fieldName: string) {\n    const policy = this.getFieldPolicy(typename, fieldName, false);\n    return !!(policy && policy.keyFn);\n  }\n\n  public getStoreFieldName(fieldSpec: FieldSpecifier): string {\n    const { typename, fieldName } = fieldSpec;\n    const policy = this.getFieldPolicy(typename, fieldName, false);\n    let storeFieldName: Exclude<ReturnType<KeyArgsFunction>, KeySpecifier>;\n\n    let keyFn = policy && policy.keyFn;\n    if (keyFn && typename) {\n      const context: Parameters<KeyArgsFunction>[1] = {\n        typename,\n        fieldName,\n        field: fieldSpec.field || null,\n        variables: fieldSpec.variables,\n      };\n      const args = argsFromFieldSpecifier(fieldSpec);\n      while (keyFn) {\n        const specifierOrString = keyFn(args, context);\n        if (isArray(specifierOrString)) {\n          keyFn = keyArgsFnFromSpecifier(specifierOrString);\n        } else {\n          // If the custom keyFn returns a falsy value, fall back to\n          // fieldName instead.\n          storeFieldName = specifierOrString || fieldName;\n          break;\n        }\n      }\n    }\n\n    if (storeFieldName === void 0) {\n      storeFieldName =\n        fieldSpec.field ?\n          storeKeyNameFromField(fieldSpec.field, fieldSpec.variables)\n        : getStoreKeyName(fieldName, argsFromFieldSpecifier(fieldSpec));\n    }\n\n    // Returning false from a keyArgs function is like configuring\n    // keyArgs: false, but more dynamic.\n    if (storeFieldName === false) {\n      return fieldName;\n    }\n\n    // Make sure custom field names start with the actual field.name.value\n    // of the field, so we can always figure out which properties of a\n    // StoreObject correspond to which original field names.\n    return fieldName === fieldNameFromStoreName(storeFieldName) ? storeFieldName\n      : fieldName + \":\" + storeFieldName;\n  }\n\n  public readField<V = StoreValue>(\n    options: ReadFieldOptions,\n    context: ReadMergeModifyContext\n  ): SafeReadonly<V> | undefined {\n    const objectOrReference = options.from;\n    if (!objectOrReference) return;\n\n    const nameOrField = options.field || options.fieldName;\n    if (!nameOrField) return;\n\n    if (options.typename === void 0) {\n      const typename = context.store.getFieldValue<string>(\n        objectOrReference,\n        \"__typename\"\n      );\n      if (typename) options.typename = typename;\n    }\n\n    const storeFieldName = this.getStoreFieldName(options);\n    const fieldName = fieldNameFromStoreName(storeFieldName);\n    const existing = context.store.getFieldValue<V>(\n      objectOrReference,\n      storeFieldName\n    );\n    const policy = this.getFieldPolicy(options.typename, fieldName, false);\n    const read = policy && policy.read;\n\n    if (read) {\n      const readOptions = makeFieldFunctionOptions(\n        this,\n        objectOrReference,\n        options,\n        context,\n        context.store.getStorage(\n          isReference(objectOrReference) ?\n            objectOrReference.__ref\n          : objectOrReference,\n          storeFieldName\n        )\n      );\n\n      // Call read(existing, readOptions) with cacheSlot holding this.cache.\n      return cacheSlot.withValue(this.cache, read, [\n        existing,\n        readOptions,\n      ]) as SafeReadonly<V>;\n    }\n\n    return existing;\n  }\n\n  public getReadFunction(\n    typename: string | undefined,\n    fieldName: string\n  ): FieldReadFunction | undefined {\n    const policy = this.getFieldPolicy(typename, fieldName, false);\n    return policy && policy.read;\n  }\n\n  public getMergeFunction(\n    parentTypename: string | undefined,\n    fieldName: string,\n    childTypename: string | undefined\n  ): FieldMergeFunction | undefined {\n    let policy:\n      | Policies[\"typePolicies\"][string]\n      | Policies[\"typePolicies\"][string][\"fields\"][string]\n      | undefined = this.getFieldPolicy(parentTypename, fieldName, false);\n    let merge = policy && policy.merge;\n    if (!merge && childTypename) {\n      policy = this.getTypePolicy(childTypename);\n      merge = policy && policy.merge;\n    }\n    return merge;\n  }\n\n  public runMergeFunction(\n    existing: StoreValue,\n    incoming: StoreValue,\n    { field, typename, merge }: MergeInfo,\n    context: WriteContext,\n    storage?: StorageType\n  ) {\n    if (merge === mergeTrueFn) {\n      // Instead of going to the trouble of creating a full\n      // FieldFunctionOptions object and calling mergeTrueFn, we can\n      // simply call mergeObjects, as mergeTrueFn would.\n      return makeMergeObjectsFunction(context.store)(\n        existing as StoreObject,\n        incoming as StoreObject\n      );\n    }\n\n    if (merge === mergeFalseFn) {\n      // Likewise for mergeFalseFn, whose implementation is even simpler.\n      return incoming;\n    }\n\n    // If cache.writeQuery or cache.writeFragment was called with\n    // options.overwrite set to true, we still call merge functions, but\n    // the existing data is always undefined, so the merge function will\n    // not attempt to combine the incoming data with the existing data.\n    if (context.overwrite) {\n      existing = void 0;\n    }\n\n    return merge(\n      existing,\n      incoming,\n      makeFieldFunctionOptions(\n        this,\n        // Unlike options.readField for read functions, we do not fall\n        // back to the current object if no foreignObjOrRef is provided,\n        // because it's not clear what the current object should be for\n        // merge functions: the (possibly undefined) existing object, or\n        // the incoming object? If you think your merge function needs\n        // to read sibling fields in order to produce a new value for\n        // the current field, you might want to rethink your strategy,\n        // because that's a recipe for making merge behavior sensitive\n        // to the order in which fields are written into the cache.\n        // However, readField(name, ref) is useful for merge functions\n        // that need to deduplicate child objects and references.\n        void 0,\n        {\n          typename,\n          fieldName: field.name.value,\n          field,\n          variables: context.variables,\n        },\n        context,\n        storage || Object.create(null)\n      )\n    );\n  }\n}\n\nfunction makeFieldFunctionOptions(\n  policies: Policies,\n  objectOrReference: StoreObject | Reference | undefined,\n  fieldSpec: FieldSpecifier,\n  context: ReadMergeModifyContext,\n  storage: StorageType\n): FieldFunctionOptions {\n  const storeFieldName = policies.getStoreFieldName(fieldSpec);\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const variables = fieldSpec.variables || context.variables;\n  const { toReference, canRead } = context.store;\n\n  return {\n    args: argsFromFieldSpecifier(fieldSpec),\n    field: fieldSpec.field || null,\n    fieldName,\n    storeFieldName,\n    variables,\n    isReference,\n    toReference,\n    storage,\n    cache: policies.cache,\n    canRead,\n    readField<T>() {\n      return policies.readField<T>(\n        normalizeReadFieldOptions(arguments, objectOrReference, variables),\n        context\n      );\n    },\n    mergeObjects: makeMergeObjectsFunction(context.store),\n  };\n}\n\nexport function normalizeReadFieldOptions(\n  readFieldArgs: IArguments,\n  objectOrReference: StoreObject | Reference | undefined,\n  variables?: ReadMergeModifyContext[\"variables\"]\n): ReadFieldOptions {\n  const { 0: fieldNameOrOptions, 1: from, length: argc } = readFieldArgs;\n\n  let options: ReadFieldOptions;\n\n  if (typeof fieldNameOrOptions === \"string\") {\n    options = {\n      fieldName: fieldNameOrOptions,\n      // Default to objectOrReference only when no second argument was\n      // passed for the from parameter, not when undefined is explicitly\n      // passed as the second argument.\n      from: argc > 1 ? from : objectOrReference,\n    };\n  } else {\n    options = { ...fieldNameOrOptions };\n    // Default to objectOrReference only when fieldNameOrOptions.from is\n    // actually omitted, rather than just undefined.\n    if (!hasOwn.call(options, \"from\")) {\n      options.from = objectOrReference;\n    }\n  }\n\n  if (__DEV__ && options.from === void 0) {\n    invariant.warn(\n      `Undefined 'from' passed to readField with arguments %s`,\n      stringifyForDisplay(Array.from(readFieldArgs))\n    );\n  }\n\n  if (void 0 === options.variables) {\n    options.variables = variables;\n  }\n\n  return options;\n}\n\nfunction makeMergeObjectsFunction(\n  store: NormalizedCache\n): MergeObjectsFunction {\n  return function mergeObjects(existing, incoming) {\n    if (isArray(existing) || isArray(incoming)) {\n      throw newInvariantError(\"Cannot automatically merge arrays\");\n    }\n\n    // These dynamic checks are necessary because the parameters of a\n    // custom merge function can easily have the any type, so the type\n    // system cannot always enforce the StoreObject | Reference parameter\n    // types of options.mergeObjects.\n    if (isNonNullObject(existing) && isNonNullObject(incoming)) {\n      const eType = store.getFieldValue(existing, \"__typename\");\n      const iType = store.getFieldValue(incoming, \"__typename\");\n      const typesDiffer = eType && iType && eType !== iType;\n\n      if (typesDiffer) {\n        return incoming;\n      }\n\n      if (isReference(existing) && storeValueIsStoreObject(incoming)) {\n        // Update the normalized EntityStore for the entity identified by\n        // existing.__ref, preferring/overwriting any fields contributed by the\n        // newer incoming StoreObject.\n        store.merge(existing.__ref, incoming);\n        return existing;\n      }\n\n      if (storeValueIsStoreObject(existing) && isReference(incoming)) {\n        // Update the normalized EntityStore for the entity identified by\n        // incoming.__ref, taking fields from the older existing object only if\n        // those fields are not already present in the newer StoreObject\n        // identified by incoming.__ref.\n        store.merge(existing, incoming.__ref);\n        return incoming;\n      }\n\n      if (\n        storeValueIsStoreObject(existing) &&\n        storeValueIsStoreObject(incoming)\n      ) {\n        return { ...existing, ...incoming };\n      }\n    }\n\n    return incoming;\n  };\n}\n", "import { invariant, newInvariantError } from \"../../utilities/globals/index.js\";\nimport { equal } from \"@wry/equality\";\nimport { Trie } from \"@wry/trie\";\nimport type { SelectionSetNode, FieldNode } from \"graphql\";\nimport { Kind } from \"graphql\";\n\nimport type {\n  FragmentMap,\n  FragmentMapFunction,\n  StoreValue,\n  StoreObject,\n  Reference,\n} from \"../../utilities/index.js\";\nimport {\n  getFragmentFromSelection,\n  getDefaultValues,\n  getOperationDefinition,\n  getTypenameFromResult,\n  makeReference,\n  isField,\n  resultKeyNameFromField,\n  isReference,\n  shouldInclude,\n  cloneDeep,\n  addTypenameToDocument,\n  isNonEmptyArray,\n  argumentsObjectFromField,\n  canonicalStringify,\n} from \"../../utilities/index.js\";\n\nimport type {\n  NormalizedCache,\n  ReadMergeModifyContext,\n  MergeTree,\n  InMemoryCacheConfig,\n} from \"./types.js\";\nimport {\n  isArray,\n  makeProcessedFieldsMerger,\n  fieldNameFromStoreName,\n  storeValueIsStoreObject,\n  extractFragmentContext,\n} from \"./helpers.js\";\nimport type { StoreReader } from \"./readFromStore.js\";\nimport type { InMemoryCache } from \"./inMemoryCache.js\";\nimport type { EntityStore } from \"./entityStore.js\";\nimport type { Cache } from \"../../core/index.js\";\nimport { normalizeReadFieldOptions } from \"./policies.js\";\nimport type { ReadFieldFunction } from \"../core/types/common.js\";\n\nexport interface WriteContext extends ReadMergeModifyContext {\n  readonly written: {\n    [dataId: string]: SelectionSetNode[];\n  };\n  readonly fragmentMap: FragmentMap;\n  lookupFragment: FragmentMapFunction;\n  // General-purpose deep-merge function for use during writes.\n  merge<T>(existing: T, incoming: T): T;\n  // If true, merge functions will be called with undefined existing data.\n  overwrite: boolean;\n  incomingById: Map<\n    string,\n    {\n      storeObject: StoreObject;\n      mergeTree?: MergeTree;\n      fieldNodeSet: Set<FieldNode>;\n    }\n  >;\n  // Directive metadata for @client and @defer. We could use a bitfield for this\n  // information to save some space, and use that bitfield number as the keys in\n  // the context.flavors Map.\n  clientOnly: boolean;\n  deferred: boolean;\n  flavors: Map<string, FlavorableWriteContext>;\n}\n\ntype FlavorableWriteContext = Pick<\n  WriteContext,\n  \"clientOnly\" | \"deferred\" | \"flavors\"\n>;\n\n// Since there are only four possible combinations of context.clientOnly and\n// context.deferred values, we should need at most four \"flavors\" of any given\n// WriteContext. To avoid creating multiple copies of the same context, we cache\n// the contexts in the context.flavors Map (shared by all flavors) according to\n// their clientOnly and deferred values (always in that order).\nfunction getContextFlavor<TContext extends FlavorableWriteContext>(\n  context: TContext,\n  clientOnly: TContext[\"clientOnly\"],\n  deferred: TContext[\"deferred\"]\n): TContext {\n  const key = `${clientOnly}${deferred}`;\n  let flavored = context.flavors.get(key);\n  if (!flavored) {\n    context.flavors.set(\n      key,\n      (flavored =\n        context.clientOnly === clientOnly && context.deferred === deferred ?\n          context\n        : {\n            ...context,\n            clientOnly,\n            deferred,\n          })\n    );\n  }\n  return flavored as TContext;\n}\n\ninterface ProcessSelectionSetOptions {\n  dataId?: string;\n  result: Record<string, any>;\n  selectionSet: SelectionSetNode;\n  context: WriteContext;\n  mergeTree: MergeTree;\n}\n\nexport class StoreWriter {\n  constructor(\n    public readonly cache: InMemoryCache,\n    private reader?: StoreReader,\n    private fragments?: InMemoryCacheConfig[\"fragments\"]\n  ) {}\n\n  public writeToStore(\n    store: NormalizedCache,\n    { query, result, dataId, variables, overwrite }: Cache.WriteOptions\n  ): Reference | undefined {\n    const operationDefinition = getOperationDefinition(query)!;\n    const merger = makeProcessedFieldsMerger();\n\n    variables = {\n      ...getDefaultValues(operationDefinition),\n      ...variables!,\n    };\n\n    const context: WriteContext = {\n      store,\n      written: Object.create(null),\n      merge<T>(existing: T, incoming: T) {\n        return merger.merge(existing, incoming) as T;\n      },\n      variables,\n      varString: canonicalStringify(variables),\n      ...extractFragmentContext(query, this.fragments),\n      overwrite: !!overwrite,\n      incomingById: new Map(),\n      clientOnly: false,\n      deferred: false,\n      flavors: new Map(),\n    };\n\n    const ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: { map: new Map() },\n      context,\n    });\n\n    if (!isReference(ref)) {\n      throw newInvariantError(`Could not identify object %s`, result);\n    }\n\n    // So far, the store has not been modified, so now it's time to process\n    // context.incomingById and merge those incoming fields into context.store.\n    context.incomingById.forEach(\n      ({ storeObject, mergeTree, fieldNodeSet }, dataId) => {\n        const entityRef = makeReference(dataId);\n\n        if (mergeTree && mergeTree.map.size) {\n          const applied = this.applyMerges(\n            mergeTree,\n            entityRef,\n            storeObject,\n            context\n          );\n          if (isReference(applied)) {\n            // Assume References returned by applyMerges have already been merged\n            // into the store. See makeMergeObjectsFunction in policies.ts for an\n            // example of how this can happen.\n            return;\n          }\n          // Otherwise, applyMerges returned a StoreObject, whose fields we should\n          // merge into the store (see store.merge statement below).\n          storeObject = applied;\n        }\n\n        if (__DEV__ && !context.overwrite) {\n          const fieldsWithSelectionSets: Record<string, true> =\n            Object.create(null);\n          fieldNodeSet.forEach((field) => {\n            if (field.selectionSet) {\n              fieldsWithSelectionSets[field.name.value] = true;\n            }\n          });\n\n          const hasSelectionSet = (storeFieldName: string) =>\n            fieldsWithSelectionSets[fieldNameFromStoreName(storeFieldName)] ===\n            true;\n\n          const hasMergeFunction = (storeFieldName: string) => {\n            const childTree = mergeTree && mergeTree.map.get(storeFieldName);\n            return Boolean(childTree && childTree.info && childTree.info.merge);\n          };\n\n          Object.keys(storeObject).forEach((storeFieldName) => {\n            // If a merge function was defined for this field, trust that it\n            // did the right thing about (not) clobbering data. If the field\n            // has no selection set, it's a scalar field, so it doesn't need\n            // a merge function (even if it's an object, like JSON data).\n            if (\n              hasSelectionSet(storeFieldName) &&\n              !hasMergeFunction(storeFieldName)\n            ) {\n              warnAboutDataLoss(\n                entityRef,\n                storeObject,\n                storeFieldName,\n                context.store\n              );\n            }\n          });\n        }\n\n        store.merge(dataId, storeObject);\n      }\n    );\n\n    // Any IDs written explicitly to the cache will be retained as\n    // reachable root IDs for garbage collection purposes. Although this\n    // logic includes root IDs like ROOT_QUERY and ROOT_MUTATION, their\n    // retainment counts are effectively ignored because cache.gc() always\n    // includes them in its root ID set.\n    store.retain(ref.__ref);\n\n    return ref;\n  }\n\n  private processSelectionSet({\n    dataId,\n    result,\n    selectionSet,\n    context,\n    // This object allows processSelectionSet to report useful information\n    // to its callers without explicitly returning that information.\n    mergeTree,\n  }: ProcessSelectionSetOptions): StoreObject | Reference {\n    const { policies } = this.cache;\n\n    // This variable will be repeatedly updated using context.merge to\n    // accumulate all fields that need to be written into the store.\n    let incoming: StoreObject = Object.create(null);\n\n    // If typename was not passed in, infer it. Note that typename is\n    // always passed in for tricky-to-infer cases such as \"Query\" for\n    // ROOT_QUERY.\n    const typename: string | undefined =\n      (dataId && policies.rootTypenamesById[dataId]) ||\n      getTypenameFromResult(result, selectionSet, context.fragmentMap) ||\n      (dataId && (context.store.get(dataId, \"__typename\") as string));\n\n    if (\"string\" === typeof typename) {\n      incoming.__typename = typename;\n    }\n\n    // This readField function will be passed as context.readField in the\n    // KeyFieldsContext object created within policies.identify (called below).\n    // In addition to reading from the existing context.store (thanks to the\n    // policies.readField(options, context) line at the very bottom), this\n    // version of readField can read from Reference objects that are currently\n    // pending in context.incomingById, which is important whenever keyFields\n    // need to be extracted from a child object that processSelectionSet has\n    // turned into a Reference.\n    const readField: ReadFieldFunction = function (this: void) {\n      const options = normalizeReadFieldOptions(\n        arguments,\n        incoming,\n        context.variables\n      );\n\n      if (isReference(options.from)) {\n        const info = context.incomingById.get(options.from.__ref);\n        if (info) {\n          const result = policies.readField(\n            {\n              ...options,\n              from: info.storeObject,\n            },\n            context\n          );\n\n          if (result !== void 0) {\n            return result;\n          }\n        }\n      }\n\n      return policies.readField(options, context);\n    };\n\n    const fieldNodeSet = new Set<FieldNode>();\n\n    this.flattenFields(\n      selectionSet,\n      result,\n      // This WriteContext will be the default context value for fields returned\n      // by the flattenFields method, but some fields may be assigned a modified\n      // context, depending on the presence of @client and other directives.\n      context,\n      typename\n    ).forEach((context, field) => {\n      const resultFieldKey = resultKeyNameFromField(field);\n      const value = result[resultFieldKey];\n\n      fieldNodeSet.add(field);\n\n      if (value !== void 0) {\n        const storeFieldName = policies.getStoreFieldName({\n          typename,\n          fieldName: field.name.value,\n          field,\n          variables: context.variables,\n        });\n\n        const childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n        let incomingValue = this.processFieldValue(\n          value,\n          field,\n          // Reset context.clientOnly and context.deferred to their default\n          // values before processing nested selection sets.\n          field.selectionSet ?\n            getContextFlavor(context, false, false)\n          : context,\n          childTree\n        );\n\n        // To determine if this field holds a child object with a merge function\n        // defined in its type policy (see PR #7070), we need to figure out the\n        // child object's __typename.\n        let childTypename: string | undefined;\n\n        // The field's value can be an object that has a __typename only if the\n        // field has a selection set. Otherwise incomingValue is scalar.\n        if (\n          field.selectionSet &&\n          (isReference(incomingValue) || storeValueIsStoreObject(incomingValue))\n        ) {\n          childTypename = readField<string>(\"__typename\", incomingValue);\n        }\n\n        const merge = policies.getMergeFunction(\n          typename,\n          field.name.value,\n          childTypename\n        );\n\n        if (merge) {\n          childTree.info = {\n            // TODO Check compatibility against any existing childTree.field?\n            field,\n            typename,\n            merge,\n          };\n        } else {\n          maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n        }\n\n        incoming = context.merge(incoming, {\n          [storeFieldName]: incomingValue,\n        });\n      } else if (\n        __DEV__ &&\n        !context.clientOnly &&\n        !context.deferred &&\n        !addTypenameToDocument.added(field) &&\n        // If the field has a read function, it may be a synthetic field or\n        // provide a default value, so its absence from the written data should\n        // not be cause for alarm.\n        !policies.getReadFunction(typename, field.name.value)\n      ) {\n        invariant.error(\n          `Missing field '%s' while writing result %o`,\n          resultKeyNameFromField(field),\n          result\n        );\n      }\n    });\n\n    // Identify the result object, even if dataId was already provided,\n    // since we always need keyObject below.\n    try {\n      const [id, keyObject] = policies.identify(result, {\n        typename,\n        selectionSet,\n        fragmentMap: context.fragmentMap,\n        storeObject: incoming,\n        readField,\n      });\n\n      // If dataId was not provided, fall back to the id just generated by\n      // policies.identify.\n      dataId = dataId || id;\n\n      // Write any key fields that were used during identification, even if\n      // they were not mentioned in the original query.\n      if (keyObject) {\n        // TODO Reverse the order of the arguments?\n        incoming = context.merge(incoming, keyObject);\n      }\n    } catch (e) {\n      // If dataId was provided, tolerate failure of policies.identify.\n      if (!dataId) throw e;\n    }\n\n    if (\"string\" === typeof dataId) {\n      const dataRef = makeReference(dataId);\n\n      // Avoid processing the same entity object using the same selection\n      // set more than once. We use an array instead of a Set since most\n      // entity IDs will be written using only one selection set, so the\n      // size of this array is likely to be very small, meaning indexOf is\n      // likely to be faster than Set.prototype.has.\n      const sets = context.written[dataId] || (context.written[dataId] = []);\n      if (sets.indexOf(selectionSet) >= 0) return dataRef;\n      sets.push(selectionSet);\n\n      // If we're about to write a result object into the store, but we\n      // happen to know that the exact same (===) result object would be\n      // returned if we were to reread the result with the same inputs,\n      // then we can skip the rest of the processSelectionSet work for\n      // this object, and immediately return a Reference to it.\n      if (\n        this.reader &&\n        this.reader.isFresh(result, dataRef, selectionSet, context)\n      ) {\n        return dataRef;\n      }\n\n      const previous = context.incomingById.get(dataId);\n      if (previous) {\n        previous.storeObject = context.merge(previous.storeObject, incoming);\n        previous.mergeTree = mergeMergeTrees(previous.mergeTree, mergeTree);\n        fieldNodeSet.forEach((field) => previous.fieldNodeSet.add(field));\n      } else {\n        context.incomingById.set(dataId, {\n          storeObject: incoming,\n          // Save a reference to mergeTree only if it is not empty, because\n          // empty MergeTrees may be recycled by maybeRecycleChildMergeTree and\n          // reused for entirely different parts of the result tree.\n          mergeTree: mergeTreeIsEmpty(mergeTree) ? void 0 : mergeTree,\n          fieldNodeSet,\n        });\n      }\n\n      return dataRef;\n    }\n\n    return incoming;\n  }\n\n  private processFieldValue(\n    value: any,\n    field: FieldNode,\n    context: WriteContext,\n    mergeTree: MergeTree\n  ): StoreValue {\n    if (!field.selectionSet || value === null) {\n      // In development, we need to clone scalar values so that they can be\n      // safely frozen with maybeDeepFreeze in readFromStore.ts. In production,\n      // it's cheaper to store the scalar values directly in the cache.\n      return __DEV__ ? cloneDeep(value) : value;\n    }\n\n    if (isArray(value)) {\n      return value.map((item, i) => {\n        const value = this.processFieldValue(\n          item,\n          field,\n          context,\n          getChildMergeTree(mergeTree, i)\n        );\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context,\n      mergeTree,\n    });\n  }\n\n  // Implements https://spec.graphql.org/draft/#sec-Field-Collection, but with\n  // some additions for tracking @client and @defer directives.\n  private flattenFields<\n    TContext extends Pick<\n      WriteContext,\n      | \"clientOnly\"\n      | \"deferred\"\n      | \"flavors\"\n      | \"fragmentMap\"\n      | \"lookupFragment\"\n      | \"variables\"\n    >,\n  >(\n    selectionSet: SelectionSetNode,\n    result: Record<string, any>,\n    context: TContext,\n    typename = getTypenameFromResult(result, selectionSet, context.fragmentMap)\n  ): Map<FieldNode, TContext> {\n    const fieldMap = new Map<FieldNode, TContext>();\n    const { policies } = this.cache;\n\n    const limitingTrie = new Trie<{\n      // Tracks whether (selectionSet, clientOnly, deferred) has been flattened\n      // before. The GraphQL specification only uses the fragment name for\n      // skipping previously visited fragments, but the top-level fragment\n      // selection set corresponds 1:1 with the fagment name (and is slightly\n      // easier too work with), and we need to consider clientOnly and deferred\n      // values as well, potentially revisiting selection sets that were\n      // previously visited with different inherited configurations of those\n      // directives.\n      visited?: boolean;\n    }>(false); // No need for WeakMap, since limitingTrie does not escape.\n\n    (function flatten(\n      this: void,\n      selectionSet: SelectionSetNode,\n      inheritedContext: TContext\n    ) {\n      const visitedNode = limitingTrie.lookup(\n        selectionSet,\n        // Because we take inheritedClientOnly and inheritedDeferred into\n        // consideration here (in addition to selectionSet), it's possible for\n        // the same selection set to be flattened more than once, if it appears\n        // in the query with different @client and/or @directive configurations.\n        inheritedContext.clientOnly,\n        inheritedContext.deferred\n      );\n      if (visitedNode.visited) return;\n      visitedNode.visited = true;\n\n      selectionSet.selections.forEach((selection) => {\n        if (!shouldInclude(selection, context.variables)) return;\n\n        let { clientOnly, deferred } = inheritedContext;\n        if (\n          // Since the presence of @client or @defer on this field can only\n          // cause clientOnly or deferred to become true, we can skip the\n          // forEach loop if both clientOnly and deferred are already true.\n          !(clientOnly && deferred) &&\n          isNonEmptyArray(selection.directives)\n        ) {\n          selection.directives.forEach((dir) => {\n            const name = dir.name.value;\n            if (name === \"client\") clientOnly = true;\n            if (name === \"defer\") {\n              const args = argumentsObjectFromField(dir, context.variables);\n              // The @defer directive takes an optional args.if boolean\n              // argument, similar to @include(if: boolean). Note that\n              // @defer(if: false) does not make context.deferred false, but\n              // instead behaves as if there was no @defer directive.\n              if (!args || (args as { if?: boolean }).if !== false) {\n                deferred = true;\n              }\n              // TODO In the future, we may want to record args.label using\n              // context.deferred, if a label is specified.\n            }\n          });\n        }\n\n        if (isField(selection)) {\n          const existing = fieldMap.get(selection);\n          if (existing) {\n            // If this field has been visited along another recursive path\n            // before, the final context should have clientOnly or deferred set\n            // to true only if *all* paths have the directive (hence the &&).\n            clientOnly = clientOnly && existing.clientOnly;\n            deferred = deferred && existing.deferred;\n          }\n\n          fieldMap.set(\n            selection,\n            getContextFlavor(context, clientOnly, deferred)\n          );\n        } else {\n          const fragment = getFragmentFromSelection(\n            selection,\n            context.lookupFragment\n          );\n\n          if (!fragment && selection.kind === Kind.FRAGMENT_SPREAD) {\n            throw newInvariantError(\n              `No fragment named %s`,\n              selection.name.value\n            );\n          }\n\n          if (\n            fragment &&\n            policies.fragmentMatches(\n              fragment,\n              typename,\n              result,\n              context.variables\n            )\n          ) {\n            flatten(\n              fragment.selectionSet,\n              getContextFlavor(context, clientOnly, deferred)\n            );\n          }\n        }\n      });\n    })(selectionSet, context);\n\n    return fieldMap;\n  }\n\n  private applyMerges<T extends StoreValue>(\n    mergeTree: MergeTree,\n    existing: StoreValue,\n    incoming: T,\n    context: WriteContext,\n    getStorageArgs?: Parameters<EntityStore[\"getStorage\"]>\n  ): T | Reference {\n    if (mergeTree.map.size && !isReference(incoming)) {\n      const e: StoreObject | Reference | undefined =\n        // Items in the same position in different arrays are not\n        // necessarily related to each other, so when incoming is an array\n        // we process its elements as if there was no existing data.\n        (\n          !isArray(incoming) &&\n          // Likewise, existing must be either a Reference or a StoreObject\n          // in order for its fields to be safe to merge with the fields of\n          // the incoming object.\n          (isReference(existing) || storeValueIsStoreObject(existing))\n        ) ?\n          existing\n        : void 0;\n\n      // This narrowing is implied by mergeTree.map.size > 0 and\n      // !isReference(incoming), though TypeScript understandably cannot\n      // hope to infer this type.\n      const i = incoming as StoreObject | StoreValue[];\n\n      // The options.storage objects provided to read and merge functions\n      // are derived from the identity of the parent object plus a\n      // sequence of storeFieldName strings/numbers identifying the nested\n      // field name path of each field value to be merged.\n      if (e && !getStorageArgs) {\n        getStorageArgs = [isReference(e) ? e.__ref : e];\n      }\n\n      // It's possible that applying merge functions to this subtree will\n      // not change the incoming data, so this variable tracks the fields\n      // that did change, so we can create a new incoming object when (and\n      // only when) at least one incoming field has changed. We use a Map\n      // to preserve the type of numeric keys.\n      let changedFields: Map<string | number, StoreValue> | undefined;\n\n      const getValue = (\n        from: typeof e | typeof i,\n        name: string | number\n      ): StoreValue => {\n        return (\n          isArray(from) ?\n            typeof name === \"number\" ?\n              from[name]\n            : void 0\n          : context.store.getFieldValue(from, String(name))\n        );\n      };\n\n      mergeTree.map.forEach((childTree, storeFieldName) => {\n        const eVal = getValue(e, storeFieldName);\n        const iVal = getValue(i, storeFieldName);\n        // If we have no incoming data, leave any existing data untouched.\n        if (void 0 === iVal) return;\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n        const aVal = this.applyMerges(\n          childTree,\n          eVal,\n          iVal,\n          context,\n          getStorageArgs\n        );\n        if (aVal !== iVal) {\n          changedFields = changedFields || new Map();\n          changedFields.set(storeFieldName, aVal);\n        }\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields) {\n        // Shallow clone i so we can add changed fields to it.\n        incoming = (isArray(i) ? i.slice(0) : { ...i }) as T;\n        changedFields.forEach((value, name) => {\n          (incoming as any)[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(\n        existing,\n        incoming,\n        mergeTree.info,\n        context,\n        getStorageArgs && context.store.getStorage(...getStorageArgs)\n      );\n    }\n\n    return incoming;\n  }\n}\n\nconst emptyMergeTreePool: MergeTree[] = [];\n\nfunction getChildMergeTree(\n  { map }: MergeTree,\n  name: string | number\n): MergeTree {\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || { map: new Map() });\n  }\n  return map.get(name)!;\n}\n\nfunction mergeMergeTrees(\n  left: MergeTree | undefined,\n  right: MergeTree | undefined\n): MergeTree {\n  if (left === right || !right || mergeTreeIsEmpty(right)) return left!;\n  if (!left || mergeTreeIsEmpty(left)) return right;\n\n  const info =\n    left.info && right.info ?\n      {\n        ...left.info,\n        ...right.info,\n      }\n    : left.info || right.info;\n\n  const needToMergeMaps = left.map.size && right.map.size;\n  const map =\n    needToMergeMaps ? new Map()\n    : left.map.size ? left.map\n    : right.map;\n\n  const merged = { info, map };\n\n  if (needToMergeMaps) {\n    const remainingRightKeys = new Set(right.map.keys());\n\n    left.map.forEach((leftTree, key) => {\n      merged.map.set(key, mergeMergeTrees(leftTree, right.map.get(key)));\n      remainingRightKeys.delete(key);\n    });\n\n    remainingRightKeys.forEach((key) => {\n      merged.map.set(\n        key,\n        mergeMergeTrees(right.map.get(key), left.map.get(key))\n      );\n    });\n  }\n\n  return merged;\n}\n\nfunction mergeTreeIsEmpty(tree: MergeTree | undefined): boolean {\n  return !tree || !(tree.info || tree.map.size);\n}\n\nfunction maybeRecycleChildMergeTree({ map }: MergeTree, name: string | number) {\n  const childTree = map.get(name);\n  if (childTree && mergeTreeIsEmpty(childTree)) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nconst warnings = new Set<string>();\n\n// Note that this function is unused in production, and thus should be\n// pruned by any well-configured minifier.\nfunction warnAboutDataLoss(\n  existingRef: Reference,\n  incomingObj: StoreObject,\n  storeFieldName: string,\n  store: NormalizedCache\n) {\n  const getChild = (objOrRef: StoreObject | Reference): StoreObject | false => {\n    const child = store.getFieldValue<StoreObject>(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  const existing = getChild(existingRef);\n  if (!existing) return;\n\n  const incoming = getChild(incomingObj);\n  if (!incoming) return;\n\n  // It's always safe to replace a reference, since it refers to data\n  // safely stored elsewhere.\n  if (isReference(existing)) return;\n\n  // If the values are structurally equivalent, we do not need to worry\n  // about incoming replacing existing.\n  if (equal(existing, incoming)) return;\n\n  // If we're replacing every key of the existing object, then the\n  // existing data would be overwritten even if the objects were\n  // normalized, so warning would not be helpful here.\n  if (\n    Object.keys(existing).every(\n      (key) => store.getFieldValue(incoming, key) !== void 0\n    )\n  ) {\n    return;\n  }\n\n  const parentType =\n    store.getFieldValue<string>(existingRef, \"__typename\") ||\n    store.getFieldValue<string>(incomingObj, \"__typename\");\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const typeDotName = `${parentType}.${fieldName}`;\n  // Avoid warning more than once for the same type and field name.\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n\n  const childTypenames: string[] = [];\n  // Arrays do not have __typename fields, and always need a custom merge\n  // function, even if their elements are normalized entities.\n  if (!isArray(existing) && !isArray(incoming)) {\n    [existing, incoming].forEach((child) => {\n      const typename = store.getFieldValue(child, \"__typename\");\n      if (typeof typename === \"string\" && !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  invariant.warn(\n    `Cache data may be lost when replacing the %s field of a %s object.\n\nThis could cause additional (usually avoidable) network requests to fetch data that were otherwise cached.\n\nTo address this problem (which is not a bug in Apollo Client), %sdefine a custom merge function for the %s field, so InMemoryCache can safely merge these objects:\n\n  existing: %o\n  incoming: %o\n\nFor more information about these options, please refer to the documentation:\n\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\n`,\n    fieldName,\n    parentType,\n    childTypenames.length ?\n      \"either ensure all objects of type \" +\n        childTypenames.join(\" and \") +\n        \" have an ID or a custom merge function, or \"\n    : \"\",\n    typeDotName,\n    { ...existing },\n    { ...incoming }\n  );\n}\n", "import { invariant } from \"../../utilities/globals/index.js\";\n\n// Make builtins like Map and Set safe to use with non-extensible objects.\nimport \"./fixPolyfills.js\";\n\nimport type { DocumentNode } from \"graphql\";\nimport type { OptimisticWrapperFunction } from \"optimism\";\nimport { wrap } from \"optimism\";\nimport { equal } from \"@wry/equality\";\n\nimport { ApolloCache } from \"../core/cache.js\";\nimport type { Cache } from \"../core/types/Cache.js\";\nimport { MissingFieldError } from \"../core/types/common.js\";\nimport type { StoreObject, Reference } from \"../../utilities/index.js\";\nimport {\n  addTypenameToDocument,\n  isReference,\n  DocumentTransform,\n  canonicalStringify,\n  print,\n  cacheSizes,\n  defaultCacheSizes,\n} from \"../../utilities/index.js\";\nimport type { InMemoryCacheConfig, NormalizedCacheObject } from \"./types.js\";\nimport { StoreReader } from \"./readFromStore.js\";\nimport { StoreWriter } from \"./writeToStore.js\";\nimport { EntityStore, supportsResultCaching } from \"./entityStore.js\";\nimport { makeVar, forgetCache, recallCache } from \"./reactiveVars.js\";\nimport { Policies } from \"./policies.js\";\nimport { hasOwn, normalizeConfig, shouldCanonizeResults } from \"./helpers.js\";\nimport type { OperationVariables } from \"../../core/index.js\";\nimport { getInMemoryCacheMemoryInternals } from \"../../utilities/caching/getMemoryInternals.js\";\n\ntype BroadcastOptions = Pick<\n  Cache.BatchOptions<InMemoryCache>,\n  \"optimistic\" | \"onWatchUpdated\"\n>;\n\nexport class InMemoryCache extends ApolloCache<NormalizedCacheObject> {\n  private data!: EntityStore;\n  private optimisticData!: EntityStore;\n\n  protected config: InMemoryCacheConfig;\n  private watches = new Set<Cache.WatchOptions>();\n  private addTypename: boolean;\n\n  private storeReader!: StoreReader;\n  private storeWriter!: StoreWriter;\n  private addTypenameTransform = new DocumentTransform(addTypenameToDocument);\n\n  private maybeBroadcastWatch!: OptimisticWrapperFunction<\n    [Cache.WatchOptions, BroadcastOptions?],\n    any,\n    [Cache.WatchOptions]\n  >;\n\n  // Override the default value, since InMemoryCache result objects are frozen\n  // in development and expected to remain logically immutable in production.\n  public readonly assumeImmutableResults = true;\n\n  // Dynamically imported code can augment existing typePolicies or\n  // possibleTypes by calling cache.policies.addTypePolicies or\n  // cache.policies.addPossibletypes.\n  public readonly policies: Policies;\n\n  public readonly makeVar = makeVar;\n\n  constructor(config: InMemoryCacheConfig = {}) {\n    super();\n    this.config = normalizeConfig(config);\n    this.addTypename = !!this.config.addTypename;\n\n    this.policies = new Policies({\n      cache: this,\n      dataIdFromObject: this.config.dataIdFromObject,\n      possibleTypes: this.config.possibleTypes,\n      typePolicies: this.config.typePolicies,\n    });\n\n    this.init();\n  }\n\n  private init() {\n    // Passing { resultCaching: false } in the InMemoryCache constructor options\n    // will completely disable dependency tracking, which will improve memory\n    // usage but worsen the performance of repeated reads.\n    const rootStore = (this.data = new EntityStore.Root({\n      policies: this.policies,\n      resultCaching: this.config.resultCaching,\n    }));\n\n    // When no optimistic writes are currently active, cache.optimisticData ===\n    // cache.data, so there are no additional layers on top of the actual data.\n    // When an optimistic update happens, this.optimisticData will become a\n    // linked list of EntityStore Layer objects that terminates with the\n    // original this.data cache object.\n    this.optimisticData = rootStore.stump;\n\n    this.resetResultCache();\n  }\n\n  private resetResultCache(resetResultIdentities?: boolean) {\n    const previousReader = this.storeReader;\n    const { fragments } = this.config;\n\n    // The StoreWriter is mostly stateless and so doesn't really need to be\n    // reset, but it does need to have its writer.storeReader reference updated,\n    // so it's simpler to update this.storeWriter as well.\n    this.storeWriter = new StoreWriter(\n      this,\n      (this.storeReader = new StoreReader({\n        cache: this,\n        addTypename: this.addTypename,\n        resultCacheMaxSize: this.config.resultCacheMaxSize,\n        canonizeResults: shouldCanonizeResults(this.config),\n        canon:\n          resetResultIdentities ? void 0 : (\n            previousReader && previousReader.canon\n          ),\n        fragments,\n      })),\n      fragments\n    );\n\n    this.maybeBroadcastWatch = wrap(\n      (c: Cache.WatchOptions, options?: BroadcastOptions) => {\n        return this.broadcastWatch(c, options);\n      },\n      {\n        max:\n          this.config.resultCacheMaxSize ||\n          cacheSizes[\"inMemoryCache.maybeBroadcastWatch\"] ||\n          defaultCacheSizes[\"inMemoryCache.maybeBroadcastWatch\"],\n        makeCacheKey: (c: Cache.WatchOptions) => {\n          // Return a cache key (thus enabling result caching) only if we're\n          // currently using a data store that can track cache dependencies.\n          const store = c.optimistic ? this.optimisticData : this.data;\n          if (supportsResultCaching(store)) {\n            const { optimistic, id, variables } = c;\n            return store.makeCacheKey(\n              c.query,\n              // Different watches can have the same query, optimistic\n              // status, rootId, and variables, but if their callbacks are\n              // different, the (identical) result needs to be delivered to\n              // each distinct callback. The easiest way to achieve that\n              // separation is to include c.callback in the cache key for\n              // maybeBroadcastWatch calls. See issue #5733.\n              c.callback,\n              canonicalStringify({ optimistic, id, variables })\n            );\n          }\n        },\n      }\n    );\n\n    // Since we have thrown away all the cached functions that depend on the\n    // CacheGroup dependencies maintained by EntityStore, we should also reset\n    // all CacheGroup dependency information.\n    new Set([this.data.group, this.optimisticData.group]).forEach((group) =>\n      group.resetCaching()\n    );\n  }\n\n  public restore(data: NormalizedCacheObject): this {\n    this.init();\n    // Since calling this.init() discards/replaces the entire StoreReader, along\n    // with the result caches it maintains, this.data.replace(data) won't have\n    // to bother deleting the old data.\n    if (data) this.data.replace(data);\n    return this;\n  }\n\n  public extract(optimistic: boolean = false): NormalizedCacheObject {\n    return (optimistic ? this.optimisticData : this.data).extract();\n  }\n\n  public read<T>(options: Cache.ReadOptions): T | null {\n    const {\n      // Since read returns data or null, without any additional metadata\n      // about whether/where there might have been missing fields, the\n      // default behavior cannot be returnPartialData = true (like it is\n      // for the diff method), since defaulting to true would violate the\n      // integrity of the T in the return type. However, partial data may\n      // be useful in some cases, so returnPartialData:true may be\n      // specified explicitly.\n      returnPartialData = false,\n    } = options;\n    try {\n      return (\n        this.storeReader.diffQueryAgainstStore<T>({\n          ...options,\n          store: options.optimistic ? this.optimisticData : this.data,\n          config: this.config,\n          returnPartialData,\n        }).result || null\n      );\n    } catch (e) {\n      if (e instanceof MissingFieldError) {\n        // Swallow MissingFieldError and return null, so callers do not need to\n        // worry about catching \"normal\" exceptions resulting from incomplete\n        // cache data. Unexpected errors will be re-thrown. If you need more\n        // information about which fields were missing, use cache.diff instead,\n        // and examine diffResult.missing.\n        return null;\n      }\n      throw e;\n    }\n  }\n\n  public write(options: Cache.WriteOptions): Reference | undefined {\n    try {\n      ++this.txCount;\n      return this.storeWriter.writeToStore(this.data, options);\n    } finally {\n      if (!--this.txCount && options.broadcast !== false) {\n        this.broadcastWatches();\n      }\n    }\n  }\n\n  public modify<Entity extends Record<string, any> = Record<string, any>>(\n    options: Cache.ModifyOptions<Entity>\n  ): boolean {\n    if (hasOwn.call(options, \"id\") && !options.id) {\n      // To my knowledge, TypeScript does not currently provide a way to\n      // enforce that an optional property?:type must *not* be undefined\n      // when present. That ability would be useful here, because we want\n      // options.id to default to ROOT_QUERY only when no options.id was\n      // provided. If the caller attempts to pass options.id with a\n      // falsy/undefined value (perhaps because cache.identify failed), we\n      // should not assume the goal was to modify the ROOT_QUERY object.\n      // We could throw, but it seems natural to return false to indicate\n      // that nothing was modified.\n      return false;\n    }\n    const store =\n      (\n        options.optimistic // Defaults to false.\n      ) ?\n        this.optimisticData\n      : this.data;\n    try {\n      ++this.txCount;\n      return store.modify(options.id || \"ROOT_QUERY\", options.fields);\n    } finally {\n      if (!--this.txCount && options.broadcast !== false) {\n        this.broadcastWatches();\n      }\n    }\n  }\n\n  public diff<TData, TVariables extends OperationVariables = any>(\n    options: Cache.DiffOptions<TData, TVariables>\n  ): Cache.DiffResult<TData> {\n    return this.storeReader.diffQueryAgainstStore({\n      ...options,\n      store: options.optimistic ? this.optimisticData : this.data,\n      rootId: options.id || \"ROOT_QUERY\",\n      config: this.config,\n    });\n  }\n\n  public watch<TData = any, TVariables = any>(\n    watch: Cache.WatchOptions<TData, TVariables>\n  ): () => void {\n    if (!this.watches.size) {\n      // In case we previously called forgetCache(this) because\n      // this.watches became empty (see below), reattach this cache to any\n      // reactive variables on which it previously depended. It might seem\n      // paradoxical that we're able to recall something we supposedly\n      // forgot, but the point of calling forgetCache(this) is to silence\n      // useless broadcasts while this.watches is empty, and to allow the\n      // cache to be garbage collected. If, however, we manage to call\n      // recallCache(this) here, this cache object must not have been\n      // garbage collected yet, and should resume receiving updates from\n      // reactive variables, now that it has a watcher to notify.\n      recallCache(this);\n    }\n    this.watches.add(watch);\n    if (watch.immediate) {\n      this.maybeBroadcastWatch(watch);\n    }\n    return () => {\n      // Once we remove the last watch from this.watches, cache.broadcastWatches\n      // no longer does anything, so we preemptively tell the reactive variable\n      // system to exclude this cache from future broadcasts.\n      if (this.watches.delete(watch) && !this.watches.size) {\n        forgetCache(this);\n      }\n      // Remove this watch from the LRU cache managed by the\n      // maybeBroadcastWatch OptimisticWrapperFunction, to prevent memory\n      // leaks involving the closure of watch.callback.\n      this.maybeBroadcastWatch.forget(watch);\n    };\n  }\n\n  public gc(options?: {\n    // If true, also free non-essential result cache memory by bulk-releasing\n    // this.{store{Reader,Writer},maybeBroadcastWatch}. Defaults to false.\n    resetResultCache?: boolean;\n    // If resetResultCache is true, this.storeReader.canon will be preserved by\n    // default, but can also be discarded by passing resetResultIdentities:true.\n    // Defaults to false.\n    resetResultIdentities?: boolean;\n  }) {\n    canonicalStringify.reset();\n    print.reset();\n    this.addTypenameTransform.resetCache();\n    this.config.fragments?.resetCaches();\n    const ids = this.optimisticData.gc();\n    if (options && !this.txCount) {\n      if (options.resetResultCache) {\n        this.resetResultCache(options.resetResultIdentities);\n      } else if (options.resetResultIdentities) {\n        this.storeReader.resetCanon();\n      }\n    }\n    return ids;\n  }\n\n  // Call this method to ensure the given root ID remains in the cache after\n  // garbage collection, along with its transitive child entities. Note that\n  // the cache automatically retains all directly written entities. By default,\n  // the retainment persists after optimistic updates are removed. Pass true\n  // for the optimistic argument if you would prefer for the retainment to be\n  // discarded when the top-most optimistic layer is removed. Returns the\n  // resulting (non-negative) retainment count.\n  public retain(rootId: string, optimistic?: boolean): number {\n    return (optimistic ? this.optimisticData : this.data).retain(rootId);\n  }\n\n  // Call this method to undo the effect of the retain method, above. Once the\n  // retainment count falls to zero, the given ID will no longer be preserved\n  // during garbage collection, though it may still be preserved by other safe\n  // entities that refer to it. Returns the resulting (non-negative) retainment\n  // count, in case that's useful.\n  public release(rootId: string, optimistic?: boolean): number {\n    return (optimistic ? this.optimisticData : this.data).release(rootId);\n  }\n\n  // Returns the canonical ID for a given StoreObject, obeying typePolicies\n  // and keyFields (and dataIdFromObject, if you still use that). At minimum,\n  // the object must contain a __typename and any primary key fields required\n  // to identify entities of that type. If you pass a query result object, be\n  // sure that none of the primary key fields have been renamed by aliasing.\n  // If you pass a Reference object, its __ref ID string will be returned.\n  public identify(object: StoreObject | Reference): string | undefined {\n    if (isReference(object)) return object.__ref;\n    try {\n      return this.policies.identify(object)[0];\n    } catch (e) {\n      invariant.warn(e);\n    }\n  }\n\n  public evict(options: Cache.EvictOptions): boolean {\n    if (!options.id) {\n      if (hasOwn.call(options, \"id\")) {\n        // See comment in modify method about why we return false when\n        // options.id exists but is falsy/undefined.\n        return false;\n      }\n      options = { ...options, id: \"ROOT_QUERY\" };\n    }\n    try {\n      // It's unlikely that the eviction will end up invoking any other\n      // cache update operations while it's running, but {in,de}crementing\n      // this.txCount still seems like a good idea, for uniformity with\n      // the other update methods.\n      ++this.txCount;\n      // Pass this.data as a limit on the depth of the eviction, so evictions\n      // during optimistic updates (when this.data is temporarily set equal to\n      // this.optimisticData) do not escape their optimistic Layer.\n      return this.optimisticData.evict(options, this.data);\n    } finally {\n      if (!--this.txCount && options.broadcast !== false) {\n        this.broadcastWatches();\n      }\n    }\n  }\n\n  public reset(options?: Cache.ResetOptions): Promise<void> {\n    this.init();\n\n    canonicalStringify.reset();\n\n    if (options && options.discardWatches) {\n      // Similar to what happens in the unsubscribe function returned by\n      // cache.watch, applied to all current watches.\n      this.watches.forEach((watch) => this.maybeBroadcastWatch.forget(watch));\n      this.watches.clear();\n      forgetCache(this);\n    } else {\n      // Calling this.init() above unblocks all maybeBroadcastWatch caching, so\n      // this.broadcastWatches() triggers a broadcast to every current watcher\n      // (letting them know their data is now missing). This default behavior is\n      // convenient because it means the watches do not have to be manually\n      // reestablished after resetting the cache. To prevent this broadcast and\n      // cancel all watches, pass true for options.discardWatches.\n      this.broadcastWatches();\n    }\n\n    return Promise.resolve();\n  }\n\n  public removeOptimistic(idToRemove: string) {\n    const newOptimisticData = this.optimisticData.removeLayer(idToRemove);\n    if (newOptimisticData !== this.optimisticData) {\n      this.optimisticData = newOptimisticData;\n      this.broadcastWatches();\n    }\n  }\n\n  private txCount = 0;\n\n  public batch<TUpdateResult>(\n    options: Cache.BatchOptions<InMemoryCache, TUpdateResult>\n  ): TUpdateResult {\n    const {\n      update,\n      optimistic = true,\n      removeOptimistic,\n      onWatchUpdated,\n    } = options;\n\n    let updateResult: TUpdateResult;\n    const perform = (layer?: EntityStore): TUpdateResult => {\n      const { data, optimisticData } = this;\n      ++this.txCount;\n      if (layer) {\n        this.data = this.optimisticData = layer;\n      }\n      try {\n        return (updateResult = update(this));\n      } finally {\n        --this.txCount;\n        this.data = data;\n        this.optimisticData = optimisticData;\n      }\n    };\n\n    const alreadyDirty = new Set<Cache.WatchOptions>();\n\n    if (onWatchUpdated && !this.txCount) {\n      // If an options.onWatchUpdated callback is provided, we want to call it\n      // with only the Cache.WatchOptions objects affected by options.update,\n      // but there might be dirty watchers already waiting to be broadcast that\n      // have nothing to do with the update. To prevent including those watchers\n      // in the post-update broadcast, we perform this initial broadcast to\n      // collect the dirty watchers, so we can re-dirty them later, after the\n      // post-update broadcast, allowing them to receive their pending\n      // broadcasts the next time broadcastWatches is called, just as they would\n      // if we never called cache.batch.\n      this.broadcastWatches({\n        ...options,\n        onWatchUpdated(watch) {\n          alreadyDirty.add(watch);\n          return false;\n        },\n      });\n    }\n\n    if (typeof optimistic === \"string\") {\n      // Note that there can be multiple layers with the same optimistic ID.\n      // When removeOptimistic(id) is called for that id, all matching layers\n      // will be removed, and the remaining layers will be reapplied.\n      this.optimisticData = this.optimisticData.addLayer(optimistic, perform);\n    } else if (optimistic === false) {\n      // Ensure both this.data and this.optimisticData refer to the root\n      // (non-optimistic) layer of the cache during the update. Note that\n      // this.data could be a Layer if we are currently executing an optimistic\n      // update function, but otherwise will always be an EntityStore.Root\n      // instance.\n      perform(this.data);\n    } else {\n      // Otherwise, leave this.data and this.optimisticData unchanged and run\n      // the update with broadcast batching.\n      perform();\n    }\n\n    if (typeof removeOptimistic === \"string\") {\n      this.optimisticData = this.optimisticData.removeLayer(removeOptimistic);\n    }\n\n    // Note: if this.txCount > 0, then alreadyDirty.size === 0, so this code\n    // takes the else branch and calls this.broadcastWatches(options), which\n    // does nothing when this.txCount > 0.\n    if (onWatchUpdated && alreadyDirty.size) {\n      this.broadcastWatches({\n        ...options,\n        onWatchUpdated(watch, diff) {\n          const result = onWatchUpdated.call(this, watch, diff);\n          if (result !== false) {\n            // Since onWatchUpdated did not return false, this diff is\n            // about to be broadcast to watch.callback, so we don't need\n            // to re-dirty it with the other alreadyDirty watches below.\n            alreadyDirty.delete(watch);\n          }\n          return result;\n        },\n      });\n      // Silently re-dirty any watches that were already dirty before the update\n      // was performed, and were not broadcast just now.\n      if (alreadyDirty.size) {\n        alreadyDirty.forEach((watch) => this.maybeBroadcastWatch.dirty(watch));\n      }\n    } else {\n      // If alreadyDirty is empty or we don't have an onWatchUpdated\n      // function, we don't need to go to the trouble of wrapping\n      // options.onWatchUpdated.\n      this.broadcastWatches(options);\n    }\n\n    return updateResult!;\n  }\n\n  public performTransaction(\n    update: (cache: InMemoryCache) => any,\n    optimisticId?: string | null\n  ) {\n    return this.batch({\n      update,\n      optimistic: optimisticId || optimisticId !== null,\n    });\n  }\n\n  public transformDocument(document: DocumentNode): DocumentNode {\n    return this.addTypenameToDocument(this.addFragmentsToDocument(document));\n  }\n\n  protected broadcastWatches(options?: BroadcastOptions) {\n    if (!this.txCount) {\n      this.watches.forEach((c) => this.maybeBroadcastWatch(c, options));\n    }\n  }\n\n  private addFragmentsToDocument(document: DocumentNode) {\n    const { fragments } = this.config;\n    return fragments ? fragments.transform(document) : document;\n  }\n\n  private addTypenameToDocument(document: DocumentNode) {\n    if (this.addTypename) {\n      return this.addTypenameTransform.transformDocument(document);\n    }\n    return document;\n  }\n\n  // This method is wrapped by maybeBroadcastWatch, which is called by\n  // broadcastWatches, so that we compute and broadcast results only when\n  // the data that would be broadcast might have changed. It would be\n  // simpler to check for changes after recomputing a result but before\n  // broadcasting it, but this wrapping approach allows us to skip both\n  // the recomputation and the broadcast, in most cases.\n  private broadcastWatch(c: Cache.WatchOptions, options?: BroadcastOptions) {\n    const { lastDiff } = c;\n\n    // Both WatchOptions and DiffOptions extend ReadOptions, and DiffOptions\n    // currently requires no additional properties, so we can use c (a\n    // WatchOptions object) as DiffOptions, without having to allocate a new\n    // object, and without having to enumerate the relevant properties (query,\n    // variables, etc.) explicitly. There will be some additional properties\n    // (lastDiff, callback, etc.), but cache.diff ignores them.\n    const diff = this.diff<any>(c);\n\n    if (options) {\n      if (c.optimistic && typeof options.optimistic === \"string\") {\n        diff.fromOptimisticTransaction = true;\n      }\n\n      if (\n        options.onWatchUpdated &&\n        options.onWatchUpdated.call(this, c, diff, lastDiff) === false\n      ) {\n        // Returning false from the onWatchUpdated callback will prevent\n        // calling c.callback(diff) for this watcher.\n        return;\n      }\n    }\n\n    if (!lastDiff || !equal(lastDiff.result, diff.result)) {\n      c.callback((c.lastDiff = diff), lastDiff);\n    }\n  }\n\n  /**\n   * @experimental\n   * @internal\n   * This is not a stable API - it is used in development builds to expose\n   * information to the DevTools.\n   * Use at your own risk!\n   */\n  public getMemoryInternals?: typeof getInMemoryCacheMemoryInternals;\n}\n\nif (__DEV__) {\n  InMemoryCache.prototype.getMemoryInternals = getInMemoryCacheMemoryInternals;\n}\n", "import type {\n  DocumentNode,\n  ASTNode,\n  FragmentDefinitionNode,\n  FragmentSpreadNode,\n} from \"graphql\";\nimport { visit } from \"graphql\";\n\nimport { wrap } from \"optimism\";\n\nimport type { FragmentMap } from \"../../utilities/index.js\";\nimport {\n  cacheSizes,\n  defaultCacheSizes,\n  getFragmentDefinitions,\n} from \"../../utilities/index.js\";\nimport { WeakCache } from \"@wry/caches\";\n\nexport interface FragmentRegistryAPI {\n  register(...fragments: DocumentNode[]): this;\n  lookup(fragmentName: string): FragmentDefinitionNode | null;\n  transform<D extends DocumentNode>(document: D): D;\n  resetCaches(): void;\n}\n\n// As long as createFragmentRegistry is not imported or used, the\n// FragmentRegistry example implementation provided below should not be bundled\n// (by tree-shaking bundlers like Rollup), because the implementation of\n// InMemoryCache refers only to the TypeScript interface FragmentRegistryAPI,\n// never the concrete implementation FragmentRegistry (which is deliberately not\n// exported from this module).\nexport function createFragmentRegistry(\n  ...fragments: DocumentNode[]\n): FragmentRegistryAPI {\n  return new FragmentRegistry(...fragments);\n}\n\nclass FragmentRegistry implements FragmentRegistryAPI {\n  private registry: FragmentMap = Object.create(null);\n\n  // Call `createFragmentRegistry` instead of invoking the\n  // FragmentRegistry constructor directly. This reserves the constructor for\n  // future configuration of the FragmentRegistry.\n  constructor(...fragments: DocumentNode[]) {\n    this.resetCaches();\n    if (fragments.length) {\n      this.register(...fragments);\n    }\n  }\n\n  public register(...fragments: DocumentNode[]): this {\n    const definitions = new Map<string, FragmentDefinitionNode>();\n    fragments.forEach((doc: DocumentNode) => {\n      getFragmentDefinitions(doc).forEach((node) => {\n        definitions.set(node.name.value, node);\n      });\n    });\n\n    definitions.forEach((node, name) => {\n      if (node !== this.registry[name]) {\n        this.registry[name] = node;\n        this.invalidate(name);\n      }\n    });\n\n    return this;\n  }\n\n  // Overridden in the resetCaches method below.\n  private invalidate(name: string) {}\n\n  public resetCaches() {\n    const proto = FragmentRegistry.prototype;\n    this.invalidate = (this.lookup = wrap(proto.lookup.bind(this), {\n      makeCacheKey: (arg) => arg,\n      max:\n        cacheSizes[\"fragmentRegistry.lookup\"] ||\n        defaultCacheSizes[\"fragmentRegistry.lookup\"],\n    })).dirty; // This dirty function is bound to the wrapped lookup method.\n    this.transform = wrap(proto.transform.bind(this), {\n      cache: WeakCache,\n      max:\n        cacheSizes[\"fragmentRegistry.transform\"] ||\n        defaultCacheSizes[\"fragmentRegistry.transform\"],\n    });\n    this.findFragmentSpreads = wrap(proto.findFragmentSpreads.bind(this), {\n      cache: WeakCache,\n      max:\n        cacheSizes[\"fragmentRegistry.findFragmentSpreads\"] ||\n        defaultCacheSizes[\"fragmentRegistry.findFragmentSpreads\"],\n    });\n  }\n\n  /*\n   * Note:\n   * This method is only memoized so it can serve as a dependency to `tranform`,\n   * so calling `invalidate` will invalidate cache entries for `transform`.\n   */\n  public lookup(fragmentName: string): FragmentDefinitionNode | null {\n    return this.registry[fragmentName] || null;\n  }\n\n  public transform<D extends DocumentNode>(document: D): D {\n    const defined = new Map<string, FragmentDefinitionNode>();\n    getFragmentDefinitions(document).forEach((def) => {\n      defined.set(def.name.value, def);\n    });\n\n    const unbound = new Set<string>();\n    const enqueue = (spreadName: string) => {\n      if (!defined.has(spreadName)) {\n        unbound.add(spreadName);\n      }\n    };\n\n    const enqueueChildSpreads = (node: ASTNode) =>\n      Object.keys(this.findFragmentSpreads(node)).forEach(enqueue);\n\n    enqueueChildSpreads(document);\n\n    const missing: string[] = [];\n    const map: FragmentMap = Object.create(null);\n\n    // This Set forEach loop can be extended during iteration by adding\n    // additional strings to the unbound set.\n    unbound.forEach((fragmentName) => {\n      const knownFragmentDef = defined.get(fragmentName);\n      if (knownFragmentDef) {\n        enqueueChildSpreads((map[fragmentName] = knownFragmentDef));\n      } else {\n        missing.push(fragmentName);\n        const def = this.lookup(fragmentName);\n        if (def) {\n          enqueueChildSpreads((map[fragmentName] = def));\n        }\n      }\n    });\n\n    if (missing.length) {\n      const defsToAppend: FragmentDefinitionNode[] = [];\n      missing.forEach((name) => {\n        const def = map[name];\n        if (def) {\n          defsToAppend.push(def);\n        }\n      });\n\n      if (defsToAppend.length) {\n        document = {\n          ...document,\n          definitions: document.definitions.concat(defsToAppend),\n        };\n      }\n    }\n\n    return document;\n  }\n\n  public findFragmentSpreads(root: ASTNode): FragmentSpreadMap {\n    const spreads: FragmentSpreadMap = Object.create(null);\n\n    visit(root, {\n      FragmentSpread(node) {\n        spreads[node.name.value] = node;\n      },\n    });\n\n    return spreads;\n  }\n}\n\ninterface FragmentSpreadMap {\n  [fragmentSpreadName: string]: FragmentSpreadNode;\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;AAAA,IAAM,iBAAiB;AAErB,IAAA,KAIE,OAAa;AAJf,IAAA,iBAAc,OAAA,SAAG,SAAU,KAAU,OAAU;AAC7C,MAAI,YAAY;AAChB,SAAO;AACT,IAAC;AAGH,IAAA;;EAAA,SAAA,QAAA;AAAoC,cAAAA,iBAAA,MAAA;AAGlC,aAAAA,gBAAY,SAAyC;AAAzC,UAAA,YAAA,QAAA;AAAA,kBAAA;MAAyC;AAArD,UAAA,QACE,OAAA,KAAA,MACE,OAAO,YAAY,WACZ,iBAAc,OAAK,UAAO,+DAC7B,OAAO,KACZ;AAPH,YAAA,cAAc;AACd,YAAA,OAAO;AAOL,qBAAe,OAAMA,gBAAe,SAAS;;IAC/C;AACF,WAAAA;EAAA,EAXoC,KAAK;;AAanC,SAAU,UACd,WACA,SAAyB;AAEzB,MAAI,CAAC,WAAW;AACd,UAAM,IAAI,eAAe,OAAO;;AAEpC;AAEA,IAAM,kBAAkB,CAAC,SAAS,OAAO,QAAQ,SAAS,QAAQ;AAGlE,IAAI,iBAAiB,gBAAgB,QAAQ,KAAK;AAElD,SAAS,kBAA+C,MAAO;AAC7D,SAAO,WAAA;AACL,QAAI,gBAAgB,QAAQ,IAAI,KAAK,gBAAgB;AAGnD,UAAM,SAAS,QAAQ,IAAI,KAAK,QAAQ;AACxC,aAAO,OAAO,MAAM,SAAS,SAAgB;;EAEjD;AACF;CAEA,SAAiBC,YAAS;AACX,EAAAA,WAAA,QAAQ,kBAAkB,OAAO;AACjC,EAAAA,WAAA,MAAM,kBAAkB,KAAK;AAC7B,EAAAA,WAAA,OAAO,kBAAkB,MAAM;AAC/B,EAAAA,WAAA,QAAQ,kBAAkB,OAAO;AAChD,GALiB,cAAA,YAAS,CAAA,EAAA;AAOpB,SAAU,aAAa,OAAqB;AAChD,MAAM,MAAM,gBAAgB,cAAc;AAC1C,mBAAiB,KAAK,IAAI,GAAG,gBAAgB,QAAQ,KAAK,CAAC;AAC3D,SAAO;AACT;;;ACzDO,IAAM,UAAU;;;ACAjB,SAAU,MAAS,OAAc;AACrC,MAAI;AACF,WAAO,MAAK;EACd,SAAEC,KAAM;EAAC;AACX;;;ACKA,IAAA,iBAAgB,MAAM,WAAA;AAAM,SAAA;AAAA,CAAU,KACpC,MAAM,WAAA;AAAM,SAAA;AAAA,CAAM,KAClB,MAAM,WAAA;AAAM,SAAA;AAAA,CAAI,KAChB,MAAM,WAAA;AAAM,SAAA;AAAA,CAAM;;;;;;MAMlB,WAAA;AACA,SAAM,MAAA,YAAA,aAAA,EAAA;;;;ACnBR,IAAM,eAAe,oBAAI,IAAG;AAItB,SAAU,aAAa,QAAc;AACzC,MAAM,QAAQ,aAAa,IAAI,MAAM,KAAK;AAC1C,eAAa,IAAI,QAAQ,QAAQ,CAAC;AAClC,SAAO,GAAA,OAAG,QAAM,GAAA,EAAA,OAAI,OAAK,GAAA,EAAA,OAAI,KAAK,OAAM,EAAG,SAAS,EAAE,EAAE,MAAM,CAAC,CAAC;AAClE;;;ACNM,SAAU,oBAAoB,OAAY,OAAS;AAAT,MAAA,UAAA,QAAA;AAAA,YAAA;EAAS;AACvD,MAAM,UAAU,aAAa,qBAAqB;AAClD,SAAO,KAAK,UACV,OACA,SAAC,KAAKC,QAAK;AACT,WAAOA,WAAU,SAAS,UAAUA;EACtC,GACA,KAAK,EAEJ,MAAM,KAAK,UAAU,OAAO,CAAC,EAC7B,KAAK,aAAa;AACvB;;;ACPA,SAAS,KAAK,IAA0C;AACtD,SAAO,SAAU,SAAyB;AAAE,QAAA,OAAA,CAAA;aAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAAc;AAAd,WAAA,KAAA,CAAA,IAAA,UAAA,EAAA;;AAC1C,QAAI,OAAO,YAAY,UAAU;AAC/B,UAAM,OAAO;AACb,gBAAU,mBAAmB,IAAI;AACjC,UAAI,CAAC,SAAS;AACZ,kBAAU,oBAAoB,MAAM,IAAI;AACxC,eAAO,CAAA;MACT;IACF;AACA,OAAE,MAAA,QAAI,CAAC,OAAO,EAAE,OAAO,IAAI,CAAC;EAC9B;AACF;AAgDA,IAAMC,aAA8B,OAAO,OACzC,SAASA,WACP,WACA,SAAyB;AACzB,MAAA,OAAA,CAAA;WAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAAkB;AAAlB,SAAA,KAAA,CAAA,IAAA,UAAA,EAAA;;AAEA,MAAI,CAAC,WAAW;AACd,cACE,WACA,mBAAmB,SAAS,IAAI,KAAK,oBAAoB,SAAS,IAAI,CAAC;EAE3E;AACF,GACA;EACE,OAAO,KAAK,UAAkB,KAAK;EACnC,KAAK,KAAK,UAAkB,GAAG;EAC/B,MAAM,KAAK,UAAkB,IAAI;EACjC,OAAO,KAAK,UAAkB,KAAK;CACpC;AAaH,SAAS,kBACP,SAAyB;AACzB,MAAA,iBAAA,CAAA;WAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAA4B;AAA5B,mBAAA,KAAA,CAAA,IAAA,UAAA,EAAA;;AAEA,SAAO,IAAI,eACT,mBAAmB,SAAS,cAAc,KACxC,oBAAoB,SAAS,cAAc,CAAC;AAElD;AAEA,IAAM,4BAA4B,OAAO,IACvC,+BAA+B,OAAO;AAUxC,SAAS,UAAU,KAAQ;AACzB,MAAI,OAAO,OAAO,UAAU;AAC1B,WAAO;EACT;AAEA,MAAI;AACF,WAAO,oBAAoB,KAAK,CAAC,EAAE,MAAM,GAAG,GAAI;EAClD,SAAEC,KAAM;AACN,WAAO;EACT;AACF;AAEA,SAAS,mBACP,SACA,aAA2B;AAA3B,MAAA,gBAAA,QAAA;AAAA,kBAAA,CAAA;EAA2B;AAE3B,MAAI,CAAC;AAAS;AACd,SACE,eAAO,yBAAyB,KAChC,eAAO,yBAAyB,EAAE,SAAS,YAAY,IAAI,SAAS,CAAC;AAEzE;AAEA,SAAS,oBACP,SACA,aAA2B;AAA3B,MAAA,gBAAA,QAAA;AAAA,kBAAA,CAAA;EAA2B;AAE3B,MAAI,CAAC;AAAS;AACd,SAAO,+FAAA,OAA+F,mBACpG,KAAK,UAAU;IACb;IACA;IACA,MAAM,YAAY,IAAI,SAAS;GAChC,CAAC,CACH;AACH;;;ACxIO,IAAM,MAAM,WAAW,YAAY;;;;;;ACX1C,IAAM,kBAAkB,MAAM,uBAAO,OAAO,IAAI;AAGhD,IAAM,EAAE,SAAS,MAAK,IAAK,MAAM;AACjC,IAAM,EAAE,eAAc,IAAK,OAAO;AAE5B,IAAO,OAAP,MAAO,MAAI;EAQf,YACU,WAAW,MACX,WAAmC,iBAAe;AADlD,SAAA,WAAA;AACA,SAAA,WAAA;EACP;EAEI,UAA2B,OAAQ;AACxC,WAAO,KAAK,YAAY,KAAK;EAC/B;EAEO,YAA0C,OAAQ;AACvD,QAAI,OAAmB;AACvB,YAAQ,KAAK,OAAO,SAAO,OAAO,KAAK,aAAa,GAAG,CAAC;AACxD,WAAO,eAAe,KAAK,MAAM,MAAM,IACnC,KAAK,OACL,KAAK,OAAO,KAAK,SAAS,MAAM,KAAK,KAAK,CAAC;EACjD;EAEO,QAAyB,OAAQ;AACtC,WAAO,KAAK,UAAU,KAAK;EAC7B;EAEO,UAAwC,OAAQ;AACrD,QAAI,OAA+B;AAEnC,aAAS,IAAI,GAAG,MAAM,MAAM,QAAQ,QAAQ,IAAI,KAAK,EAAE,GAAG;AACxD,YAAM,MACJ,KAAK,YAAY,SAAS,MAAM,CAAC,CAAC,IAAI,KAAK,OAAO,KAAK;AAEzD,aAAO,OAAO,IAAI,IAAI,MAAM,CAAC,CAAC;;AAGhC,WAAO,QAAQ,KAAK;EACtB;EAEQ,aAAa,KAAQ;AAC3B,UAAM,MAAM,KAAK,YAAY,SAAS,GAAG,IACrC,KAAK,SAAS,KAAK,OAAO,oBAAI,QAAO,KACrC,KAAK,WAAW,KAAK,SAAS,oBAAI,IAAG;AACzC,QAAI,QAAQ,IAAI,IAAI,GAAG;AACvB,QAAI,CAAC;AAAO,UAAI,IAAI,KAAK,QAAQ,IAAI,MAAW,KAAK,UAAU,KAAK,QAAQ,CAAC;AAC7E,WAAO;EACT;;AAGF,SAAS,SAAS,OAAU;AAC1B,UAAQ,OAAO,OAAO;IACtB,KAAK;AACH,UAAI,UAAU;AAAM;IAEtB,KAAK;AACH,aAAO;;AAET,SAAO;AACT;;;AChEA,SAAS,iBAAc;AAAI;AAErB,IAAO,cAAP,MAAkB;EAKtB,YACU,MAAM,UACP,UAAsC,gBAAc;AADnD,SAAA,MAAA;AACD,SAAA,UAAA;AAND,SAAA,MAAM,oBAAI,IAAG;AACb,SAAA,SAA4B;AAC5B,SAAA,SAA4B;EAKjC;EAEI,IAAI,KAAM;AACf,WAAO,KAAK,IAAI,IAAI,GAAG;EACzB;EAEO,IAAI,KAAM;AACf,UAAM,OAAO,KAAK,QAAQ,GAAG;AAC7B,WAAO,QAAQ,KAAK;EACtB;EAEA,IAAW,OAAI;AACb,WAAO,KAAK,IAAI;EAClB;EAEQ,QAAQ,KAAM;AACpB,UAAM,OAAO,KAAK,IAAI,IAAI,GAAG;AAE7B,QAAI,QAAQ,SAAS,KAAK,QAAQ;AAChC,YAAM,EAAE,OAAO,MAAK,IAAK;AAEzB,UAAI,OAAO;AACT,cAAM,QAAQ;;AAGhB,UAAI,OAAO;AACT,cAAM,QAAQ;;AAGhB,WAAK,QAAQ,KAAK;AAClB,WAAK,MAAO,QAAQ;AAEpB,WAAK,QAAQ;AACb,WAAK,SAAS;AAEd,UAAI,SAAS,KAAK,QAAQ;AACxB,aAAK,SAAS;;;AAIlB,WAAO;EACT;EAEO,IAAI,KAAQ,OAAQ;AACzB,QAAI,OAAO,KAAK,QAAQ,GAAG;AAC3B,QAAI,MAAM;AACR,aAAO,KAAK,QAAQ;;AAGtB,WAAO;MACL;MACA;MACA,OAAO;MACP,OAAO,KAAK;;AAGd,QAAI,KAAK,QAAQ;AACf,WAAK,OAAO,QAAQ;;AAGtB,SAAK,SAAS;AACd,SAAK,SAAS,KAAK,UAAU;AAE7B,SAAK,IAAI,IAAI,KAAK,IAAI;AAEtB,WAAO,KAAK;EACd;EAEO,QAAK;AACV,WAAO,KAAK,UAAU,KAAK,IAAI,OAAO,KAAK,KAAK;AAC9C,WAAK,OAAO,KAAK,OAAO,GAAG;;EAE/B;EAEO,OAAO,KAAM;AAClB,UAAM,OAAO,KAAK,IAAI,IAAI,GAAG;AAC7B,QAAI,MAAM;AACR,UAAI,SAAS,KAAK,QAAQ;AACxB,aAAK,SAAS,KAAK;;AAGrB,UAAI,SAAS,KAAK,QAAQ;AACxB,aAAK,SAAS,KAAK;;AAGrB,UAAI,KAAK,OAAO;AACd,aAAK,MAAM,QAAQ,KAAK;;AAG1B,UAAI,KAAK,OAAO;AACd,aAAK,MAAM,QAAQ,KAAK;;AAG1B,WAAK,IAAI,OAAO,GAAG;AACnB,WAAK,QAAQ,KAAK,OAAO,GAAG;AAE5B,aAAO;;AAGT,WAAO;EACT;;;;ACnGF,SAAS,OAAI;AAAI;AACjB,IAAMC,kBAAiB;AAEvB,IAAM,WACJ,OAAO,YAAY,cACf,UACC,SAAa,OAAQ;AACpB,SAAO,EAAE,OAAO,MAAM,MAAK;AAI7B;AACN,IAAM,WAAW,OAAO,YAAY,cAAc,UAAU;AAC5D,IAAM,wBACJ,OAAO,yBAAyB,cAC5B,uBACC,WAAA;AACC,SAAO;IACL,UAAU;IACV,YAAY;;AAEhB;AAEN,IAAM,wBAAwB;AAExB,IAAO,YAAP,MAAgB;EAWpB,YACU,MAAM,UACP,UAAuCA,iBAAc;AADpD,SAAA,MAAA;AACD,SAAA,UAAA;AAVD,SAAA,MAAM,IAAI,SAAQ;AAElB,SAAA,SAA4B;AAC5B,SAAA,SAA4B;AAC5B,SAAA,mBAA+C,oBAAI,IAAG;AACtD,SAAA,wBAAwB;AACzB,SAAA,OAAO;AAgIN,SAAA,WAAW,MAAK;AACtB,YAAM,WAAW,KAAK,iBAAiB,OAAM;AAC7C,eAAS,IAAI,GAAG,IAAI,uBAAuB,KAAK;AAC9C,cAAM,OAAO,SAAS,KAAI,EAAG;AAC7B,YAAI,CAAC;AAAM;AACX,aAAK,iBAAiB,OAAO,IAAI;AACjC,cAAM,MAAM,KAAK;AACjB,eAAQ,KAAmC;AAC1C,aAAmC,SAAS,IAAI,SAAS,GAAG;AAC7D,aAAK,SAAS,SAAS,KAAK,MAAM,IAAI;;AAExC,UAAI,KAAK,iBAAiB,OAAO,GAAG;AAClC,uBAAe,KAAK,QAAQ;aACvB;AACL,aAAK,wBAAwB;;IAEjC;AA1IE,SAAK,WAAW,IAAI,sBAClB,KAAK,WAAW,KAAK,IAAI,CAAC;EAE9B;EAEO,IAAI,KAAM;AACf,WAAO,KAAK,IAAI,IAAI,GAAG;EACzB;EAEO,IAAI,KAAM;AACf,UAAM,OAAO,KAAK,QAAQ,GAAG;AAC7B,WAAO,QAAQ,KAAK;EACtB;EAEQ,QAAQ,KAAM;AACpB,UAAM,OAAO,KAAK,IAAI,IAAI,GAAG;AAE7B,QAAI,QAAQ,SAAS,KAAK,QAAQ;AAChC,YAAM,EAAE,OAAO,MAAK,IAAK;AAEzB,UAAI,OAAO;AACT,cAAM,QAAQ;;AAGhB,UAAI,OAAO;AACT,cAAM,QAAQ;;AAGhB,WAAK,QAAQ,KAAK;AAClB,WAAK,MAAO,QAAQ;AAEpB,WAAK,QAAQ;AACb,WAAK,SAAS;AAEd,UAAI,SAAS,KAAK,QAAQ;AACxB,aAAK,SAAS;;;AAIlB,WAAO;EACT;EAEO,IAAI,KAAQ,OAAQ;AACzB,QAAI,OAAO,KAAK,QAAQ,GAAG;AAC3B,QAAI,MAAM;AACR,aAAQ,KAAK,QAAQ;;AAGvB,WAAO;MACL;MACA;MACA,OAAO;MACP,OAAO,KAAK;;AAGd,QAAI,KAAK,QAAQ;AACf,WAAK,OAAO,QAAQ;;AAGtB,SAAK,SAAS;AACd,SAAK,SAAS,KAAK,UAAU;AAE7B,SAAK,qBAAqB,IAAI;AAC9B,SAAK,IAAI,IAAI,KAAK,IAAI;AACtB,SAAK;AAEL,WAAO,KAAK;EACd;EAEO,QAAK;AACV,WAAO,KAAK,UAAU,KAAK,OAAO,KAAK,KAAK;AAC1C,WAAK,WAAW,KAAK,MAAM;;EAE/B;EAEQ,WAAW,MAAgB;AACjC,QAAI,SAAS,KAAK,QAAQ;AACxB,WAAK,SAAS,KAAK;;AAGrB,QAAI,SAAS,KAAK,QAAQ;AACxB,WAAK,SAAS,KAAK;;AAGrB,QAAI,KAAK,OAAO;AACd,WAAK,MAAM,QAAQ,KAAK;;AAG1B,QAAI,KAAK,OAAO;AACd,WAAK,MAAM,QAAQ,KAAK;;AAG1B,SAAK;AACL,UAAM,MAAM,KAAK,OAAQ,KAAK,UAAU,KAAK,OAAO,MAAK;AACzD,SAAK,QAAQ,KAAK,OAAO,GAAG;AAC5B,QAAI,CAAC,KAAK,QAAQ;AAChB,WAAK,iBAAiB,OAAO,IAAI;WAC5B;AACL,WAAK,SAAS,WAAW,IAAI;;AAE/B,QAAI;AAAK,WAAK,IAAI,OAAO,GAAG;EAC9B;EAEO,OAAO,KAAM;AAClB,UAAM,OAAO,KAAK,IAAI,IAAI,GAAG;AAC7B,QAAI,MAAM;AACR,WAAK,WAAW,IAAI;AAEpB,aAAO;;AAGT,WAAO;EACT;EAEQ,qBAAqB,MAA2B;AACtD,SAAK,iBAAiB,IAAI,IAAI;AAC9B,QAAI,CAAC,KAAK,uBAAuB;AAC/B,WAAK,wBAAwB;AAC7B,qBAAe,KAAK,QAAQ;;EAEhC;;;;AC5KF,IAAI,iBAAiC;AAIrC,IAAM,gBAAqB,CAAA;AAE3B,IAAI,YAAY;AAKhB,IAAM,gBAAgB,MAAM,MAAM,KAAI;EAAV,cAAA;AAIV,SAAA,KAAK;MACnB;MACA;MACA,KAAK,IAAG;MACR,KAAK,OAAM,EAAG,SAAS,EAAE,EAAE,MAAM,CAAC;MAClC,KAAK,GAAG;EA+FZ;EA7FS,WAAQ;AACb,aAAS,UAAU,gBAAgB,SAAS,UAAU,QAAQ,QAAQ;AAGpE,UAAI,KAAK,MAAM,QAAQ,OAAO;AAC5B,cAAM,QAAQ,QAAQ,MAAM,KAAK,EAAE;AACnC,YAAI,UAAU;AAAe;AAC7B,YAAI,YAAY,gBAAgB;AAI9B,yBAAgB,MAAM,KAAK,EAAE,IAAI;;AAEnC,eAAO;;;AAGX,QAAI,gBAAgB;AAIlB,qBAAe,MAAM,KAAK,EAAE,IAAI;;AAElC,WAAO;EACT;EAEO,WAAQ;AACb,QAAI,KAAK,SAAQ,GAAI;AACnB,aAAO,eAAgB,MAAM,KAAK,EAAE;;EAExC;EAEO,UACL,OACA,UAGA,MACA,SAAe;AAEf,UAAM,QAAQ;MACZ,WAAW;MACX,CAAC,KAAK,EAAE,GAAG;;AAEb,UAAM,SAAS;AACf,qBAAiB,EAAE,QAAQ,MAAK;AAChC,QAAI;AAGF,aAAO,SAAS,MAAM,SAAU,IAAK;;AAErC,uBAAiB;;EAErB;;;EAIA,OAAO,KACL,UAAkD;AAElD,UAAM,UAAU;AAChB,WAAO,WAAA;AACL,YAAM,QAAQ;AACd,UAAI;AACF,yBAAiB;AACjB,eAAO,SAAS,MAAM,MAAM,SAAgB;;AAE5C,yBAAiB;;IAErB;EACF;;EAGA,OAAO,UACL,UAGA,MACA,SAAe;AAEf,QAAI,gBAAgB;AAClB,YAAM,QAAQ;AACd,UAAI;AACF,yBAAiB;AAGjB,eAAO,SAAS,MAAM,SAAU,IAAK;;AAErC,yBAAiB;;WAEd;AACL,aAAO,SAAS,MAAM,SAAU,IAAK;;EAEzC;;AAGF,SAASC,OAAS,IAAW;AAC3B,MAAI;AACF,WAAO,GAAE;WACF,SAAS;EAAA;AACpB;AAUA,IAAM,YAAY;AAElB,IAAM;;;EAGJA,OAAM,MAAM,UAAU;;;EAItBA,OAAM,MAAM,MAAM;;;EAIlB,uBAAO,OAAO,IAAI;;AAIpB,IAAM,aAEF;AAEG,IAAM,OACX,WAAW,SAAS;;AAGnB,MAA4B,SAAS,KACrC,SAAUC,OAAI;AACb,MAAI;AACF,WAAO,eAAe,YAAY,WAAW;MAC3C,OAAOA;MACP,YAAY;MACZ,UAAU;;;;;;;MAOV,cAAc;KACf;;AAED,WAAOA;;AAEX,EAAG,cAAa,CAAE;;;ACpLb,IAAM,EAAE,MAAM,UAAS,IAAK;;;ACC5B,IAAM,kBAAkB,IAAI,KAAI;;;ACDhC,IAAM,EACX,gBAAAC,gBAAc,IACZ,OAAO;AAEJ,IAAM,eACX,MAAM,QACN,SAAU,KAAG;AACX,QAAM,QAAe,CAAA;AACrB,MAAI,QAAQ,UAAQ,MAAM,KAAK,IAAI,CAAC;AACpC,SAAO;AACT;AAMI,SAAU,iBAAiB,YAA0B;AACzD,QAAM,EAAE,YAAW,IAAK;AACxB,MAAI,OAAO,gBAAgB,YAAY;AACrC,eAAW,cAAc;AACzB,gBAAW;;AAEf;;;ACnBA,IAAM,eAA2B,CAAA;AACjC,IAAM,mBAAmB;AAIzB,SAAS,OAAO,WAAgB,iBAAwB;AACtD,MAAI,CAAE,WAAW;AACf,UAAM,IAAI,MAAM,mBAAmB,mBAAmB;;AAE1D;AASA,SAAS,QAAQ,GAAe,GAAa;AAC3C,QAAM,MAAM,EAAE;AACd;;IAEE,MAAM;IAEN,QAAQ,EAAE;IAEV,EAAE,MAAM,CAAC,MAAM,EAAE,MAAM,CAAC;;AAE5B;AAEA,SAAS,SAAY,OAAe;AAClC,UAAQ,MAAM,QAAQ;IACpB,KAAK;AAAG,YAAM,IAAI,MAAM,eAAe;IACvC,KAAK;AAAG,aAAO,MAAM,CAAC;IACtB,KAAK;AAAG,YAAM,MAAM,CAAC;;AAEzB;AAEA,SAAS,UAAa,OAAe;AACnC,SAAO,MAAM,MAAM,CAAC;AACtB;AAIM,IAAO,QAAP,MAAO,OAAK;EAmBhB,YACkB,IAA8B;AAA9B,SAAA,KAAA;AAbF,SAAA,UAAU,oBAAI,IAAG;AACjB,SAAA,cAAc,oBAAI,IAAG;AAK9B,SAAA,gBAAsC;AAEtC,SAAA,QAAQ;AACR,SAAA,cAAc;AACL,SAAA,QAAuB,CAAA;AAuE/B,SAAA,OAA6B;AAlEnC,MAAE,OAAM;EACV;EAEO,OAAI;AACT,QAAI,KAAK,MAAM,WAAW,KAAK,CAAC,aAAa,IAAI,GAAG;AAClD,qBAAe,IAAI;AACnB,aAAO,KAAK,MAAM,CAAC;;EAEvB;;;;;;;EAQO,UAAU,MAAW;AAC1B,WAAO,CAAE,KAAK,aAAa,qBAAqB;AAChD,mBAAe,IAAI;AACnB,WAAO,aAAa,IAAI,IACpB,gBAAgB,MAAM,IAAI,IAC1B,SAAS,KAAK,KAAK;EACzB;EAEO,WAAQ;AACb,QAAI,KAAK;AAAO;AAChB,SAAK,QAAQ;AACb,gBAAY,IAAI;AAIhB,qBAAiB,IAAI;EACvB;EAEO,UAAO;AACZ,SAAK,SAAQ;AAKb,mBAAe,IAAI;AAanB,eAAW,MAAM,CAAC,QAAQ,UAAS;AACjC,aAAO,SAAQ;AACf,kBAAY,QAAQ,IAAI;IAC1B,CAAC;EACH;EAEO,SAAM;AAIX,SAAK,QAAO;EACd;EAIO,SAASC,MAAa;AAC3B,IAAAA,KAAI,IAAI,IAAI;AACZ,QAAI,CAAE,KAAK,MAAM;AACf,WAAK,OAAO,aAAa,IAAG,KAAM,oBAAI,IAAG;;AAE3C,SAAK,KAAK,IAAIA,IAAG;EACnB;EAEO,aAAU;AACf,QAAI,KAAK,MAAM;AACb,mBAAa,KAAK,IAAI,EAAE,QAAQ,CAAAA,SAAOA,KAAI,OAAO,IAAI,CAAC;AACvD,WAAK,KAAK,MAAK;AACf,mBAAa,KAAK,KAAK,IAAI;AAC3B,WAAK,OAAO;;EAEhB;;AAxGc,MAAA,QAAQ;AA2GxB,SAAS,eAAe,OAAe;AACrC,QAAM,SAAS,gBAAgB,SAAQ;AACvC,MAAI,QAAQ;AACV,UAAM,QAAQ,IAAI,MAAM;AAExB,QAAI,CAAE,OAAO,YAAY,IAAI,KAAK,GAAG;AACnC,aAAO,YAAY,IAAI,OAAO,CAAA,CAAE;;AAGlC,QAAI,aAAa,KAAK,GAAG;AACvB,uBAAiB,QAAQ,KAAK;WACzB;AACL,uBAAiB,QAAQ,KAAK;;AAGhC,WAAO;;AAEX;AAEA,SAAS,gBAAgB,OAAiB,MAAW;AACnD,iBAAe,KAAK;AAGpB,kBAAgB,UAAU,OAAO,mBAAmB,CAAC,OAAO,IAAI,CAAC;AAEjE,MAAI,eAAe,OAAO,IAAI,GAAG;AAG/B,aAAS,KAAK;;AAGhB,SAAO,SAAS,MAAM,KAAK;AAC7B;AAEA,SAAS,kBAAkB,OAAiB,MAAW;AACrD,QAAM,cAAc;AAEpB,QAAM,EAAE,gBAAe,IAAK;AAC5B,MAAI;AACJ,MAAI,mBAAmB,MAAM,MAAM,WAAW,GAAG;AAC/C,mBAAe,UAAU,MAAM,KAAK;;AAItC,QAAM,MAAM,SAAS;AAErB,MAAI;AAEF,UAAM,MAAM,CAAC,IAAI,MAAM,GAAG,MAAM,MAAM,IAAI;AAM1C,QAAI,mBAAmB,gBAAgB,CAAC,QAAQ,cAAc,MAAM,KAAK,GAAG;AAC1E,UAAI;AACF,cAAM,MAAM,CAAC,IAAI,gBAAgB,MAAM,MAAM,CAAC,GAAG,aAAa,CAAC,CAAC;eAChEC,KAAM;;;WAMH,GAAG;AAEV,UAAM,MAAM,CAAC,IAAI;;AAInB,QAAM,cAAc;AACtB;AAEA,SAAS,aAAa,OAAe;AACnC,SAAO,MAAM,SAAS,CAAC,EAAE,MAAM,iBAAiB,MAAM,cAAc;AACtE;AAEA,SAAS,SAAS,OAAe;AAC/B,QAAM,QAAQ;AAEd,MAAI,aAAa,KAAK,GAAG;AAGvB;;AAGF,cAAY,KAAK;AACnB;AAEA,SAAS,YAAY,OAAe;AAClC,aAAW,OAAO,gBAAgB;AACpC;AAEA,SAAS,YAAY,OAAe;AAClC,aAAW,OAAO,gBAAgB;AACpC;AAEA,SAAS,WACP,OACA,UAAoD;AAEpD,QAAM,cAAc,MAAM,QAAQ;AAClC,MAAI,aAAa;AACf,UAAM,UAAU,aAAa,MAAM,OAAO;AAC1C,aAAS,IAAI,GAAG,IAAI,aAAa,EAAE,GAAG;AACpC,eAAS,QAAQ,CAAC,GAAG,KAAK;;;AAGhC;AAGA,SAAS,iBAAiB,QAAkB,OAAe;AAGzD,SAAO,OAAO,YAAY,IAAI,KAAK,CAAC;AACpC,SAAO,aAAa,KAAK,CAAC;AAC1B,QAAM,iBAAiB,CAAC,aAAa,MAAM;AAE3C,MAAI,CAAE,OAAO,eAAe;AAC1B,WAAO,gBAAgB,aAAa,IAAG,KAAM,oBAAI;aAExC,OAAO,cAAc,IAAI,KAAK,GAAG;AAI1C;;AAGF,SAAO,cAAc,IAAI,KAAK;AAI9B,MAAI,gBAAgB;AAClB,gBAAY,MAAM;;AAEtB;AAGA,SAAS,iBAAiB,QAAkB,OAAe;AAGzD,SAAO,OAAO,YAAY,IAAI,KAAK,CAAC;AACpC,SAAO,CAAE,aAAa,KAAK,CAAC;AAE5B,QAAM,aAAa,OAAO,YAAY,IAAI,KAAK;AAC/C,MAAI,WAAW,WAAW,GAAG;AAC3B,WAAO,YAAY,IAAI,OAAO,UAAU,MAAM,KAAK,CAAC;aAC3C,CAAE,QAAQ,YAAY,MAAM,KAAK,GAAG;AAC7C,WAAO,SAAQ;;AAGjB,mBAAiB,QAAQ,KAAK;AAE9B,MAAI,aAAa,MAAM,GAAG;AACxB;;AAGF,cAAY,MAAM;AACpB;AAEA,SAAS,iBAAiB,QAAkB,OAAe;AACzD,QAAM,KAAK,OAAO;AAClB,MAAI,IAAI;AACN,OAAG,OAAO,KAAK;AACf,QAAI,GAAG,SAAS,GAAG;AACjB,UAAI,aAAa,SAAS,kBAAkB;AAC1C,qBAAa,KAAK,EAAE;;AAEtB,aAAO,gBAAgB;;;AAG7B;AAIA,SAAS,eAAe,QAAgB;AACtC,MAAI,OAAO,YAAY,OAAO,GAAG;AAC/B,WAAO,YAAY,QAAQ,CAAC,QAAQ,UAAS;AAC3C,kBAAY,QAAQ,KAAK;IAC3B,CAAC;;AAKH,SAAO,WAAU;AAIjB,SAAO,OAAO,kBAAkB,IAAI;AACtC;AAEA,SAAS,YAAY,QAAkB,OAAe;AACpD,QAAM,QAAQ,OAAO,MAAM;AAC3B,SAAO,YAAY,OAAO,KAAK;AAC/B,mBAAiB,QAAQ,KAAK;AAChC;AAEA,SAAS,eAAe,OAAiB,MAAW;AAClD,MAAI,OAAO,MAAM,cAAc,YAAY;AACzC,QAAI;AACF,uBAAiB,KAAK;AACtB,YAAM,cAAc,MAAM,UAAU,MAAM,MAAM,IAAI;aAC7C,GAAG;AAKV,YAAM,SAAQ;AACd,aAAO;;;AAMX,SAAO;AACT;;;ACxWA,IAAM,eAAe;EACnB,UAAU;EACV,SAAS;EACT,QAAQ;;;AAYJ,SAAU,IAAU,SAEzB;AACC,QAAM,YAAY,oBAAI,IAAG;AACzB,QAAM,YAAY,WAAW,QAAQ;AAErC,WAAS,OAAO,KAAS;AACvB,UAAM,SAAS,gBAAgB,SAAQ;AACvC,QAAI,QAAQ;AACV,UAAIC,OAAM,UAAU,IAAI,GAAG;AAC3B,UAAI,CAACA,MAAK;AACR,kBAAU,IAAI,KAAKA,OAAM,oBAAI,KAAgB;;AAE/C,aAAO,SAASA,IAAG;AACnB,UAAI,OAAO,cAAc,YAAY;AACnC,yBAAiBA,IAAG;AACpB,QAAAA,KAAI,cAAc,UAAU,GAAG;;;EAGrC;AAEA,SAAO,QAAQ,SAAS,MACtB,KACA,iBAAiC;AAEjC,UAAMA,OAAM,UAAU,IAAI,GAAG;AAC7B,QAAIA,MAAK;AACP,YAAM,IACJ,mBACAC,gBAAe,KAAK,cAAc,eAAe,IAC/C,kBAAkB;AAItB,mBAAaD,IAAG,EAAE,QAAQ,WAAS,MAAM,CAAC,EAAC,CAAE;AAC7C,gBAAU,OAAO,GAAG;AACpB,uBAAiBA,IAAG;;EAExB;AAEA,SAAO;AACT;;;AChCA,IAAI;AACE,SAAU,uBAAuB,MAAW;AAChD,QAAM,OAAO,mBACX,iBAAiB,IAAI,KAAK,OAAO,YAAY,UAAU;AAEzD,SAAO,KAAK,YAAY,IAAI;AAC9B;AA4FA,IAAM,SAAS,oBAAI,IAAG;AAEhB,SAAUE,MAKd,kBAA+C,EAC/C,MAAM,KAAK,IAAI,GAAG,EAAE,GACpB,SACA,eAAgB,qBAChB,iBACA,WACA,OAAO,cAAc,YAAW,IAC8B,uBAAO,OAAO,IAAI,GAAC;AACjF,QAAM,QACJ,OAAO,gBAAgB,aACnB,IAAI,YAAY,KAAK,WAAS,MAAM,QAAO,CAAE,IAC7C;AAEN,QAAM,aAAa,WAAA;AACjB,UAAM,MAAM,aAAa,MACvB,MACA,UAAU,QAAQ,MAAM,MAAM,SAAgB,IAAI,SAAgB;AAGpE,QAAI,QAAQ,QAAQ;AAClB,aAAO,iBAAiB,MAAM,MAAM,SAAgB;;AAGtD,QAAI,QAAQ,MAAM,IAAI,GAAG;AACzB,QAAI,CAAC,OAAO;AACV,YAAM,IAAI,KAAK,QAAQ,IAAI,MAAM,gBAAgB,CAAC;AAClD,YAAM,kBAAkB;AACxB,YAAM,YAAY;AAGlB,YAAM,SAAS,MAAM,MAAM,OAAO,GAAG;;AAGvC,UAAM,QAAQ,MAAM,UAClB,MAAM,UAAU,MAAM,KAAK,SAAS,CAAU;AAKhD,UAAM,IAAI,KAAK,KAAK;AAEpB,WAAO,IAAI,KAAK;AAKhB,QAAI,CAAE,gBAAgB,SAAQ,GAAI;AAChC,aAAO,QAAQ,CAAAC,WAASA,OAAM,MAAK,CAAE;AACrC,aAAO,MAAK;;AAGd,WAAO;EACT;AAEA,SAAO,eAAe,YAAY,QAAQ;IACxC,KAAK,MAAM,MAAM;IACjB,cAAc;IACd,YAAY;GACb;AAED,SAAO,OAAO,WAAW,UAAU;IACjC;IACA;IACA;IACA;IACA;IACA;GACD;AAED,WAAS,SAAS,KAA0B;AAC1C,UAAM,QAAQ,OAAO,MAAM,IAAI,GAAG;AAClC,QAAI,OAAO;AACT,YAAM,SAAQ;;EAElB;AACA,aAAW,WAAW;AACtB,aAAW,QAAQ,SAAS,QAAK;AAC/B,aAAS,aAAa,MAAM,MAAM,SAAgB,CAAC;EACrD;AAEA,WAAS,QAAQ,KAA0B;AACzC,UAAM,QAAQ,OAAO,MAAM,IAAI,GAAG;AAClC,QAAI,OAAO;AACT,aAAO,MAAM,KAAI;;EAErB;AACA,aAAW,UAAU;AACrB,aAAW,OAAO,SAAS,OAAI;AAC7B,WAAO,QAAQ,aAAa,MAAM,MAAM,SAAgB,CAAC;EAC3D;AAEA,WAAS,UAAU,KAA0B;AAC3C,WAAO,MAAM,MAAM,OAAO,GAAG,IAAI;EACnC;AACA,aAAW,YAAY;AACvB,aAAW,SAAS,SAAS,SAAM;AACjC,WAAO,UAAU,aAAa,MAAM,MAAM,SAAgB,CAAC;EAC7D;AAEA,aAAW,eAAe;AAC1B,aAAW,SAAS,UAAU,SAAS,SAAM;AAC3C,WAAO,aAAa,MAAM,MAAM,QAAQ,MAAM,MAAM,SAAgB,CAAC;EACvE,IAAI;AAEJ,SAAO,OAAO,OAAO,UAAU;AACjC;;;ACjOM,SAAU,cACdC,KACA,WAA+B;MAD7B,aAAUA,IAAA;AAGZ,MAAI,CAAC,cAAc,CAAC,WAAW,QAAQ;AACrC,WAAO;EACT;AACA,SAAO,uBAAuB,UAAU,EAAE,MACxC,SAACA,KAAyB;QAAvB,YAASA,IAAA,WAAE,aAAUA,IAAA;AACtB,QAAI,cAAuB;AAC3B,QAAI,WAAW,MAAM,SAAS,YAAY;AACxC,oBACE,aAAa,UAAW,WAAW,MAAuB,KAAK,KAAK;AACtE,MAAAC,WACE,gBAAgB,QAChB,IAAA,UAAA,KAAA,KAAA;IAGJ,OAAO;AACL,oBAAe,WAAW,MAA2B;IACvD;AACA,WAAO,UAAU,KAAK,UAAU,SAAS,CAAC,cAAc;EAC1D,CAAC;AAEL;AAoBM,SAAU,cAAc,OAAiBC,OAAe,KAAa;AACzE,MAAM,UAAU,IAAI,IAAI,KAAK;AAC7B,MAAM,cAAc,QAAQ;AAE5B,QAAMA,OAAM;IACV,WAAS,SAAC,MAAI;AACZ,UAAI,QAAQ,OAAO,KAAK,KAAK,KAAK,MAAM,CAAC,OAAO,CAAC,QAAQ,OAAO;AAC9D,eAAO;MACT;IACF;GACD;AAID,SAAO,MAAM,CAAC,QAAQ,OAAO,QAAQ,OAAO;AAC9C;AAEM,SAAU,iBAAiB,UAAsB;AACrD,SAAO,YAAY,cAAc,CAAC,UAAU,QAAQ,GAAG,UAAU,IAAI;AACvE;AAOA,SAAS,qBAAqBC,KAAkC;MAAxB,QAAKA,IAAA,KAAA;AAC3C,SAAO,UAAU,UAAU,UAAU;AACvC;AAEM,SAAU,uBACd,YAAwC;AAExC,MAAMC,UAA8B,CAAA;AAEpC,MAAI,cAAc,WAAW,QAAQ;AACnC,eAAW,QAAQ,SAAC,WAAS;AAC3B,UAAI,CAAC,qBAAqB,SAAS;AAAG;AAEtC,UAAM,qBAAqB,UAAU;AACrC,UAAM,gBAAgB,UAAU,KAAK;AAErC,MAAAC,WACE,sBAAsB,mBAAmB,WAAW,GACpD,IAAA,aAAA;AAIF,UAAM,aAAa,mBAAoB,CAAC;AACxC,MAAAA,WACE,WAAW,QAAQ,WAAW,KAAK,UAAU,MAC7C,IAAA,aAAA;AAIF,UAAM,UAAqB,WAAW;AAGtC,MAAAA,WACE,YACG,QAAQ,SAAS,cAAc,QAAQ,SAAS,iBACnD,IAAA,aAAA;AAIF,MAAAD,QAAO,KAAK,EAAE,WAAW,WAAU,CAAE;IACvC,CAAC;EACH;AAEA,SAAOA;AACT;;;AChIA,IAAME,mBAAkB,MAAM,uBAAO,OAAO,IAAI;AAGhD,IAAM,EAAE,SAAAC,UAAS,OAAAC,OAAK,IAAK,MAAM;AACjC,IAAM,EAAE,gBAAAC,gBAAc,IAAK,OAAO;AAE5B,IAAOC,QAAP,MAAO,MAAI;EAQf,YACU,WAAW,MACX,WAAmCJ,kBAAe;AADlD,SAAA,WAAA;AACA,SAAA,WAAA;EACP;EAGI,SAAM;AACX,WAAO,KAAK,YAAY,SAAS;EACnC;EAEO,YAA0C,OAAQ;AACvD,QAAI,OAAmB;AACvB,IAAAC,SAAQ,KAAK,OAAO,SAAO,OAAO,KAAK,aAAa,GAAG,CAAC;AACxD,WAAOE,gBAAe,KAAK,MAAM,MAAM,IACnC,KAAK,OACL,KAAK,OAAO,KAAK,SAASD,OAAM,KAAK,KAAK,CAAC;EACjD;EAGO,OAAI;AACT,WAAO,KAAK,UAAU,SAAS;EACjC;EAEO,UAAwC,OAAQ;AACrD,QAAI,OAA+B;AAEnC,aAAS,IAAI,GAAG,MAAM,MAAM,QAAQ,QAAQ,IAAI,KAAK,EAAE,GAAG;AACxD,YAAM,MAAM,KAAK,OAAO,MAAM,CAAC,GAAG,KAAK;AACvC,aAAO,OAAO,IAAI,IAAI,MAAM,CAAC,CAAC;;AAGhC,WAAO,QAAQ,KAAK;EACtB;EAGO,SAAM;AACX,WAAO,KAAK,YAAY,SAAS;EACnC;EAEO,YAA0C,OAAQ;AACvD,QAAI;AAEJ,QAAI,MAAM,QAAQ;AAChB,YAAM,OAAO,MAAM,CAAC;AACpB,YAAM,MAAM,KAAK,OAAO,MAAM,KAAK;AACnC,YAAM,QAAQ,OAAO,IAAI,IAAI,IAAI;AACjC,UAAI,OAAO;AACT,eAAO,MAAM,YAAYA,OAAM,KAAK,OAAO,CAAC,CAAC;AAC7C,YAAI,CAAC,MAAM,QAAQ,CAAC,MAAM,QAAQ,EAAE,MAAM,UAAU,MAAM,OAAO,OAAO;AACtE,cAAI,OAAO,IAAI;;;WAGd;AACL,aAAO,KAAK;AACZ,aAAO,KAAK;;AAGd,WAAO;EACT;EAEQ,aAAa,KAAQ;AAC3B,UAAM,MAAM,KAAK,OAAO,KAAK,IAAI;AACjC,QAAI,QAAQ,IAAI,IAAI,GAAG;AACvB,QAAI,CAAC;AAAO,UAAI,IAAI,KAAK,QAAQ,IAAI,MAAW,KAAK,UAAU,KAAK,QAAQ,CAAC;AAC7E,WAAO;EACT;EAEQ,OAAO,KAAU,QAAe;AACtC,WAAO,KAAK,YAAYG,UAAS,GAAG,IAChC,KAAK,SAAS,SAAS,KAAK,OAAO,oBAAI,YAAU,UACjD,KAAK,WAAW,SAAS,KAAK,SAAS,oBAAI,QAAM;EACvD;;AAGF,SAASA,UAAS,OAAU;AAC1B,UAAQ,OAAO,OAAO;IACtB,KAAK;AACH,UAAI,UAAU;AAAM;IAEtB,KAAK;AACH,aAAO;;AAET,SAAO;AACT;;;ACrGA,IAAM,gBAAgB,MAAM,WAAA;AAAM,SAAA,UAAU;AAAV,CAAiB,KAAK;AAEjD,IAAM,gBACX,OAAO,YAAY,cACnB,EAAE,iBAAiB,CAAE,OAAe;AAE/B,IAAM,gBAAgB,OAAO,YAAY;AAEzC,IAAM,eACX,OAAO,WAAW,cAAc,OAAO,OAAO,QAAQ;AAEjD,IAAM,4BAA4B,gBAAgB,OAAO;AAEzD,IAAM,YACX,OAAO,MAAM,WAAA;AAAM,SAAA,OAAO,SAAS;AAAhB,CAA6B,MAAM;AAExD,IAAM;;;;;;;;;EASJ,MAAM,WAAA;AAAM,WAAA,UAAU,UAAU,QAAQ,OAAO,KAAK;EAAxC,CAAyC,KAAK;;;;AC3BtD,SAAU,gBAAgB,KAAQ;AACtC,SAAO,QAAQ,QAAQ,OAAO,QAAQ;AACxC;;;;ACgCM,SAAU,yBACd,UACA,cAAqB;AAErB,MAAI,qBAAqB;AAKzB,MAAM,YAA2C,CAAA;AACjD,WAAS,YAAY,QAAQ,SAAC,YAAU;AAGtC,QAAI,WAAW,SAAS,uBAAuB;AAC7C,YAAM;QAEF;QAIL,WAAA;QACD,WAAA,OAAA,WAAA,OAAA,WAAA,KAAA,OAAgE,GAAA,IAAA;MAChE;IACA;AAGC,QAAA,WAAA,SAAA,sBAAA;AAEH,gBAAA,KAAA,UAAA;IACA;EACA,CAAA;AAOA,MAAC,OAAA,uBAAA,aAAA;AAED,IAAAC,WAAA,UAAA,WAAA,GAAA,IAAA,UAAA,MAAA;AACA,yBAAyB,UAAA,CAAA,EAAA,KAAA;EACzB;cAKM,SAAA,SAAA,CAAA,GAAA,QAAA,GAA+B,EAAA,aAAA,cAAA;;MAE/B,MAAA;;iBAEE;oBACE;;oBAEM;;kBAEF;kBACD;cACF,MAAA;cACF,OAAA;YACF;UACF;QACW;MAIJ;IACb;EAaD,GAAA,SAAA,aAAA,IAAA,EAAA,CAAA;AACA,SAAA;AACA;AAIE,SAAU,kBAAS,WAAQ;MACzB,cAAS,QAAa;AAAC,gBAAS,CAAA;EAAQ;AAC1C,MAAG,WAAA,CAAA;AACH,YAAO,QAAS,SAAA,UAAA;AACjB,aAAA,SAAA,KAAA,KAAA,IAAA;EAED,CAAA;AAIE,SAAA;;SAEI,yBAAiB,WAAA,aAAA;UACnB,UAAK,MAAA;SACH;AACA,aAAI;2BACK;AACT,UAAC,eAAA,UAAA,KAAA;AACD,UAAM,OAAA,gBAAsB,YAAI;AAChC,eAAU,YAAU,YAAA;MACpB;AACD,UAAA,WAAA,eAAA,YAAA,YAAA;AACD,MAAAA,WAAA,UAAA,IAAA,YAAA;AACE,aAAO,YAAK;IACf;IACF;;;;;;ACzID,IAAM,mBAAmB,oBAAI,QAAO;AACpC,SAAS,SAAS,OAAqB;AACrC,MAAI,MAAM,SAAS,MAAM,OAAO,KAAK;AACnC;EACF;AACA,MAAI,CAAC,iBAAiB,IAAI,KAAK,GAAG;AAChC,qBAAiB,IAAI,KAAK;AAC1B,eAAW,WAAA;AACT,YAAM,MAAK;AACX,uBAAiB,OAAO,KAAK;IAC/B,GAAG,GAAG;EACR;AACF;AAYO,IAAM,uBAAuB,SAClC,KACA,SAAsD;AAStD,MAAM,QAAQ,IAAI,UAAU,KAAK,OAAO;AACxC,QAAM,MAAM,SAAU,KAAU,OAAU;AACxC,QAAM,MAAM,UAAU,UAAU,IAAI,KAAK,MAAM,KAAK,KAAK;AACzD,aAAS,IAA6B;AACtC,WAAO;EACT;AACA,SAAO;AACT;AAiBO,IAAM,yBAAyB,SACpC,KACA,SAAsD;AAStD,MAAM,QAAQ,IAAI,YAAY,KAAK,OAAO;AAC1C,QAAM,MAAM,SAAU,KAAU,OAAU;AACxC,QAAM,MAAM,YAAY,UAAU,IAAI,KAAK,MAAM,KAAK,KAAK;AAC3D,aAAS,IAA6B;AACtC,WAAO;EACT;AACA,SAAO;AACT;;;;ACkMA,IAAM,kBAAkB,OAAO,IAAI,kBAAkB;AAuB9C,IAAM,aAAU,SAAA,CAAA,GAA6B,eAAO,eAAe,CAAC;;;;AClS3E,IAAM,eAIF,CAAA;AAEE,SAAU,oBACd,MACA,SAAqB;AAErB,eAAa,IAAI,IAAI;AACvB;AA4CO,IAAM,iCACX,WAAS,YAAA,QACN,kCAGD;AAMG,IAAM,kCACX,WAAS,YAAA,QACN,mCAGD;AAMG,IAAM,gCACX,WAAS,YAAA,QACN,iCAGD;AAEJ,SAAS,uBAAoB;AAE3B,MAAM,WAA6C;IACjD,QAAM;IACN,oBAAkB;IAClB,OAAK;IACL,2BAAyB;IACzB,gCAA8B;IAE9B,2CAAyC;IAEzC,8BAA4B;IAE5B,2BAAyB;IACzB,wCAAsC;IAEtC,gCAA8B;IAE9B,sDAAoD;IAEpD,qCAAmC;IAEnC,qCAAmC;IAEnC,yCAAuC;;AAGzC,SAAO,OAAO,YACZ,OAAO,QAAQ,QAAQ,EAAE,IAAI,SAACC,KAAM;QAAL,IAACA,IAAA,CAAA,GAAE,IAACA,IAAA,CAAA;AAAM,WAAA;MACvC;MACA,WAAW,CAAqB,KAAK;;EAFE,CAGxC,CAAC;AAEN;AAEA,SAAS,kCAA+B;;AACtC,MAAI,EAAC,WAAO,YAAA;AAAE,UAAM,IAAI,MAAM,oCAAoC;AAElE,SAAO;IACL,QAAQ,qBAAoB;IAC5B,OAAK,SAAA,EACH,QAAOA,MAAA,aAAa,WAAK,QAAAA,QAAA,SAAA,SAAAA,IAAA,KAAA,YAAA,GACzB,SAAQ,KAAA,aAAa,YAAM,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA,YAAA,GAC3B,qBAAoB,KAAA,aAAa,wBAAkB,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA,YAAA,GACnD,OAAO,SAAS,KAAK,IAAI,GACzB,cAAc;MACZ,iBAAiB,KAAK,cAAc,EAAE,gBAAgB,EAAE;MACxD,oBAAoB,cAClB,KAAK,cAAc,EAAE,iBAAiB;MAEzC,IACG,MAAA,KAAA,KAAK,OAAM,wBAAkB,QAAA,OAAA,SAAA,SAAA,GAAA,KAAA,EAAA,CAG8B;;AAGrE;AAEA,SAAS,iCAA8B;AACrC,SAAO;IACL,OAAO;MACL,wBAAwB,sBAAsB,KAAK,gBAAgB,CAAC;;;AAG1E;AAEA,SAAS,mCAAgC;AACvC,MAAM,YAAY,KAAK,OAAO;AAQ9B,SAAA,SAAA,SAAA,CAAA,GACK,+BAA+B,MAAM,IAAW,CAAC,GAAA,EACpD,8BAA8B,cAAc,KAAK,sBAAsB,CAAC,GACxE,eAAe;IACb,qBAAqB,sBACnB,KAAK,aAAa,EAAE,qBAAqB,CAAC;IAE5C,yBAAyB,sBACvB,KAAK,aAAa,EAAE,yBAAyB,CAAC;IAEhD,qBAAqB,sBAAsB,KAAK,qBAAqB,CAAC;KAExE,kBAAkB;IAChB,qBAAqB,sBACnB,cAAS,QAAT,cAAS,SAAA,SAAT,UAAW,mBAAmB;IAEhC,QAAQ,sBAAsB,cAAS,QAAT,cAAS,SAAA,SAAT,UAAW,MAAM;IAC/C,WAAW,sBAAsB,cAAS,QAAT,cAAS,SAAA,SAAT,UAAW,SAAS;IACtD,CAAA;AAEL;AAEA,SAAS,UAAU,GAAY;AAC7B,SAAO,CAAC,CAAC,KAAK,cAAc;AAC9B;AAEA,SAAS,sBAAsB,GAAY;AACzC,SAAO,UAAU,CAAC,IAAI,EAAE,OAAO;AACjC;AAEA,SAAS,UAAa,OAA2B;AAC/C,SAAO,SAAS;AAClB;AAEA,SAAS,cAAc,WAA6B;AAClD,SAAO,qBAAqB,SAAS,EAAE,IAAI,SAAC,OAAK;AAAK,WAAC,EAAE,MAAK;EAAR,CAAW;AACnE;AAEA,SAAS,qBAAqB,WAA6B;AACzD,SAAO,YACH,cAAA,cAAA;IACE,sBAAsB,cAAS,QAAT,cAAS,SAAA,SAAT,UAAY,aAAa,CAAC;KAC7C,qBAAqB,cAAS,QAAT,cAAS,SAAA,SAAT,UAAY,MAAM,CAAC,GAAC,IAAA,GACzC,qBAAqB,cAAS,QAAT,cAAS,SAAA,SAAT,UAAY,OAAO,CAAC,GAAC,IAAA,EAC7C,OAAO,SAAS,IAClB,CAAA;AACN;AAEA,SAAS,SAAS,MAAiB;;AACjC,SAAO,OACH,cAAA,cAAA;KACEA,MAAA,SAAI,QAAJ,SAAI,SAAA,SAAJ,KAAM,wBAAkB,QAAAA,QAAA,SAAA,SAAAA,IAAA,KAAA,IAAA;KACrB,SAAS,SAAI,QAAJ,SAAI,SAAA,SAAJ,KAAM,IAAI,GAAC,IAAA,GACpB,SAAS,SAAI,QAAJ,SAAI,SAAA,SAAJ,KAAM,KAAK,GAAC,IAAA,EACxB,OAAO,SAAS,IAClB,CAAA;AACN;;;AC3MO,IAAM,qBAAqB,OAAO,OACvC,SAASC,oBAAmB,OAAU;AACpC,SAAO,KAAK,UAAU,OAAO,oBAAoB;AACnD,GACA;EACE,OAAK,WAAA;AAIH,iBAAa,IAAI;MACf,WAAW,sBAAkB;;IAAwC;EAEzE;CACD;AAGH,IAAI,WAAU,YAAA,OAAA;AACZ,sBAAoB,sBAAsB,WAAA;AAAM,WAAA,WAAW;EAAX,CAAe;AACjE;AAIA,IAAI;AACJ,mBAAmB,MAAK;AAQxB,SAAS,qBAAqB,KAAa,OAAU;AACnD,MAAI,SAAS,OAAO,UAAU,UAAU;AACtC,QAAM,QAAQ,OAAO,eAAe,KAAK;AAIzC,QAAI,UAAU,OAAO,aAAa,UAAU,MAAM;AAChD,UAAM,OAAO,OAAO,KAAK,KAAK;AAG9B,UAAI,KAAK,MAAM,eAAe;AAAG,eAAO;AACxC,UAAM,cAAc,KAAK,UAAU,IAAI;AACvC,UAAI,aAAa,WAAW,IAAI,WAAW;AAC3C,UAAI,CAAC,YAAY;AACf,aAAK,KAAI;AACT,YAAM,YAAY,KAAK,UAAU,IAAI;AAGrC,qBAAa,WAAW,IAAI,SAAS,KAAK;AAC1C,mBAAW,IAAI,aAAa,UAAU;AACtC,mBAAW,IAAI,WAAW,UAAU;MACtC;AACA,UAAM,iBAAe,OAAO,OAAO,KAAK;AAGxC,iBAAW,QAAQ,SAACC,MAAG;AACrB,uBAAaA,IAAG,IAAI,MAAMA,IAAG;MAC/B,CAAC;AACD,aAAO;IACT;EACF;AACA,SAAO;AACT;AAMA,SAAS,gBACP,KACA,GACA,MAAuB;AAEvB,SAAO,MAAM,KAAK,KAAK,IAAI,CAAC,KAAK;AACnC;;;ACnEM,SAAU,cAAc,IAAU;AACtC,SAAO,EAAE,OAAO,OAAO,EAAE,EAAC;AAC5B;AAEM,SAAU,YAAY,KAAQ;AAClC,SAAO,QACL,OAAO,OAAO,QAAQ,YAAY,OAAO,IAAI,UAAU,QAAQ;AAEnE;AAoCM,SAAU,eAAe,OAAU;AACvC,SACE,gBAAgB,KAAK,KACpB,MAAuB,SAAS,cACjC,MAAM,QAAS,MAAuB,WAAW;AAErD;AAEA,SAAS,cAAc,OAAgB;AACrC,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,eAAe,OAAgB;AACtC,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,WAAW,OAAgB;AAClC,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,aAAa,OAAgB;AACpC,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,WAAW,OAAgB;AAClC,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,cAAc,OAAgB;AACrC,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,YAAY,OAAgB;AACnC,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,YAAY,OAAgB;AACnC,SAAO,MAAM,SAAS;AACxB;AAEA,SAAS,YAAY,OAAgB;AACnC,SAAO,MAAM,SAAS;AACxB;AAEM,SAAU,4BACd,QACA,MACA,OACA,WAAkB;AAElB,MAAI,WAAW,KAAK,KAAK,aAAa,KAAK,GAAG;AAC5C,WAAO,KAAK,KAAK,IAAI,OAAO,MAAM,KAAK;EACzC,WAAW,eAAe,KAAK,KAAK,cAAc,KAAK,GAAG;AACxD,WAAO,KAAK,KAAK,IAAI,MAAM;EAC7B,WAAW,cAAc,KAAK,GAAG;AAC/B,QAAM,iBAAe,CAAA;AACrB,UAAM,OAAO,IAAI,SAAC,KAAG;AACnB,aAAA,4BAA4B,gBAAc,IAAI,MAAM,IAAI,OAAO,SAAS;IAAxE,CAAyE;AAE3E,WAAO,KAAK,KAAK,IAAI;EACvB,WAAW,WAAW,KAAK,GAAG;AAC5B,QAAM,iBAAiB,aAAc,CAAA,GAAY,MAAM,KAAK,KAAK;AACjE,WAAO,KAAK,KAAK,IAAI;EACvB,WAAW,YAAY,KAAK,GAAG;AAC7B,WAAO,KAAK,KAAK,IAAI,MAAM,OAAO,IAAI,SAAC,WAAS;AAC9C,UAAM,oBAAoB,CAAA;AAC1B,kCACE,mBACA,MACA,WACA,SAAS;AAEX,aAAQ,kBAA0B,KAAK,KAAK;IAC9C,CAAC;EACH,WAAW,YAAY,KAAK,GAAG;AAC7B,WAAO,KAAK,KAAK,IAAK,MAAwB;EAChD,WAAW,YAAY,KAAK,GAAG;AAC7B,WAAO,KAAK,KAAK,IAAI;EACvB,OAAO;AACL,UAAM,kBACJ,IAAA,KAAA,OAAA,MAAA,IAAA;;;AAMH,SAAA,sBAAA,OAAA,WAAA;AACF,MAAA,gBAAA;AAED,MAAM,MAAA,YAAU;AAIV,oBAAqB,CAAA;AACrB,UAAM,WAAU,QAAG,SAAA,WAAA;AACrB,oBAAkB,UAAC,KAAA,KAAA,IAAA,CAAA;AACnB,UAAM,UAAW,WAAQ;AACvB,kBAAc,UAAU,QAAK,SAAYC,KAAA;AAErC,cAAA,OAAUA,IAAA,MAAY,QAAAA,IAAA;AACxB,iBAAU,4BAAmB,cAAe,UAAA,KAAA,KAAA,GAAA,MAAA,OAAA,SAAA;;;;;MAShD,SAAG;AACL,MAAC,MAAA,aAAA,MAAA,UAAA,QAAA;AAEG,aAAc,CAAA;AACd,UAAM,UAAS,QAAS,SAAUA,KAAC;AACrC,UAAM,OAAMA,IAAA,MAAA,QAAAA,IAAA;AACZ,aAAM,4BAAkC,QAAA,MAAA,OAAA,SAAA;;;SAEtC,gBAAA,MAAA,KAAA,OAAA,QAAA,aAAA;;IAGJ,mBAAO;EACR;EAQK;EACJ;EACA;EACA;EACA;EACA;;AAMF,IAAA,wBAAA;AACA,IAAA,kBAAA,OAAA,OAAA,SAAA,WAAsD,MAAA,YAAA;AAClD,MAAA,QAEG,cAOD,WAAI,YAAA,KACJ,WAAU,YAAA,EAAA,KAAA,GAAA;AACV,QAAA,WAAW,YAAa,EAAA,QAAA,KACxB,WAAW,YAAc,EAAA,QACxB,EAAA,SAAA,GAAA;AAEC,UAAA,aAAW,WAAc,YAAS,EAAA,QAAA,IACjC,WAAW,YAAc,EAAA,QAAuB,IAE3C,CAAA;iBAED,KAAW;UACd,iBAAK,CAAA;AACP,iBAAW,QAAO,SAAA,KAAA;AAEZ,uBAAY,GAAG,IAA6B,KAAA,GAAA;MAClD,CAAA;aACE,GAAA,OAAA,WAAoB,YAAU,EAAA,KAAA,GAAA,GAAA,EAAA,OAAA,sBAAA,cAAA,GAAA,GAAA;WAGhC;AAGD,aAAA,WAAA,YAAA,EAAA,KAAA;;;MAED,oBAAC;AACH,MAAC,MAAA;AAMC,QAAA,kBAAA,sBAAA,IAAA;AACA,yBAAA,IAAA,OAAA,iBAAA,GAAA;;MAEA,YAAA;AACD,WAAA,KAAA,UAAA,EAAA,QAAA,SAAA,KAAA;AAEG,UAAA,iBAAa,QAAA,GAAA,MAAA;AACR;AACL,UAAI,WAAA,GAAA,KAAiB,OAAQ,KAAI,WAAO,GAAA,CAAA,EAAA,QAAA;AAAE,6BAAO,IAAA,OAAA,KAAA,GAAA,EAAA,OAAA,sBAAA,WAAA,GAAA,CAAA,GAAA,GAAA;MACjD,OACE;AAGD,6BAAA,IAAA,OAAA,GAAA;;;;SAGA;;EAGL,cAAO,SAAiB,GAAC;AAE3B,QAAA,WAAA;AACE,4BAA4C;AAC1C,WAAM;;;AAGP,SAAA,yBAAA,OAAA,WAAA;AAEH,MAAA,MAAA,aAAA,MAAA,UAAA,QAAA;AAEI,QAAA,WAAU,CAAA;AAIV,UAAM,UAAS,QAAS,SAAUA,KAAC;AAC/B,UAAA,OAAiBA,IAAG,MAAA,QAAAA,IAAA;AAC1B,aAAM,4BAAkC,UAAA,MAAA,OAAA,SAAA;;WACtC;;SAEF;;AAEF,SAAY,uBAAA,OAAA;AACb,SAAA,MAAA,QAAA,MAAA,MAAA,QAAA,MAAA,KAAA;AAED;AACE,SAAY,sBAAqBC,SAAQ,cAAW,aAAM;AAC3D,MAAA;AAED,WAAM,KAAU,GAAAD,MAAA,aACd,YACA,KAAAA,IAA8B,QAC9B,MAAyB;AAErB,QAAA,YAAsEA,IAAA,EAAA;AAC1E,QAAwB,QAAuB,SAAvB,GAAA;AAAb,UAAA,UAAS,KAAA,UAAA,cAAA;AACd,eAAQC,QAAU,uBAAG,SAAA,CAAA;MACvB;eAEC,WAAA;AACF,gBAAA,KAAA,SAAA;WACC;AACD,kBAAA,CAAA,SAAA;;;MAED,OAACA,QAAA,eAAA,UAAA;AACF,WAAAA,QAAA;EACD;MACE,WAAO;AACR,aAAA,KAAA,GAAA,cAAA,WAAA,KAAA,YAAA,QAAA,MAAA;AACG,UAAA,YAAY,YAAA,EAAA;AACd,UAAwB,WAAA,sBAASA,SAAT,yBAAY,WAAA,WAAA,EAAA,cAAA,WAAA;AAA/B,UAAM,OAAA,aAAS,UAAA;AACZ,eAAA;MAKN;;;;AAIH,SAAA,QAAA,WAAA;AACF,SAAA,UAAA,SAAA;AAED;AACE,SAAO,iBAAmB,WAAQ;AACnC,SAAA,UAAA,SAAA;AAED;;;ACzUM,SAAU,cAAc,KAAiB;AAC7C,EAAAC,WACE,OAAO,IAAI,SAAS,YACpB,EAAA;AAIF,MAAM,aAAa,IAAI,YACpB,OAAO,SAAC,GAAC;AAAK,WAAA,EAAE,SAAS;EAAX,CAA+B,EAC7C,IAAI,SAAC,YAAU;AACd,QAAI,WAAW,SAAS,uBAAuB;AAC7C,YAAM,kBACJ,IAAA,WAAA,IAAA;IAGJ;AACA,WAAO;EACT,CAAC;AAEH,EAAAA,WACE,WAAW,UAAU,GACrB,IAAA,WAAA,MAAA;AAIF,SAAO;AACT;AAEM,SAAU,uBACd,KAAiB;AAEjB,gBAAc,GAAG;AACjB,SAAO,IAAI,YAAY,OACrB,SAAC,YAAU;AACT,WAAA,WAAW,SAAS;EAApB,CAAyC,EAC3C,CAAC;AACL;AAEM,SAAU,iBAAiB,KAAiB;AAChD,SACE,IAAI,YACD,OACC,SAAC,YAAU;AACT,WAAA,WAAW,SAAS,yBAAyB,CAAC,CAAC,WAAW;EAA1D,CAA8D,EAEjE,IAAI,SAAC,GAAC;AAAK,WAAA,EAAE,KAAK;EAAP,CAAY,EAAE,CAAC,KAAK;AAEtC;AAGM,SAAU,uBACd,KAAiB;AAEjB,SAAO,IAAI,YAAY,OACrB,SAAC,YAAU;AACT,WAAA,WAAW,SAAS;EAApB,CAAwC;AAE9C;AAEM,SAAU,mBAAmB,KAAiB;AAClD,MAAM,WAAW,uBAAuB,GAAG;AAE3C,EAAAA,WACE,YAAY,SAAS,cAAc,SACnC,EAAA;AAGF,SAAO;AACT;AAEM,SAAU,sBACd,KAAiB;AAEjB,EAAAA,WACE,IAAI,SAAS,YACb,EAAA;AAIF,EAAAA,WACE,IAAI,YAAY,UAAU,GAC1B,EAAA;AAGF,MAAM,cAAc,IAAI,YAAY,CAAC;AAErC,EAAAA,WACE,YAAY,SAAS,sBACrB,EAAA;AAGF,SAAO;AACT;AAOM,SAAU,kBACd,UAAsB;AAEtB,gBAAc,QAAQ;AAEtB,MAAI;AAEJ,WAAuB,KAAA,GAAAC,MAAA,SAAS,aAAT,KAAAA,IAAA,QAAA,MAAsB;AAAxC,QAAI,aAAUA,IAAA,EAAA;AACjB,QAAI,WAAW,SAAS,uBAAuB;AAC7C,UAAM,YAAa,WAAuC;AAC1D,UACE,cAAc,WACd,cAAc,cACd,cAAc,gBACd;AACA,eAAO;MACT;IACF;AACA,QAAI,WAAW,SAAS,wBAAwB,CAAC,oBAAoB;AAGnE,2BAAqB;IACvB;EACF;AAEA,MAAI,oBAAoB;AACtB,WAAO;EACT;AAEA,QAAM,kBACJ,EAAA;AAEJ;AAEM,SAAU,iBACd,YAA+C;AAE/C,MAAM,gBAAgB,uBAAO,OAAO,IAAI;AACxC,MAAM,OAAO,cAAc,WAAW;AACtC,MAAI,QAAQ,KAAK,QAAQ;AACvB,SAAK,QAAQ,SAAC,KAAG;AACf,UAAI,IAAI,cAAc;AACpB,oCACE,eACA,IAAI,SAAS,MACb,IAAI,YAAyB;MAEjC;IACF,CAAC;EACH;AACA,SAAO;AACT;;;ACtIA,SAAS,SAAS,UAAsB;AACtC,SAAO;AACT;AAEA,IAAA;;EAAA,WAAA;AA4CE,aAAAC,mBACE,WACA,SAAuD;AAAvD,UAAA,YAAA,QAAA;AAAA,kBAAoC,uBAAO,OAAO,IAAI;MAAC;AA1CxC,WAAA,cACf,gBAAgB,oBAAI,QAAO,IAAmB,oBAAI,IAAG;AA2CrD,WAAK,YAAY;AAEjB,UAAI,QAAQ,aAAa;AAEvB,aAAK,cAAc,QAAQ;MAC7B;AACA,WAAK,SAAS,QAAQ,UAAU;AAEhC,WAAK,WAAU;IACjB;AA7CQ,IAAAA,mBAAA,UAAA,cAAR,SACE,UAAsB;AAEtB,aAAO,CAAC,QAAQ;IAClB;AAEO,IAAAA,mBAAA,WAAP,WAAA;AAIE,aAAO,IAAIA,mBAAkB,UAAU,EAAE,OAAO,MAAK,CAAE;IACzD;AAEO,IAAAA,mBAAA,QAAP,SACE,WACA,MACA,OAAuD;AAAvD,UAAA,UAAA,QAAA;AAAA,gBAA2BA,mBAAkB,SAAQ;MAAE;AAEvD,aAAO,OAAO,OACZ,IAAIA;QACF,SAAC,UAAQ;AACP,cAAM,oBAAoB,UAAU,QAAQ,IAAI,OAAO;AAEvD,iBAAO,kBAAkB,kBAAkB,QAAQ;QACrD;;QAEA,EAAE,OAAO,MAAK;MAAE,GAElB,EAAE,MAAM,MAAK,CAAE;IAEnB;AAoBA,IAAAA,mBAAA,UAAA,aAAA,WAAA;AAAA,UAAA,QAAA;AACE,UAAI,KAAK,QAAQ;AACf,YAAM,oBAAkB,IAAIC,MAAc,aAAa;AACvD,aAAK,cAAcC,MACjBF,mBAAkB,UAAU,YAAY,KAAK,IAAI,GACjD;UACE,cAAc,SAAC,UAAQ;AACrB,gBAAM,YAAY,MAAK,YAAY,QAAQ;AAC3C,gBAAI,WAAW;AACb,cAAAG,WACE,MAAM,QAAQ,SAAS,GACvB,EAAA;AAEF,qBAAO,kBAAgB,YAAY,SAAS;YAC9C;UACF;UACA,KAAK,WAAW,yBAAyB;UACzC,OAAO;SACR;MAEL;IACF;AAEQ,IAAAH,mBAAA,UAAA,cAAR,SAAoB,UAAsB;AACxC,oBAAc,QAAQ;AACtB,aAAO,KAAK,UAAU,QAAQ;IAChC;AAEA,IAAAA,mBAAA,UAAA,oBAAA,SAAkB,UAAsB;AAGtC,UAAI,KAAK,YAAY,IAAI,QAAQ,GAAG;AAClC,eAAO;MACT;AAEA,UAAM,sBAAsB,KAAK,YAAY,QAAQ;AAErD,WAAK,YAAY,IAAI,mBAAmB;AAExC,aAAO;IACT;AAEA,IAAAA,mBAAA,UAAA,SAAA,SAAO,gBAAiC;AAAxC,UAAA,QAAA;AACE,aAAO,OAAO,OACZ,IAAIA;QACF,SAAC,UAAQ;AACP,iBAAO,eAAe,kBACpB,MAAK,kBAAkB,QAAQ,CAAC;QAEpC;;QAEA,EAAE,OAAO,MAAK;MAAE,GAElB;QACE,MAAM;QACN,OAAO;OACR;IAEL;AAYF,WAAAA;EAAA,EApIA;;;;AC3BA,IAAI;AACG,IAAMI,SAAQ,OAAO,OAC1B,SAAC,KAAY;AACX,MAAIC,UAAS,WAAW,IAAI,GAAG;AAE/B,MAAI,CAACA,SAAQ;AACX,IAAAA,UAAS,MAAU,GAAG;AACtB,eAAW,IAAI,KAAKA,OAAM;EAC5B;AACA,SAAOA;AACT,GACA;EACE,OAAK,WAAA;AACH,iBAAa,IAAI;MACf,WAAW,SAAK;;IAA2B;EAE/C;CACD;AAEHD,OAAM,MAAK;AAEX,IAAI,WAAU,YAAA,OAAA;AACZ,sBAAoB,SAAS,WAAA;AAAM,WAAC,aAAa,WAAW,OAAO;EAAhC,CAAkC;AACvE;;;;;;AC/BO,IAAM,UAAmD,MAAM;AAEhE,SAAU,gBAAmB,OAAoB;AACrD,SAAO,MAAM,QAAQ,KAAK,KAAK,MAAM,SAAS;AAChD;;;ACqDA,IAAM,iBAA4B;EAChC,MAAM,KAAK;EACX,MAAM;IACJ,MAAM,KAAK;IACX,OAAO;;;AAIX,SAAS,QACP,IACA,aAAwB;AAExB,SACE,CAAC,MACD,GAAG,aAAa,WAAW,MACzB,SAAC,WAAS;AACR,WAAA,UAAU,SAAS,KAAK,mBACxB,QAAQ,YAAY,UAAU,KAAK,KAAK,GAAG,WAAW;EADtD,CACuD;AAG/D;AAEA,SAAS,iBAAiB,KAAiB;AACzC,SACI,QACE,uBAAuB,GAAG,KAAK,sBAAsB,GAAG,GACxD,kBAAkB,uBAAuB,GAAG,CAAC,CAAC,IAGhD,OACA;AACN;AAEA,SAAS,oBACP,SAAuD;AAEvD,MAAM,QAAQ,oBAAI,IAAG;AAErB,MAAM,QAAQ,oBAAI,IAAG;AAKrB,UAAQ,QAAQ,SAAC,WAAS;AACxB,QAAI,WAAW;AACb,UAAI,UAAU,MAAM;AAClB,cAAM,IAAI,UAAU,MAAM,SAAS;MACrC,WAAW,UAAU,MAAM;AACzB,cAAM,IAAI,UAAU,MAAM,SAAS;MACrC;IACF;EACF,CAAC;AAED,SAAO,SAAC,WAAwB;AAC9B,QAAI,SAAS,MAAM,IAAI,UAAU,KAAK,KAAK;AAC3C,QAAI,CAAC,UAAU,MAAM,MAAM;AACzB,YAAM,QAAQ,SAAC,YAAY,MAAI;AAC7B,YAAI,KAAK,SAAS,GAAG;AACnB,mBAAS;QACX;MACF,CAAC;IACH;AACA,WAAO;EACT;AACF;AAcA,SAAS,wBAA8B,YAAgB;AACrD,MAAM,MAAM,oBAAI,IAAG;AAEnB,SAAO,SAAS,oBACd,KAAsB;AAAtB,QAAA,QAAA,QAAA;AAAA,YAAA;IAAsB;AAEtB,QAAI,QAAQ,IAAI,IAAI,GAAG;AACvB,QAAI,CAAC,OAAO;AACV,UAAI,IACF,KACC,QAAQ;;;;;QAKP,WAAW,oBAAI,IAAG;QAClB,iBAAiB,oBAAI,IAAG;OACxB;IAEN;AACA,WAAO;EACT;AACF;AAEM,SAAU,6BACd,YACA,KAAiB;AAEjB,gBAAc,GAAG;AAMjB,MAAM,0BAA0B,wBAAgC,EAAE;AAClE,MAAM,yBAAyB,wBAAgC,EAAE;AACjE,MAAM,WAAW,SACf,WAAoD;AAEpD,aACM,IAAI,GAAG,WAAQ,QACnB,IAAI,UAAU,WAAW,WAAW,UAAU,CAAC,IAC/C,EAAE,GACF;AACA,UAAI,QAAQ,QAAQ;AAAG;AACvB,UAAI,SAAS,SAAS,KAAK,sBAAsB;AAE/C,eAAO,wBAAwB,SAAS,QAAQ,SAAS,KAAK,KAAK;MACrE;AACA,UAAI,SAAS,SAAS,KAAK,qBAAqB;AAC9C,eAAO,uBAAuB,SAAS,KAAK,KAAK;MACnD;IACF;AACA,eAAU,YAAM,SAAAE,WAAA,MAAA,EAAA;AAChB,WAAO;EACT;AAEA,MAAI,iBAAiB;AACrB,WAAS,IAAI,IAAI,YAAY,SAAS,GAAG,KAAK,GAAG,EAAE,GAAG;AACpD,QAAI,IAAI,YAAY,CAAC,EAAE,SAAS,KAAK,sBAAsB;AACzD,QAAE;IACJ;EACF;AAEA,MAAM,mBAAmB,oBAAoB,UAAU;AACvD,MAAM,oBAAoB,SAAC,gBAAuC;AAChE,WAAA,gBAAgB,cAAc,KAC9B,eACG,IAAI,gBAAgB,EACpB,KACC,SAAC,QAAyC;AAAK,aAAA,UAAU,OAAO;IAAjB,CAAuB;EAJ1E;AAOF,MAAM,6BAA6B,oBAAI,IAAG;AAO1C,MAAI,wBAAwB;AAE5B,MAAM,+BAEF;IACF,OAAK,SAAC,MAAI;AACR,UAAI,kBAAkB,KAAK,UAAU,GAAG;AACtC,gCAAwB;AACxB,eAAO;MACT;IACF;;AAGF,MAAM,8BAA8B,MAAM,KAAK;;IAE7C,OAAO;IACP,gBAAgB;IAEhB,oBAAoB;MAClB,OAAK,WAAA;AAKH,eAAO;MACT;;IAGF,UAAU;MACR,OAAK,SAAC,MAAM,MAAM,SAAS,OAAO,WAAS;AACzC,YAAM,QAAQ,SAAS,SAAS;AAChC,YAAI,OAAO;AACT,gBAAM,UAAU,IAAI,KAAK,KAAK,KAAK;QACrC;MACF;;IAGF,gBAAgB;MACd,OAAK,SAAC,MAAM,MAAM,SAAS,OAAO,WAAS;AACzC,YAAI,kBAAkB,KAAK,UAAU,GAAG;AACtC,kCAAwB;AACxB,iBAAO;QACT;AACA,YAAM,QAAQ,SAAS,SAAS;AAChC,YAAI,OAAO;AACT,gBAAM,gBAAgB,IAAI,KAAK,KAAK,KAAK;QAC3C;MAMF;;IAGF,oBAAoB;MAClB,OAAK,SAAC,MAAM,MAAM,SAAS,MAAI;AAC7B,mCAA2B,IAAI,KAAK,UAAU,IAAI,GAAG,IAAI;MAC3D;MACA,OAAK,SAAC,MAAM,MAAM,SAAS,MAAI;AAC7B,YAAM,eAAe,2BAA2B,IAC9C,KAAK,UAAU,IAAI,CAAC;AAEtB,YAAI,SAAS,cAAc;AAOzB,iBAAO;QACT;AAEA;;;;UAIE,iBAAiB,KACjB,KAAK,aAAa,WAAW,MAC3B,SAAC,WAAS;AACR,mBAAA,UAAU,SAAS,KAAK,SACxB,UAAU,KAAK,UAAU;UADzB,CACqC;UAEzC;AAIA,iCAAuB,KAAK,KAAK,KAAK,EAAE,UAAU;AAClD,kCAAwB;AACxB,iBAAO;QACT;MACF;;IAGF,WAAW;MACT,OAAK,SAAC,MAAI;AAIR,YAAI,iBAAiB,IAAI,GAAG;AAC1B,kCAAwB;AACxB,iBAAO;QACT;MACF;;GAEH;AAED,MAAI,CAAC,uBAAuB;AAG1B,WAAO;EACT;AAOA,MAAM,yBAAyB,SAAC,OAAwB;AACtD,QAAI,CAAC,MAAM,gBAAgB;AACzB,YAAM,iBAAiB,IAAI,IAAI,MAAM,SAAS;AAC9C,UAAI,CAAC,MAAM,SAAS;AAClB,cAAM,gBAAgB,QAAQ,SAAC,mBAAiB;AAC9C,iCACE,uBAAuB,iBAAiB,CAAC,EACzC,eAAgB,QAAQ,SAAC,SAAO;AAChC,kBAAM,eAAgB,IAAI,OAAO;UACnC,CAAC;QACH,CAAC;MACH;IACF;AACA,WAAO;EACT;AAKA,MAAM,uBAAuB,oBAAI,IAAG;AACpC,8BAA4B,YAAY,QAAQ,SAAC,KAAG;AAClD,QAAI,IAAI,SAAS,KAAK,sBAAsB;AAC1C,6BACE,wBAAwB,IAAI,QAAQ,IAAI,KAAK,KAAK,CAAC,EACnD,gBAAgB,QAAQ,SAAC,mBAAiB;AAC1C,6BAAqB,IAAI,iBAAiB;MAC5C,CAAC;IACH,WACE,IAAI,SAAS,KAAK;;;;IAKlB,mBAAmB,KACnB,CAAC,uBAAuB,IAAI,KAAK,KAAK,EAAE,SACxC;AACA,2BAAqB,IAAI,IAAI,KAAK,KAAK;IACzC;EACF,CAAC;AAID,uBAAqB,QAAQ,SAAC,cAAY;AAGxC,2BACE,uBAAuB,YAAY,CAAC,EACpC,gBAAgB,QAAQ,SAAC,mBAAiB;AAC1C,2BAAqB,IAAI,iBAAiB;IAC5C,CAAC;EACH,CAAC;AAED,MAAM,wBAAwB,SAAC,cAAoB;AACjD,WAAA,CAAC;;;KAKG,CAAC,qBAAqB,IAAI,YAAY,KACtC,uBAAuB,YAAY,EAAE;EANzC;AAUF,MAAM,eAEF;IACF,OAAK,SAAC,MAAI;AACR,UAAI,sBAAsB,KAAK,KAAK,KAAK,GAAG;AAC1C,eAAO;MACT;IACF;;AAGF,SAAO,iBACL,MAAM,6BAA6B;;;IAGjC,gBAAgB;;IAGhB,oBAAoB;IAEpB,qBAAqB;MACnB,OAAK,SAAC,MAAI;AAGR,YAAI,KAAK,qBAAqB;AAC5B,cAAM,sBAAoB;;YAExB,wBAAwB,KAAK,QAAQ,KAAK,KAAK,KAAK;UAAC,EACrD;AAaF,cAAI,oBAAkB,OAAO,KAAK,oBAAoB,QAAQ;AAC5D,mBAAA,SAAA,SAAA,CAAA,GACK,IAAI,GAAA,EACP,qBAAqB,KAAK,oBAAoB,OAAO,SAAC,QAAM;AAC1D,qBAAA,oBAAkB,IAAI,OAAO,SAAS,KAAK,KAAK;YAAhD,CAAiD,EAClD,CAAA;UAEL;QACF;MACF;;GAEH,CAAC;AAEN;AAEO,IAAM,wBAAwB,OAAO,OAC1C,SAAiC,KAAU;AACzC,SAAO,MAAM,KAAK;IAChB,cAAc;MACZ,OAAK,SAAC,MAAM,MAAM,QAAM;AAEtB,YACE,UACC,OAAmC,SAClC,KAAK,sBACP;AACA;QACF;AAGQ,YAAA,aAAe,KAAI;AAC3B,YAAI,CAAC,YAAY;AACf;QACF;AAIA,YAAM,OAAO,WAAW,KAAK,SAAC,WAAS;AACrC,iBACE,QAAQ,SAAS,MAChB,UAAU,KAAK,UAAU,gBACxB,UAAU,KAAK,MAAM,YAAY,MAAM,CAAC,MAAM;QAEpD,CAAC;AACD,YAAI,MAAM;AACR;QACF;AAIA,YAAM,QAAQ;AACd,YACE,QAAQ,KAAK,KACb,MAAM,cACN,MAAM,WAAW,KAAK,SAAC,GAAC;AAAK,iBAAA,EAAE,KAAK,UAAU;QAAjB,CAAyB,GACtD;AACA;QACF;AAGA,eAAA,SAAA,SAAA,CAAA,GACK,IAAI,GAAA,EACP,YAAU,cAAA,cAAA,CAAA,GAAM,YAAU,IAAA,GAAA,CAAE,cAAc,GAAA,KAAA,EAAA,CAAA;MAE9C;;GAEH;AACH,GACA;EACE,OAAK,SAAC,OAAgB;AACpB,WAAO,UAAU;EACnB;CACD;AAqKH,SAAA,2BAAkC,UAAA;AAClC,MAAM,aAAU,kBAAA,QACd;AAEA,MAAM,sBAAa,WAAkB;AACrC,MAAM,wBAAgD,SAAY;AAGhE,WAAA;;AAIF,MAAA,cAAA,MAAA,UAAA;IACM,qBAAoB;MACxB,OAAA,SAAqB,MAAA;AACnB,eAAK,SAAC,SAAI,CAAA,GAAA,IAAA,GAAA,EAAA,WAAA,QAAA,CAAA;;;;SAOX;;AAIL,SAAA,6BAAA,UAAA;AACA,gBAAgB,QAAA;AAGd,MAAA,cAAc,6BAAU;IAEpB;MAEA,MAAA,SAAA,WAAA;AAAA,eAAA,UAAA,KAAA,UAAA;MAAA;MACE,QAAM;;aAEP;SAEH;;;;;ACzsBJ;;;;ACEQ,IAAAC,kBAAmB,OAAO,UAAS;AAyBrC,SAAU,YAAS;AACvB,MAAA,UAAA,CAAA;WAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAAa;AAAb,YAAA,EAAA,IAAA,UAAA,EAAA;;AAEA,SAAO,eAAe,OAAO;AAC/B;AAQM,SAAU,eAAkB,SAAY;AAC5C,MAAI,SAAS,QAAQ,CAAC,KAAM,CAAA;AAC5B,MAAM,QAAQ,QAAQ;AACtB,MAAI,QAAQ,GAAG;AACb,QAAM,SAAS,IAAI,WAAU;AAC7B,aAAS,IAAI,GAAG,IAAI,OAAO,EAAE,GAAG;AAC9B,eAAS,OAAO,MAAM,QAAQ,QAAQ,CAAC,CAAC;IAC1C;EACF;AACA,SAAO;AACT;AAUA,IAAM,oBAA+C,SACnD,QACA,QACA,UAAQ;AAER,SAAO,KAAK,MAAM,OAAO,QAAQ,GAAG,OAAO,QAAQ,CAAC;AACtD;AAEA,IAAA;;EAAA,WAAA;AACE,aAAAC,YACU,YAA2G;AAA3G,UAAA,eAAA,QAAA;AAAA,qBAA+C;MAA4D;AAA3G,WAAA,aAAA;AAqCH,WAAA,WAAW;AAEV,WAAA,aAAa,oBAAI,IAAG;IAtCzB;AAEI,IAAAA,YAAA,UAAA,QAAP,SAAa,QAAa,QAAW;AAArC,UAAA,QAAA;AAAuC,UAAA,UAAA,CAAA;eAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAAwB;AAAxB,gBAAA,KAAA,CAAA,IAAA,UAAA,EAAA;;AACrC,UAAI,gBAAgB,MAAM,KAAK,gBAAgB,MAAM,GAAG;AACtD,eAAO,KAAK,MAAM,EAAE,QAAQ,SAAC,WAAS;AACpC,cAAID,gBAAe,KAAK,QAAQ,SAAS,GAAG;AAC1C,gBAAM,cAAc,OAAO,SAAS;AACpC,gBAAI,OAAO,SAAS,MAAM,aAAa;AACrC,kBAAME,UAAS,MAAK,WAAU,MAAf,OAAI,cAAA;gBACjB;gBACA;gBACA;cAAS,GACN,SAAO,KAAA,CAAA;AAIZ,kBAAIA,YAAW,aAAa;AAC1B,yBAAS,MAAK,oBAAoB,MAAM;AACxC,uBAAO,SAAS,IAAIA;cACtB;YACF;UACF,OAAO;AAGL,qBAAS,MAAK,oBAAoB,MAAM;AACxC,mBAAO,SAAS,IAAI,OAAO,SAAS;UACtC;QACF,CAAC;AAED,eAAO;MACT;AAGA,aAAO;IACT;AAMO,IAAAD,YAAA,UAAA,sBAAP,SAA8B,OAAQ;AACpC,UAAI,gBAAgB,KAAK,GAAG;AAC1B,YAAI,CAAC,KAAK,WAAW,IAAI,KAAK,GAAG;AAC/B,cAAI,MAAM,QAAQ,KAAK,GAAG;AACxB,oBAAS,MAAc,MAAM,CAAC;UAChC,OAAO;AACL,oBAAK,SAAA,EACH,WAAW,OAAO,eAAe,KAAK,EAAC,GACpC,KAAK;UAEZ;AACA,eAAK,WAAW,IAAI,KAAK;QAC3B;MACF;AACA,aAAO;IACT;AACF,WAAAA;EAAA,EA3DA;;;;ACnEA,SAAS,gCAAgC,GAAG,gBAAgB;AAAE,MAAI,KAAK,OAAO,WAAW,eAAe,EAAE,OAAO,QAAQ,KAAK,EAAE,YAAY;AAAG,MAAI,GAAI,SAAQ,KAAK,GAAG,KAAK,CAAC,GAAG,KAAK,KAAK,EAAE;AAAG,MAAI,MAAM,QAAQ,CAAC,MAAM,KAAK,4BAA4B,CAAC,MAAM,kBAAkB,KAAK,OAAO,EAAE,WAAW,UAAU;AAAE,QAAI,GAAI,KAAI;AAAI,QAAI,IAAI;AAAG,WAAO,WAAY;AAAE,UAAI,KAAK,EAAE,OAAQ,QAAO,EAAE,MAAM,KAAK;AAAG,aAAO,EAAE,MAAM,OAAO,OAAO,EAAE,GAAG,EAAE;AAAA,IAAG;AAAA,EAAG;AAAE,QAAM,IAAI,UAAU,uIAAuI;AAAG;AAE3lB,SAAS,4BAA4B,GAAG,QAAQ;AAAE,MAAI,CAAC,EAAG;AAAQ,MAAI,OAAO,MAAM,SAAU,QAAO,kBAAkB,GAAG,MAAM;AAAG,MAAI,IAAI,OAAO,UAAU,SAAS,KAAK,CAAC,EAAE,MAAM,GAAG,EAAE;AAAG,MAAI,MAAM,YAAY,EAAE,YAAa,KAAI,EAAE,YAAY;AAAM,MAAI,MAAM,SAAS,MAAM,MAAO,QAAO,MAAM,KAAK,CAAC;AAAG,MAAI,MAAM,eAAe,2CAA2C,KAAK,CAAC,EAAG,QAAO,kBAAkB,GAAG,MAAM;AAAG;AAE/Z,SAAS,kBAAkB,KAAK,KAAK;AAAE,MAAI,OAAO,QAAQ,MAAM,IAAI,OAAQ,OAAM,IAAI;AAAQ,WAAS,IAAI,GAAG,OAAO,IAAI,MAAM,GAAG,GAAG,IAAI,KAAK,KAAK;AAAE,SAAK,CAAC,IAAI,IAAI,CAAC;AAAA,EAAG;AAAE,SAAO;AAAM;AAEtL,SAAS,kBAAkB,QAAQ,OAAO;AAAE,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AAAE,QAAI,aAAa,MAAM,CAAC;AAAG,eAAW,aAAa,WAAW,cAAc;AAAO,eAAW,eAAe;AAAM,QAAI,WAAW,WAAY,YAAW,WAAW;AAAM,WAAO,eAAe,QAAQ,WAAW,KAAK,UAAU;AAAA,EAAG;AAAE;AAE5T,SAAS,aAAa,aAAa,YAAY,aAAa;AAAE,MAAI,WAAY,mBAAkB,YAAY,WAAW,UAAU;AAAG,MAAI,YAAa,mBAAkB,aAAa,WAAW;AAAG,SAAO,eAAe,aAAa,aAAa,EAAE,UAAU,MAAM,CAAC;AAAG,SAAO;AAAa;AAG5R,IAAI,aAAa,WAAY;AAC3B,SAAO,OAAO,WAAW;AAC3B;AAEA,IAAI,YAAY,SAAU,MAAM;AAC9B,SAAO,WAAW,KAAK,QAAQ,OAAO,IAAI,CAAC;AAC7C;AAEA,IAAI,YAAY,SAAU,MAAM;AAC9B,SAAO,UAAU,IAAI,IAAI,OAAO,IAAI,IAAI,OAAO;AACjD;AAEA,IAAI,WAAW,KAAK,CAAC,UAAU,YAAY,GAAG;AAC5C,SAAO,aAAa,OAAO,YAAY;AACzC;AAEA,IAAI,iBAAiB,UAAU,UAAU;AACzC,IAAI,mBAAmB,UAAU,YAAY;AAC7C,IAAI,gBAAgB,UAAU,SAAS;AAEvC,SAAS,UAAU,KAAK,KAAK;AAC3B,MAAI,QAAQ,IAAI,GAAG;AACnB,MAAI,SAAS,KAAM,QAAO;AAC1B,MAAI,OAAO,UAAU,WAAY,OAAM,IAAI,UAAU,QAAQ,oBAAoB;AACjF,SAAO;AACT;AAEA,SAAS,WAAW,KAAK;AACvB,MAAI,OAAO,IAAI;AAEf,MAAI,SAAS,QAAW;AACtB,WAAO,KAAK,aAAa;AAEzB,QAAI,SAAS,MAAM;AACjB,aAAO;AAAA,IACT;AAAA,EACF;AAEA,SAAO,SAAS,SAAY,OAAO;AACrC;AAEA,SAAS,aAAa,GAAG;AACvB,SAAO,aAAa;AACtB;AAEA,SAAS,gBAAgB,GAAG;AAC1B,MAAI,gBAAgB,KAAK;AACvB,oBAAgB,IAAI,CAAC;AAAA,EACvB,OAAO;AACL,eAAW,WAAY;AACrB,YAAM;AAAA,IACR,CAAC;AAAA,EACH;AACF;AAEA,SAAS,QAAQ,IAAI;AACnB,UAAQ,QAAQ,EAAE,KAAK,WAAY;AACjC,QAAI;AACF,SAAG;AAAA,IACL,SAAS,GAAG;AACV,sBAAgB,CAAC;AAAA,IACnB;AAAA,EACF,CAAC;AACH;AAEA,SAAS,oBAAoB,cAAc;AACzC,MAAI,UAAU,aAAa;AAC3B,MAAI,YAAY,OAAW;AAC3B,eAAa,WAAW;AAExB,MAAI,CAAC,SAAS;AACZ;AAAA,EACF;AAEA,MAAI;AACF,QAAI,OAAO,YAAY,YAAY;AACjC,cAAQ;AAAA,IACV,OAAO;AACL,UAAI,cAAc,UAAU,SAAS,aAAa;AAElD,UAAI,aAAa;AACf,oBAAY,KAAK,OAAO;AAAA,MAC1B;AAAA,IACF;AAAA,EACF,SAAS,GAAG;AACV,oBAAgB,CAAC;AAAA,EACnB;AACF;AAEA,SAAS,kBAAkB,cAAc;AACvC,eAAa,YAAY;AACzB,eAAa,SAAS;AACtB,eAAa,SAAS;AACxB;AAEA,SAAS,kBAAkB,cAAc;AACvC,MAAI,QAAQ,aAAa;AAEzB,MAAI,CAAC,OAAO;AACV;AAAA,EACF;AAEA,eAAa,SAAS;AACtB,eAAa,SAAS;AAEtB,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,EAAE,GAAG;AACrC,uBAAmB,cAAc,MAAM,CAAC,EAAE,MAAM,MAAM,CAAC,EAAE,KAAK;AAC9D,QAAI,aAAa,WAAW,SAAU;AAAA,EACxC;AACF;AAEA,SAAS,mBAAmB,cAAc,MAAM,OAAO;AACrD,eAAa,SAAS;AACtB,MAAI,WAAW,aAAa;AAE5B,MAAI;AACF,QAAI,IAAI,UAAU,UAAU,IAAI;AAEhC,YAAQ,MAAM;AAAA,MACZ,KAAK;AACH,YAAI,EAAG,GAAE,KAAK,UAAU,KAAK;AAC7B;AAAA,MAEF,KAAK;AACH,0BAAkB,YAAY;AAC9B,YAAI,EAAG,GAAE,KAAK,UAAU,KAAK;AAAA,YAAO,OAAM;AAC1C;AAAA,MAEF,KAAK;AACH,0BAAkB,YAAY;AAC9B,YAAI,EAAG,GAAE,KAAK,QAAQ;AACtB;AAAA,IACJ;AAAA,EACF,SAAS,GAAG;AACV,oBAAgB,CAAC;AAAA,EACnB;AAEA,MAAI,aAAa,WAAW,SAAU,qBAAoB,YAAY;AAAA,WAAW,aAAa,WAAW,UAAW,cAAa,SAAS;AAC5I;AAEA,SAAS,SAAS,cAAc,MAAM,OAAO;AAC3C,MAAI,aAAa,WAAW,SAAU;AAEtC,MAAI,aAAa,WAAW,aAAa;AACvC,iBAAa,OAAO,KAAK;AAAA,MACvB;AAAA,MACA;AAAA,IACF,CAAC;AAED;AAAA,EACF;AAEA,MAAI,aAAa,WAAW,SAAS;AACnC,iBAAa,SAAS;AACtB,iBAAa,SAAS,CAAC;AAAA,MACrB;AAAA,MACA;AAAA,IACF,CAAC;AACD,YAAQ,WAAY;AAClB,aAAO,kBAAkB,YAAY;AAAA,IACvC,CAAC;AACD;AAAA,EACF;AAEA,qBAAmB,cAAc,MAAM,KAAK;AAC9C;AAEA,IAAI,eAA4B,WAAY;AAC1C,WAASE,cAAa,UAAU,YAAY;AAG1C,SAAK,WAAW;AAChB,SAAK,YAAY;AACjB,SAAK,SAAS;AACd,SAAK,SAAS;AACd,QAAI,uBAAuB,IAAI,qBAAqB,IAAI;AAExD,QAAI;AACF,WAAK,WAAW,WAAW,KAAK,QAAW,oBAAoB;AAAA,IACjE,SAAS,GAAG;AACV,2BAAqB,MAAM,CAAC;AAAA,IAC9B;AAEA,QAAI,KAAK,WAAW,eAAgB,MAAK,SAAS;AAAA,EACpD;AAEA,MAAI,SAASA,cAAa;AAE1B,SAAO,cAAc,SAAS,cAAc;AAC1C,QAAI,KAAK,WAAW,UAAU;AAC5B,wBAAkB,IAAI;AACtB,0BAAoB,IAAI;AAAA,IAC1B;AAAA,EACF;AAEA,eAAaA,eAAc,CAAC;AAAA,IAC1B,KAAK;AAAA,IACL,KAAK,WAAY;AACf,aAAO,KAAK,WAAW;AAAA,IACzB;AAAA,EACF,CAAC,CAAC;AAEF,SAAOA;AACT,EAAE;AAEF,IAAI,uBAAoC,WAAY;AAClD,WAASC,sBAAqB,cAAc;AAC1C,SAAK,gBAAgB;AAAA,EACvB;AAEA,MAAI,UAAUA,sBAAqB;AAEnC,UAAQ,OAAO,SAAS,KAAK,OAAO;AAClC,aAAS,KAAK,eAAe,QAAQ,KAAK;AAAA,EAC5C;AAEA,UAAQ,QAAQ,SAAS,MAAM,OAAO;AACpC,aAAS,KAAK,eAAe,SAAS,KAAK;AAAA,EAC7C;AAEA,UAAQ,WAAW,SAAS,WAAW;AACrC,aAAS,KAAK,eAAe,UAAU;AAAA,EACzC;AAEA,eAAaA,uBAAsB,CAAC;AAAA,IAClC,KAAK;AAAA,IACL,KAAK,WAAY;AACf,aAAO,KAAK,cAAc,WAAW;AAAA,IACvC;AAAA,EACF,CAAC,CAAC;AAEF,SAAOA;AACT,EAAE;AAEF,IAAI,aAA0B,WAAY;AACxC,WAASC,YAAW,YAAY;AAC9B,QAAI,EAAE,gBAAgBA,aAAa,OAAM,IAAI,UAAU,2CAA2C;AAClG,QAAI,OAAO,eAAe,WAAY,OAAM,IAAI,UAAU,2CAA2C;AACrG,SAAK,cAAc;AAAA,EACrB;AAEA,MAAI,UAAUA,YAAW;AAEzB,UAAQ,YAAY,SAAS,UAAU,UAAU;AAC/C,QAAI,OAAO,aAAa,YAAY,aAAa,MAAM;AACrD,iBAAW;AAAA,QACT,MAAM;AAAA,QACN,OAAO,UAAU,CAAC;AAAA,QAClB,UAAU,UAAU,CAAC;AAAA,MACvB;AAAA,IACF;AAEA,WAAO,IAAI,aAAa,UAAU,KAAK,WAAW;AAAA,EACpD;AAEA,UAAQ,UAAU,SAASC,SAAQ,IAAI;AACrC,QAAI,QAAQ;AAEZ,WAAO,IAAI,QAAQ,SAAU,SAAS,QAAQ;AAC5C,UAAI,OAAO,OAAO,YAAY;AAC5B,eAAO,IAAI,UAAU,KAAK,oBAAoB,CAAC;AAC/C;AAAA,MACF;AAEA,eAAS,OAAO;AACd,qBAAa,YAAY;AACzB,gBAAQ;AAAA,MACV;AAEA,UAAI,eAAe,MAAM,UAAU;AAAA,QACjC,MAAM,SAAU,OAAO;AACrB,cAAI;AACF,eAAG,OAAO,IAAI;AAAA,UAChB,SAAS,GAAG;AACV,mBAAO,CAAC;AACR,yBAAa,YAAY;AAAA,UAC3B;AAAA,QACF;AAAA,QACA,OAAO;AAAA,QACP,UAAU;AAAA,MACZ,CAAC;AAAA,IACH,CAAC;AAAA,EACH;AAEA,UAAQ,MAAM,SAAS,IAAI,IAAI;AAC7B,QAAI,SAAS;AAEb,QAAI,OAAO,OAAO,WAAY,OAAM,IAAI,UAAU,KAAK,oBAAoB;AAC3E,QAAI,IAAI,WAAW,IAAI;AACvB,WAAO,IAAI,EAAE,SAAU,UAAU;AAC/B,aAAO,OAAO,UAAU;AAAA,QACtB,MAAM,SAAU,OAAO;AACrB,cAAI;AACF,oBAAQ,GAAG,KAAK;AAAA,UAClB,SAAS,GAAG;AACV,mBAAO,SAAS,MAAM,CAAC;AAAA,UACzB;AAEA,mBAAS,KAAK,KAAK;AAAA,QACrB;AAAA,QACA,OAAO,SAAU,GAAG;AAClB,mBAAS,MAAM,CAAC;AAAA,QAClB;AAAA,QACA,UAAU,WAAY;AACpB,mBAAS,SAAS;AAAA,QACpB;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AAAA,EACH;AAEA,UAAQ,SAAS,SAAS,OAAO,IAAI;AACnC,QAAI,SAAS;AAEb,QAAI,OAAO,OAAO,WAAY,OAAM,IAAI,UAAU,KAAK,oBAAoB;AAC3E,QAAI,IAAI,WAAW,IAAI;AACvB,WAAO,IAAI,EAAE,SAAU,UAAU;AAC/B,aAAO,OAAO,UAAU;AAAA,QACtB,MAAM,SAAU,OAAO;AACrB,cAAI;AACF,gBAAI,CAAC,GAAG,KAAK,EAAG;AAAA,UAClB,SAAS,GAAG;AACV,mBAAO,SAAS,MAAM,CAAC;AAAA,UACzB;AAEA,mBAAS,KAAK,KAAK;AAAA,QACrB;AAAA,QACA,OAAO,SAAU,GAAG;AAClB,mBAAS,MAAM,CAAC;AAAA,QAClB;AAAA,QACA,UAAU,WAAY;AACpB,mBAAS,SAAS;AAAA,QACpB;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AAAA,EACH;AAEA,UAAQ,SAAS,SAAS,OAAO,IAAI;AACnC,QAAI,SAAS;AAEb,QAAI,OAAO,OAAO,WAAY,OAAM,IAAI,UAAU,KAAK,oBAAoB;AAC3E,QAAI,IAAI,WAAW,IAAI;AACvB,QAAI,UAAU,UAAU,SAAS;AACjC,QAAI,WAAW;AACf,QAAI,OAAO,UAAU,CAAC;AACtB,QAAI,MAAM;AACV,WAAO,IAAI,EAAE,SAAU,UAAU;AAC/B,aAAO,OAAO,UAAU;AAAA,QACtB,MAAM,SAAU,OAAO;AACrB,cAAI,QAAQ,CAAC;AACb,qBAAW;AAEX,cAAI,CAAC,SAAS,SAAS;AACrB,gBAAI;AACF,oBAAM,GAAG,KAAK,KAAK;AAAA,YACrB,SAAS,GAAG;AACV,qBAAO,SAAS,MAAM,CAAC;AAAA,YACzB;AAAA,UACF,OAAO;AACL,kBAAM;AAAA,UACR;AAAA,QACF;AAAA,QACA,OAAO,SAAU,GAAG;AAClB,mBAAS,MAAM,CAAC;AAAA,QAClB;AAAA,QACA,UAAU,WAAY;AACpB,cAAI,CAAC,YAAY,CAAC,QAAS,QAAO,SAAS,MAAM,IAAI,UAAU,iCAAiC,CAAC;AACjG,mBAAS,KAAK,GAAG;AACjB,mBAAS,SAAS;AAAA,QACpB;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AAAA,EACH;AAEA,UAAQ,SAAS,SAAS,SAAS;AACjC,QAAI,SAAS;AAEb,aAAS,OAAO,UAAU,QAAQ,UAAU,IAAI,MAAM,IAAI,GAAG,OAAO,GAAG,OAAO,MAAM,QAAQ;AAC1F,cAAQ,IAAI,IAAI,UAAU,IAAI;AAAA,IAChC;AAEA,QAAI,IAAI,WAAW,IAAI;AACvB,WAAO,IAAI,EAAE,SAAU,UAAU;AAC/B,UAAI;AACJ,UAAI,QAAQ;AAEZ,eAAS,UAAU,MAAM;AACvB,uBAAe,KAAK,UAAU;AAAA,UAC5B,MAAM,SAAU,GAAG;AACjB,qBAAS,KAAK,CAAC;AAAA,UACjB;AAAA,UACA,OAAO,SAAU,GAAG;AAClB,qBAAS,MAAM,CAAC;AAAA,UAClB;AAAA,UACA,UAAU,WAAY;AACpB,gBAAI,UAAU,QAAQ,QAAQ;AAC5B,6BAAe;AACf,uBAAS,SAAS;AAAA,YACpB,OAAO;AACL,wBAAU,EAAE,KAAK,QAAQ,OAAO,CAAC,CAAC;AAAA,YACpC;AAAA,UACF;AAAA,QACF,CAAC;AAAA,MACH;AAEA,gBAAU,MAAM;AAChB,aAAO,WAAY;AACjB,YAAI,cAAc;AAChB,uBAAa,YAAY;AACzB,yBAAe;AAAA,QACjB;AAAA,MACF;AAAA,IACF,CAAC;AAAA,EACH;AAEA,UAAQ,UAAU,SAAS,QAAQ,IAAI;AACrC,QAAI,SAAS;AAEb,QAAI,OAAO,OAAO,WAAY,OAAM,IAAI,UAAU,KAAK,oBAAoB;AAC3E,QAAI,IAAI,WAAW,IAAI;AACvB,WAAO,IAAI,EAAE,SAAU,UAAU;AAC/B,UAAI,gBAAgB,CAAC;AAErB,UAAI,QAAQ,OAAO,UAAU;AAAA,QAC3B,MAAM,SAAU,OAAO;AACrB,cAAI,IAAI;AACN,gBAAI;AACF,sBAAQ,GAAG,KAAK;AAAA,YAClB,SAAS,GAAG;AACV,qBAAO,SAAS,MAAM,CAAC;AAAA,YACzB;AAAA,UACF;AAEA,cAAI,QAAQ,EAAE,KAAK,KAAK,EAAE,UAAU;AAAA,YAClC,MAAM,SAAUC,QAAO;AACrB,uBAAS,KAAKA,MAAK;AAAA,YACrB;AAAA,YACA,OAAO,SAAU,GAAG;AAClB,uBAAS,MAAM,CAAC;AAAA,YAClB;AAAA,YACA,UAAU,WAAY;AACpB,kBAAI,IAAI,cAAc,QAAQ,KAAK;AACnC,kBAAI,KAAK,EAAG,eAAc,OAAO,GAAG,CAAC;AACrC,6BAAe;AAAA,YACjB;AAAA,UACF,CAAC;AACD,wBAAc,KAAK,KAAK;AAAA,QAC1B;AAAA,QACA,OAAO,SAAU,GAAG;AAClB,mBAAS,MAAM,CAAC;AAAA,QAClB;AAAA,QACA,UAAU,WAAY;AACpB,yBAAe;AAAA,QACjB;AAAA,MACF,CAAC;AAED,eAAS,iBAAiB;AACxB,YAAI,MAAM,UAAU,cAAc,WAAW,EAAG,UAAS,SAAS;AAAA,MACpE;AAEA,aAAO,WAAY;AACjB,sBAAc,QAAQ,SAAU,GAAG;AACjC,iBAAO,EAAE,YAAY;AAAA,QACvB,CAAC;AACD,cAAM,YAAY;AAAA,MACpB;AAAA,IACF,CAAC;AAAA,EACH;AAEA,UAAQ,gBAAgB,IAAI,WAAY;AACtC,WAAO;AAAA,EACT;AAEA,EAAAF,YAAW,OAAO,SAAS,KAAK,GAAG;AACjC,QAAI,IAAI,OAAO,SAAS,aAAa,OAAOA;AAC5C,QAAI,KAAK,KAAM,OAAM,IAAI,UAAU,IAAI,mBAAmB;AAC1D,QAAI,SAAS,UAAU,GAAG,gBAAgB;AAE1C,QAAI,QAAQ;AACV,UAAI,aAAa,OAAO,KAAK,CAAC;AAC9B,UAAI,OAAO,UAAU,MAAM,WAAY,OAAM,IAAI,UAAU,aAAa,mBAAmB;AAC3F,UAAI,aAAa,UAAU,KAAK,WAAW,gBAAgB,EAAG,QAAO;AACrE,aAAO,IAAI,EAAE,SAAU,UAAU;AAC/B,eAAO,WAAW,UAAU,QAAQ;AAAA,MACtC,CAAC;AAAA,IACH;AAEA,QAAI,UAAU,UAAU,GAAG;AACzB,eAAS,UAAU,GAAG,cAAc;AAEpC,UAAI,QAAQ;AACV,eAAO,IAAI,EAAE,SAAU,UAAU;AAC/B,kBAAQ,WAAY;AAClB,gBAAI,SAAS,OAAQ;AAErB,qBAAS,YAAY,gCAAgC,OAAO,KAAK,CAAC,CAAC,GAAG,OAAO,EAAE,QAAQ,UAAU,GAAG,QAAO;AACzG,kBAAI,OAAO,MAAM;AACjB,uBAAS,KAAK,IAAI;AAClB,kBAAI,SAAS,OAAQ;AAAA,YACvB;AAEA,qBAAS,SAAS;AAAA,UACpB,CAAC;AAAA,QACH,CAAC;AAAA,MACH;AAAA,IACF;AAEA,QAAI,MAAM,QAAQ,CAAC,GAAG;AACpB,aAAO,IAAI,EAAE,SAAU,UAAU;AAC/B,gBAAQ,WAAY;AAClB,cAAI,SAAS,OAAQ;AAErB,mBAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,EAAE,GAAG;AACjC,qBAAS,KAAK,EAAE,CAAC,CAAC;AAClB,gBAAI,SAAS,OAAQ;AAAA,UACvB;AAEA,mBAAS,SAAS;AAAA,QACpB,CAAC;AAAA,MACH,CAAC;AAAA,IACH;AAEA,UAAM,IAAI,UAAU,IAAI,oBAAoB;AAAA,EAC9C;AAEA,EAAAA,YAAW,KAAK,SAAS,KAAK;AAC5B,aAAS,QAAQ,UAAU,QAAQ,QAAQ,IAAI,MAAM,KAAK,GAAG,QAAQ,GAAG,QAAQ,OAAO,SAAS;AAC9F,YAAM,KAAK,IAAI,UAAU,KAAK;AAAA,IAChC;AAEA,QAAI,IAAI,OAAO,SAAS,aAAa,OAAOA;AAC5C,WAAO,IAAI,EAAE,SAAU,UAAU;AAC/B,cAAQ,WAAY;AAClB,YAAI,SAAS,OAAQ;AAErB,iBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,EAAE,GAAG;AACrC,mBAAS,KAAK,MAAM,CAAC,CAAC;AACtB,cAAI,SAAS,OAAQ;AAAA,QACvB;AAEA,iBAAS,SAAS;AAAA,MACpB,CAAC;AAAA,IACH,CAAC;AAAA,EACH;AAEA,eAAaA,aAAY,MAAM,CAAC;AAAA,IAC9B,KAAK;AAAA,IACL,KAAK,WAAY;AACf,aAAO;AAAA,IACT;AAAA,EACF,CAAC,CAAC;AAEF,SAAOA;AACT,EAAE;AAEF,IAAI,WAAW,GAAG;AAChB,SAAO,eAAe,YAAY,OAAO,YAAY,GAAG;AAAA,IACtD,OAAO;AAAA,MACL,QAAQ;AAAA,MACR;AAAA,IACF;AAAA,IACA,cAAc;AAAA,EAChB,CAAC;AACH;;;AC7jBe,SAAR,yBAA0CG,OAAM;AACtD,MAAIC;AACJ,MAAIC,UAASF,MAAK;AAElB,MAAI,OAAOE,YAAW,YAAY;AACjC,QAAIA,QAAO,YAAY;AACtB,MAAAD,UAASC,QAAO;AAAA,IACjB,OAAO;AAEN,UAAI,OAAOA,QAAO,QAAQ,YAAY;AAIrC,QAAAD,UAASC,QAAO,IAAI,8CAA8C;AAAA,MACnE,OAAO;AAIN,QAAAD,UAASC,QAAO,8CAA8C;AAAA,MAC/D;AACA,UAAI;AACH,QAAAA,QAAO,aAAaD;AAAA,MACrB,SAAS,KAAK;AAAA,MAId;AAAA,IACD;AAAA,EACD,OAAO;AACN,IAAAA,UAAS;AAAA,EACV;AAEA,SAAOA;AACR;;;AC9BA,IAAI;AAEJ,IAAI,OAAO,SAAS,aAAa;AAC/B,SAAO;AACT,WAAW,OAAO,WAAW,aAAa;AACxC,SAAO;AACT,WAAW,OAAO,WAAW,aAAa;AACxC,SAAO;AACT,WAAW,OAAO,WAAW,aAAa;AACxC,SAAO;AACT,OAAO;AACL,SAAO,SAAS,aAAa,EAAE;AACjC;AAEA,IAAI,SAAS,yBAAS,IAAI;;;ACDlB,IAAA,YAAc,WAAU;AAChC,IAAM,gBAAgB;AACtB,IAAI,CAAC,UAAU,aAAa,GAAG;AAE7B,YAAU,aAAa,IAAI,WAAA;AACzB,WAAO;EACT;AACF;;;ACvBQ,IAAA,WAAa,OAAO,UAAS;AAK/B,SAAU,UAAa,OAAQ;AACnC,SAAO,gBAAgB,KAAK;AAC9B;AAEA,SAAS,gBAAmB,KAAQ,MAAoB;AACtD,UAAQ,SAAS,KAAK,GAAG,GAAG;IAC1B,KAAK,kBAAkB;AACrB,aAAO,QAAQ,oBAAI,IAAG;AACtB,UAAI,KAAK,IAAI,GAAG;AAAG,eAAO,KAAK,IAAI,GAAG;AACtC,UAAM,SAAmB,IAAY,MAAM,CAAC;AAC5C,WAAK,IAAI,KAAK,MAAI;AAClB,aAAK,QAAQ,SAAU,OAAO,GAAC;AAC7B,eAAK,CAAC,IAAI,gBAAgB,OAAO,IAAI;MACvC,CAAC;AACD,aAAO;IACT;IAEA,KAAK,mBAAmB;AACtB,aAAO,QAAQ,oBAAI,IAAG;AACtB,UAAI,KAAK,IAAI,GAAG;AAAG,eAAO,KAAK,IAAI,GAAG;AAGtC,UAAM,SAAO,OAAO,OAAO,OAAO,eAAe,GAAG,CAAC;AACrD,WAAK,IAAI,KAAK,MAAI;AAClB,aAAO,KAAK,GAA8B,EAAE,QAAQ,SAAC,KAAG;AACtD,eAAK,GAAG,IAAI,gBAAiB,IAAY,GAAG,GAAG,IAAI;MACrD,CAAC;AACD,aAAO;IACT;IAEA;AACE,aAAO;EACX;AACF;;;ACpCA,SAAS,WAAW,OAAU;AAC5B,MAAM,UAAU,oBAAI,IAAI,CAAC,KAAK,CAAC;AAC/B,UAAQ,QAAQ,SAAC,KAAG;AAClB,QAAI,gBAAgB,GAAG,KAAK,cAAc,GAAG,MAAM,KAAK;AACtD,aAAO,oBAAoB,GAAG,EAAE,QAAQ,SAAC,MAAI;AAC3C,YAAI,gBAAgB,IAAI,IAAI,CAAC;AAAG,kBAAQ,IAAI,IAAI,IAAI,CAAC;MACvD,CAAC;IACH;EACF,CAAC;AACD,SAAO;AACT;AAEA,SAAS,cAAgC,KAAM;AAC7C,MAAI,WAAW,YAAQ,SAAa,CAAA,OAAG,SAAA,GAAA,GAAA;AACrC,QAAI;AACF,aAAO,OAAO,GAAG;IACnB,SAAS,GAAG;AAIV,UAAI,aAAa;AAAW,eAAO;AACnC,YAAM;IACR;EACF;AACA,SAAO;AACT;AAEM,SAAU,gBAAmB,KAAM;AACvC,MAAI,WAAU,YAAA,OAAA;AACZ,eAAW,GAAG;EAChB;AACA,SAAO;AACT;;;AChCM,SAAU,uBACd,WACA,QACA,UAAY;AAKZ,MAAM,sBAAqC,CAAA;AAC3C,YAAU,QAAQ,SAAC,KAAG;AAAK,WAAA,IAAI,MAAM,KAAK,oBAAoB,KAAK,GAAG;EAA3C,CAA4C;AACvE,sBAAoB,QAAQ,SAAC,KAAG;AAAK,WAAC,IAAY,MAAM,EAAE,QAAQ;EAA7B,CAA8B;AACrE;;;ACRM,SAAU,SACd,YACA,OACA,SAA4C;AAE5C,SAAO,IAAI,WAAc,SAAC,UAAQ;AAChC,QAAI,eAAe;;;;MAIjB,MAAI,SAAC,UAAmB;AACtB,eAAO,IAAI,QAAQ,SAAC,SAAO;AAAK,iBAAA,QAAQ,SAAQ,CAAE;QAAlB,CAAmB;MACrD;;AAGF,aAAS,aACP,UACA,KAAqB;AAErB,aAAO,SAAC,KAAG;AACT,YAAI,UAAU;AACZ,cAAM,OAAO,WAAA;AAGX,mBAAA,SAAS;;cACkB;gBACzB,SAAS,GAAG;UAFd;AAIF,yBAAe,aAAa,KAAK,MAAM,IAAI,EAAE,KAC3C,SAACE,SAAM;AAAK,mBAAA,SAAS,KAAKA,OAAM;UAApB,GACZ,SAAC,OAAK;AAAK,mBAAA,SAAS,MAAM,KAAK;UAApB,CAAqB;QAEpC,OAAO;AACL,mBAAS,GAAG,EAAE,GAAG;QACnB;MACF;IACF;AAEA,QAAM,UAAuB;MAC3B,MAAM,aAAa,OAAO,MAAM;MAChC,OAAO,aAAa,SAAS,OAAO;MACpC,UAAQ,WAAA;AAGc,qBAAa,KAAK,WAAA;AAAM,iBAAA,SAAS,SAAQ;QAAjB,CAAmB;MACjE;;AAGF,QAAM,MAAM,WAAW,UAAU,OAAO;AACxC,WAAO,WAAA;AAAM,aAAA,IAAI,YAAW;IAAf;EACf,CAAC;AACH;;;;;;AC7CM,SAAU,sBAEd,UAAW;AACX,WAAS,IAAI,KAAoB;AAI/B,WAAO,eAAe,UAAU,KAAK,EAAE,OAAO,WAAU,CAAE;EAC5D;AACA,MAAI,gBAAgB,OAAO,SAAS;AAClC,QAAI,OAAO,OAAO;EACpB;AAIA,MAAI,WAAW;AACf,SAAO;AACT;;;ACjBA,SAAS,cAAiB,OAAoB;AAC5C,SAAO,SAAS,OAAQ,MAAc,SAAS;AACjD;AAqCA,IAAA;;EAAA,SAAA,QAAA;AAAgC,cAAAC,UAAA,MAAA;AAc9B,aAAAA,SAAY,SAA8D;AACxE,UAAA,QAAA,OAAK,KAAA,MAAC,SAAC,UAAQ;AACb,cAAK,YAAY,QAAQ;AACzB,eAAO,WAAA;AAAM,iBAAA,MAAK,eAAe,QAAQ;QAA5B;MACf,CAAC,KAAC;AAdI,YAAA,YAAY,oBAAI,IAAG;AAiGX,YAAA,UAAU,IAAI,QAAuB,SAAC,SAAS,QAAM;AACnE,cAAK,UAAU;AACf,cAAK,SAAS;MAChB,CAAC;AAQO,YAAA,WAAW;QACjB,MAAM,SAACC,SAAS;AACd,cAAI,MAAK,QAAQ,MAAM;AACrB,kBAAK,SAAS,CAAC,QAAQA,OAAM;AAC7B,kBAAK,OAAO,QAAQA,OAAM;AAC1B,mCAAuB,MAAK,WAAW,QAAQA,OAAM;UACvD;QACF;QAEA,OAAO,SAAC,OAAU;AACR,cAAA,MAAQ,MAAI;AACpB,cAAI,QAAQ,MAAM;AAIhB,gBAAI;AAAK,yBAAW,WAAA;AAAM,uBAAA,IAAI,YAAW;cAAf,CAAiB;AAC3C,kBAAK,MAAM;AACX,kBAAK,SAAS,CAAC,SAAS,KAAK;AAC7B,kBAAK,OAAO,KAAK;AACjB,kBAAK,OAAO,SAAS,KAAK;AAC1B,mCAAuB,MAAK,WAAW,SAAS,KAAK;UACvD;QACF;QAEA,UAAU,WAAA;AACF,cAAAC,MAAwB,OAAtB,MAAGA,IAAA,KAAE,KAAAA,IAAA,SAAAC,WAAO,OAAA,SAAG,CAAA,IAAE;AACzB,cAAI,QAAQ,MAAM;AAMhB,gBAAM,QAAQA,SAAQ,MAAK;AAC3B,gBAAI,CAAC,OAAO;AACV,kBAAI;AAAK,2BAAW,WAAA;AAAM,yBAAA,IAAI,YAAW;gBAAf,CAAiB;AAC3C,oBAAK,MAAM;AACX,kBAAI,MAAK,UAAU,MAAK,OAAO,CAAC,MAAM,QAAQ;AAC5C,sBAAK,QAAQ,MAAK,OAAO,CAAC,CAAC;cAC7B,OAAO;AACL,sBAAK,QAAO;cACd;AACA,oBAAK,OAAO,UAAU;AAOtB,qCAAuB,MAAK,WAAW,UAAU;YACnD,WAAW,cAAc,KAAK,GAAG;AAC/B,oBAAM,KACJ,SAAC,KAAG;AAAK,uBAAC,MAAK,MAAM,IAAI,UAAU,MAAK,QAAQ;cAAvC,GACT,MAAK,SAAS,KAAK;YAEvB,OAAO;AACL,oBAAK,MAAM,MAAM,UAAU,MAAK,QAAQ;YAC1C;UACF;QACF;;AAGM,YAAA,sBAAsB,oBAAI,IAAG;AAgC9B,YAAA,SAAS,SAAC,QAAW;AAC1B,cAAK,OAAO,MAAM;AAClB,cAAK,UAAU,CAAA;AACf,cAAK,SAAS,SAAQ;MACxB;AA1LE,YAAK,QAAQ,MAAM,SAAC,GAAC;MAAM,CAAC;AAK5B,UAAI,OAAO,YAAY,YAAY;AACjC,kBAAU,CAAC,IAAI,WAAW,OAAO,CAAC;MACpC;AAEA,UAAI,cAAc,OAAO,GAAG;AAC1B,gBAAQ,KAAK,SAAC,UAAQ;AAAK,iBAAA,MAAK,MAAM,QAAQ;QAAnB,GAAsB,MAAK,SAAS,KAAK;MACtE,OAAO;AACL,cAAK,MAAM,OAAO;MACpB;;IACF;AASQ,IAAAH,SAAA,UAAA,QAAR,SAAc,SAAkC;AAC9C,UAAI,KAAK,QAAQ;AAAQ;AAKzB,WAAK,UAAU,MAAM,KAAK,OAAO;AAMjC,WAAK,SAAS,SAAQ;IACxB;AAEQ,IAAAA,SAAA,UAAA,qBAAR,SAA2B,UAAqB;AAC9C,UAAI,KAAK,QAAQ;AACf,YAAM,cAAc,KAAK,OAAO,CAAC;AACjC,YAAM,SAAS,SAAS,WAAW;AACnC,YAAI,QAAQ;AACV,iBAAO,KAAK,UAAU,KAAK,OAAO,CAAC,CAAC;QACtC;AAIA,YAAI,KAAK,QAAQ,QAAQ,gBAAgB,UAAU,SAAS,UAAU;AACpE,mBAAS,SAAQ;QACnB;MACF;IACF;AAEO,IAAAA,SAAA,UAAA,cAAP,SAAmB,UAAqB;AACtC,UAAI,CAAC,KAAK,UAAU,IAAI,QAAQ,GAAG;AAGjC,aAAK,mBAAmB,QAAQ;AAChC,aAAK,UAAU,IAAI,QAAQ;MAC7B;IACF;AAEO,IAAAA,SAAA,UAAA,iBAAP,SAAsB,UAAqB;AACzC,UAAI,KAAK,UAAU,OAAO,QAAQ,KAAK,KAAK,UAAU,OAAO,GAAG;AAK9D,aAAK,SAAS,SAAQ;MACxB;IACF;AAiFQ,IAAAA,SAAA,UAAA,SAAR,SACE,QACA,KAAuC;AAE/B,UAAA,sBAAwB,KAAI;AACpC,UAAI,oBAAoB,MAAM;AAG5B,aAAK,sBAAsB,oBAAI,IAAG;AAClC,4BAAoB,QAAQ,SAAC,UAAQ;AAAK,iBAAA,SAAS,QAAQ,GAAG;QAApB,CAAqB;MACjE;IACF;AAQA,IAAAA,SAAA,UAAA,aAAA,SAAW,UAA4B;AACrC,UAAI,SAAS;AACb,WAAK,oBAAoB,IAAI,SAAC,QAAQ,KAAG;AACvC,YAAI,CAAC,QAAQ;AACX,mBAAS;AACT,mBAAS,QAAQ,GAAG;QACtB;MACF,CAAC;IACH;AAQF,WAAAA;EAAA,EAlNgC,UAAU;;AA2N1C,sBAAsB,OAAO;;;AClQvB,SAAU,kCACd,OAAqB;AAErB,SAAO,iBAAiB;AAC1B;AAEM,SAAU,8BACd,OAAqB;AAErB,SAAO,aAAa,SAAS,UAAU;AACzC;AAEM,SAAU,uBACd,OAAqB;AAErB,SACE,kCAAkC,KAAK,KACvC,8BAA8B,KAAK;AAEvC;AAKM,SAAU,sBACd,OAAc;AAEd,SAAO,gBAAgB,KAAK,KAAK,aAAa;AAChD;AAEM,SAAU,qBACd,YACAI,SAAmC;AAEnC,MAAI,aAAa;AACjB,MAAM,SAAS,IAAI,WAAU;AAC7B,MACE,kCAAkCA,OAAM,KACxC,gBAAgBA,QAAO,WAAW,GAClC;AACA,IAAAA,QAAO,YAAY,QAAQ,SAACC,KAAc;UAAZ,OAAIA,IAAA,MAAE,OAAIA,IAAA;AACtC,eAAS,IAAI,KAAK,SAAS,GAAG,KAAK,GAAG,EAAE,GAAG;AACzC,YAAM,MAAM,KAAK,CAAC;AAClB,YAAM,eAAe,CAAC,MAAM,CAAC,GAAG;AAChC,YAAM,WAAuC,eAAe,CAAA,IAAK,CAAA;AACjE,iBAAO,GAAG,IAAI;AACd,eAAO;MACT;AACA,mBAAa,OAAO,MAAM,YAAY,IAAI;IAC5C,CAAC;EACH;AACA,SAAO;AACT;;;AC3DM,SAAU,sBAAyBC,SAAsB;AAC7D,MAAM,SAAS,2BAA2BA,OAAM;AAChD,SAAO,gBAAgB,MAAM;AAC/B;AAEM,SAAU,2BAA8BA,SAAsB;AAClE,MAAM,gBACJ,gBAAgBA,QAAO,MAAM,IAAIA,QAAO,OAAO,MAAM,CAAC,IAAI,CAAA;AAE5D,MACE,kCAAkCA,OAAM,KACxC,gBAAgBA,QAAO,WAAW,GAClC;AACA,IAAAA,QAAO,YAAY,QAAQ,SAAC,mBAAiB;AAC3C,UAAI,kBAAkB,QAAQ;AAC5B,sBAAc,KAAI,MAAlB,eAAsB,kBAAkB,MAAM;MAChD;IACF,CAAC;EACH;AACA,SAAO;AACT;;;AClBM,SAAU,UAAO;AACrB,MAAA,UAAA,CAAA;WAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAAiB;AAAjB,YAAA,EAAA,IAAA,UAAA,EAAA;;AAEA,MAAMC,UAAS,uBAAO,OAAO,IAAI;AAEjC,UAAQ,QAAQ,SAAC,KAAG;AAClB,QAAI,CAAC;AAAK;AACV,WAAO,KAAK,GAAG,EAAE,QAAQ,SAAC,KAAG;AAC3B,UAAM,QAAS,IAAY,GAAG;AAC9B,UAAI,UAAU,QAAQ;AACpB,QAAAA,QAAO,GAAG,IAAI;MAChB;IACF,CAAC;EACH,CAAC;AAED,SAAOA;AACT;;;;ACRM,SAAU,aAId,UACA,SAAqC;AAErC,SAAO,QACL,UACA,SACA,QAAQ,aAAa;IACnB,WAAW,QAAO,SAAA,SAAA,CAAA,GACZ,YAAY,SAAS,SAAU,GAChC,QAAQ,SAAS,CAAA;GAEvB;AAEL;;;;;;AC/BA,IAAM,EAAE,UAAAC,WAAU,gBAAAC,gBAAc,IAAK,OAAO;AAC5C,IAAM,UAAU,SAAS,UAAU;AACnC,IAAM,sBAAsB,oBAAI,IAAG;AAK7B,SAAU,MAAM,GAAQ,GAAM;AAClC,MAAI;AACF,WAAO,MAAM,GAAG,CAAC;;AAEjB,wBAAoB,MAAK;;AAE7B;AAGA,IAAA,cAAe;AAEf,SAAS,MAAM,GAAQ,GAAM;AAE3B,MAAI,MAAM,GAAG;AACX,WAAO;;AAKT,QAAM,OAAOD,UAAS,KAAK,CAAC;AAC5B,QAAM,OAAOA,UAAS,KAAK,CAAC;AAK5B,MAAI,SAAS,MAAM;AACjB,WAAO;;AAGT,UAAQ,MAAM;IACZ,KAAK;AAGH,UAAI,EAAE,WAAW,EAAE;AAAQ,eAAO;IAEpC,KAAK,mBAAmB;AACtB,UAAI,mBAAmB,GAAG,CAAC;AAAG,eAAO;AAErC,YAAM,QAAQ,YAAY,CAAC;AAC3B,YAAM,QAAQ,YAAY,CAAC;AAI3B,YAAM,WAAW,MAAM;AACvB,UAAI,aAAa,MAAM;AAAQ,eAAO;AAGtC,eAAS,IAAI,GAAG,IAAI,UAAU,EAAE,GAAG;AACjC,YAAI,CAACC,gBAAe,KAAK,GAAG,MAAM,CAAC,CAAC,GAAG;AACrC,iBAAO;;;AAKX,eAAS,IAAI,GAAG,IAAI,UAAU,EAAE,GAAG;AACjC,cAAM,MAAM,MAAM,CAAC;AACnB,YAAI,CAAC,MAAM,EAAE,GAAG,GAAG,EAAE,GAAG,CAAC,GAAG;AAC1B,iBAAO;;;AAIX,aAAO;;IAGT,KAAK;AACH,aAAO,EAAE,SAAS,EAAE,QAAQ,EAAE,YAAY,EAAE;IAE9C,KAAK;AAEH,UAAI,MAAM;AAAG,eAAO,MAAM;IAE5B,KAAK;IACL,KAAK;AACH,aAAO,CAAC,MAAM,CAAC;IAEjB,KAAK;IACL,KAAK;AACH,aAAO,KAAK,GAAG,CAAC;IAElB,KAAK;IACL,KAAK,gBAAgB;AACnB,UAAI,EAAE,SAAS,EAAE;AAAM,eAAO;AAC9B,UAAI,mBAAmB,GAAG,CAAC;AAAG,eAAO;AAErC,YAAM,YAAY,EAAE,QAAO;AAC3B,YAAM,QAAQ,SAAS;AAEvB,aAAO,MAAM;AACX,cAAM,OAAO,UAAU,KAAI;AAC3B,YAAI,KAAK;AAAM;AAGf,cAAM,CAAC,MAAM,MAAM,IAAI,KAAK;AAG5B,YAAI,CAAC,EAAE,IAAI,IAAI,GAAG;AAChB,iBAAO;;AAKT,YAAI,SAAS,CAAC,MAAM,QAAQ,EAAE,IAAI,IAAI,CAAC,GAAG;AACxC,iBAAO;;;AAIX,aAAO;;IAGT,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AAGH,UAAI,IAAI,WAAW,CAAC;AACpB,UAAI,IAAI,WAAW,CAAC;IAEtB,KAAK,qBAAqB;AACxB,UAAI,MAAM,EAAE;AACZ,UAAI,QAAQ,EAAE,YAAY;AACxB,eAAO,SAAS,EAAE,GAAG,MAAM,EAAE,GAAG,GAAG;;;AAIrC,aAAO,QAAQ;;IAGjB,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK,qBAAqB;AACxB,YAAM,QAAQ,QAAQ,KAAK,CAAC;AAC5B,UAAI,UAAU,QAAQ,KAAK,CAAC,GAAG;AAC7B,eAAO;;AA0BT,aAAO,CAAC,SAAS,OAAO,gBAAgB;;;AAK5C,SAAO;AACT;AAEA,SAAS,YAAoC,KAAY;AAGvD,SAAO,OAAO,KAAK,GAAG,EAAE,OAAO,cAAc,GAAG;AAClD;AACA,SAAS,aAEP,KAAkB;AAElB,SAAO,KAAK,GAAG,MAAM;AACvB;AAEA,IAAM,mBAAmB;AAEzB,SAAS,SAAS,MAAc,QAAc;AAC5C,QAAM,YAAY,KAAK,SAAS,OAAO;AACvC,SAAO,aAAa,KAClB,KAAK,QAAQ,QAAQ,SAAS,MAAM;AACxC;AAEA,SAAS,mBAAmB,GAAW,GAAS;AAS9C,MAAI,OAAO,oBAAoB,IAAI,CAAC;AACpC,MAAI,MAAM;AAGR,QAAI,KAAK,IAAI,CAAC;AAAG,aAAO;SACnB;AACL,wBAAoB,IAAI,GAAG,OAAO,oBAAI,KAAG;;AAE3C,OAAK,IAAI,CAAC;AACV,SAAO;AACT;;;AC7LM,SAAU,aACd,OACAC,KACA,IACA,WAA8B;AAF5B,MAAM,QAAKA,IAAA,MAAK,QAAK,OAAAA,KAAvB,CAAA,MAAA,CAAyB;MACjB,QAAK,GAAA,MAAK,QAAK,OAAA,IAAvB,CAAA,MAAA,CAAyB;AAGzB,SACE,YAAM,OAAO,KAAK,KAClB,oBAAoB,kBAAkB,KAAK,EAAE,cAAc,OAAO,OAAO;IACvE,aAAa,kBAAkB,uBAAuB,KAAK,CAAC;IAC5D;GACD;AAEL;AASA,SAAS,oBACP,cACA,SACA,SACA,SAA2C;AAE3C,MAAI,YAAY,SAAS;AACvB,WAAO;EACT;AAEA,MAAM,iBAAiB,oBAAI,IAAG;AAK9B,SAAO,aAAa,WAAW,MAAM,SAAC,WAAS;AAG7C,QAAI,eAAe,IAAI,SAAS;AAAG,aAAO;AAC1C,mBAAe,IAAI,SAAS;AAG5B,QAAI,CAAC,cAAc,WAAW,QAAQ,SAAS;AAAG,aAAO;AAIzD,QAAI,iCAAiC,SAAS;AAAG,aAAO;AAExD,QAAI,QAAQ,SAAS,GAAG;AACtB,UAAM,YAAY,uBAAuB,SAAS;AAClD,UAAM,eAAe,WAAW,QAAQ,SAAS;AACjD,UAAM,eAAe,WAAW,QAAQ,SAAS;AACjD,UAAM,oBAAoB,UAAU;AAEpC,UAAI,CAAC,mBAAmB;AAGtB,eAAO,YAAM,cAAc,YAAY;MACzC;AAEA,UAAM,gBAAgB,MAAM,QAAQ,YAAY;AAChD,UAAM,gBAAgB,MAAM,QAAQ,YAAY;AAChD,UAAI,kBAAkB;AAAe,eAAO;AAC5C,UAAI,iBAAiB,eAAe;AAClC,YAAM,WAAS,aAAa;AAC5B,YAAI,aAAa,WAAW,UAAQ;AAClC,iBAAO;QACT;AACA,iBAAS,IAAI,GAAG,IAAI,UAAQ,EAAE,GAAG;AAC/B,cACE,CAAC,oBACC,mBACA,aAAa,CAAC,GACd,aAAa,CAAC,GACd,OAAO,GAET;AACA,mBAAO;UACT;QACF;AACA,eAAO;MACT;AAEA,aAAO,oBACL,mBACA,cACA,cACA,OAAO;IAEX,OAAO;AACL,UAAM,WAAW,yBAAyB,WAAW,QAAQ,WAAW;AACxE,UAAI,UAAU;AAGZ,YAAI,iCAAiC,QAAQ;AAAG,iBAAO;AAEvD,eAAO;UACL,SAAS;;;;;UAKT;UACA;UACA;QAAO;MAEX;IACF;EACF,CAAC;AACH;AAEA,SAAS,iCACP,WAI0B;AAE1B,SACE,CAAC,CAAC,UAAU,cAAc,UAAU,WAAW,KAAK,sBAAsB;AAE9E;AAEA,SAAS,uBAAuB,KAAkB;AAChD,SAAO,IAAI,KAAK,UAAU;AAC5B;;;ACxDA,IAAA;;EAAA,WAAA;AAAA,aAAAC,eAAA;AACkB,WAAA,yBAAkC;AAmL1C,WAAA,iBAAiBC,MAAK,0BAA0B;QACtD,KACE,WAAW,8BAA8B;QAE3C,OAAO;OACR;IAiFH;AAnNS,IAAAD,aAAA,UAAA,QAAP,SAAgB,SAAoC;AAApD,UAAA,QAAA;AACE,UAAM,eACJ,OAAO,QAAQ,eAAe,WAAW,QAAQ,aAC/C,QAAQ,eAAe,QAAQ,OAC/B;AACJ,UAAI;AACJ,WAAK,mBACH,WAAA;AAAM,eAAC,eAAe,QAAQ,OAAO,KAAI;MAAnC,GACN,YAAY;AAEd,aAAO;IACT;AAcO,IAAAA,aAAA,UAAA,8BAAP,SACE,aACA,cAAoB;AAEpB,WAAK,mBAAmB,aAAa,YAAY;IACnD;AAMO,IAAAA,aAAA,UAAA,oBAAP,SAAyB,UAAsB;AAC7C,aAAO;IACT;AAIO,IAAAA,aAAA,UAAA,mBAAP,SAAwB,UAAsB;AAC5C,aAAO;IACT;AAEO,IAAAA,aAAA,UAAA,WAAP,SAAgB,QAA+B;AAC7C;IACF;AAEO,IAAAA,aAAA,UAAA,KAAP,WAAA;AACE,aAAO,CAAA;IACT;AAEO,IAAAA,aAAA,UAAA,SAAP,SACE,SAAoC;AAEpC,aAAO;IACT;AAGO,IAAAA,aAAA,UAAA,YAAP,SACE,SACA,YAAiC;AAAjC,UAAA,eAAA,QAAA;AAAA,qBAAA,CAAc,CAAC,QAAQ;MAAU;AAEjC,aAAO,KAAK,KAAI,SAAA,SAAA,CAAA,GACX,OAAO,GAAA,EACV,QAAQ,QAAQ,MAAM,cACtB,WAAU,CAAA,CAAA;IAEd;AAGO,IAAAA,aAAA,UAAA,gBAAP,SACE,SAA2C;AAD7C,UAAA,QAAA;AAGU,UAAA,WAAoD,QAAO,UAAjD,eAA0C,QAAO,cAAnC,OAA4B,QAAO,MAA7BE,MAAsB,QAAO,YAA7B,aAAUA,QAAA,SAAG,OAAIA;AACvD,UAAM,QAAQ,KAAK,eAAe,UAAU,YAAY;AAExD,UAAM,cAA+C;QACnD,mBAAmB;QACnB,IAAI,OAAO,SAAS,WAAW,OAAO,KAAK,SAAS,IAAI;QACxD;QACA;;AAGF,UAAI;AAEJ,aAAO,IAAI,WAAW,SAAC,UAAQ;AAC7B,eAAO,MAAK,MAAK,SAAA,SAAA,CAAA,GACZ,WAAW,GAAA,EACd,WAAW,MACX,UAAQ,SAAC,MAAI;AACX;;YAEE,cACA,aACE,OACA,EAAE,MAAM,eAAU,QAAV,eAAU,SAAA,SAAV,WAAY,OAAM,GAC1B,EAAE,MAAM,KAAK,OAAM,CAAE;YAEvB;AACA;UACF;AAEA,cAAMC,UAAS;YACb,MAAM,KAAK;YACX,UAAU,CAAC,CAAC,KAAK;;AAGnB,cAAI,KAAK,SAAS;AAChB,YAAAA,QAAO,UAAU,eACf,KAAK,QAAQ,IAAI,SAAC,OAAK;AAAK,qBAAA,MAAM;YAAN,CAAa,CAAC;UAE9C;AAEA,uBAAa;AACb,mBAAS,KAAKA,OAAM;QACtB,EAAC,CAAA,CAAA;MAEL,CAAC;IACH;AAWO,IAAAH,aAAA,UAAA,eAAP,SACE,SACA,YAAiC;AAAjC,UAAA,eAAA,QAAA;AAAA,qBAAA,CAAc,CAAC,QAAQ;MAAU;AAEjC,aAAO,KAAK,KAAI,SAAA,SAAA,CAAA,GACX,OAAO,GAAA,EACV,OAAO,KAAK,eAAe,QAAQ,UAAU,QAAQ,YAAY,GACjE,QAAQ,QAAQ,IAChB,WAAU,CAAA,CAAA;IAEd;AAEO,IAAAA,aAAA,UAAA,aAAP,SAAiDE,KAIJ;AAH3C,UAAA,KAAEA,IAAA,IACF,OAAIA,IAAA,MACD,UAAO,OAAAA,KAHqC,CAAA,MAAA,MAAA,CAIhD;AACC,aAAO,KAAK,MACV,OAAO,OAAO,SAAS;QACrB,QAAQ,MAAM;QACd,QAAQ;OACT,CAAC;IAEN;AAEO,IAAAF,aAAA,UAAA,gBAAP,SAAoDE,KAMJ;AAL9C,UAAA,KAAEA,IAAA,IACF,OAAIA,IAAA,MACJ,WAAQA,IAAA,UACR,eAAYA,IAAA,cACT,UAAO,OAAAA,KALwC,CAAA,MAAA,QAAA,YAAA,cAAA,CAMnD;AACC,aAAO,KAAK,MACV,OAAO,OAAO,SAAS;QACrB,OAAO,KAAK,eAAe,UAAU,YAAY;QACjD,QAAQ;QACR,QAAQ;OACT,CAAC;IAEN;AAEO,IAAAF,aAAA,UAAA,cAAP,SACE,SACA,QAAmD;AAEnD,aAAO,KAAK,MAAM;QAChB,QAAM,SAAC,OAAK;AACV,cAAM,QAAQ,MAAM,UAA6B,OAAO;AACxD,cAAM,OAAO,OAAO,KAAK;AACzB,cAAI,SAAS,UAAU,SAAS;AAAM,mBAAO;AAC7C,gBAAM,WAAU,SAAA,SAAA,CAAA,GAAyB,OAAO,GAAA,EAAE,KAAI,CAAA,CAAA;AACtD,iBAAO;QACT;OACD;IACH;AAEO,IAAAA,aAAA,UAAA,iBAAP,SACE,SACA,QAAmD;AAEnD,aAAO,KAAK,MAAM;QAChB,QAAM,SAAC,OAAK;AACV,cAAM,QAAQ,MAAM,aAAgC,OAAO;AAC3D,cAAM,OAAO,OAAO,KAAK;AACzB,cAAI,SAAS,UAAU,SAAS;AAAM,mBAAO;AAC7C,gBAAM,cAAa,SAAA,SAAA,CAAA,GAAyB,OAAO,GAAA,EAAE,KAAI,CAAA,CAAA;AACzD,iBAAO;QACT;OACD;IACH;AAUF,WAAAA;EAAA,EA1QA;;AA4QA,IAAI,WAAU,YAAA,OAAA;AACZ,cAAY,UAAU,qBAAqB;AAC7C;;;AC7WM,IAAW;AAAjB,0BAAiBI,QAAK;AA8GtB,GA9GiB,UAAA,QAAK,CAAA,EAAA;;;;ACuBtB,IAAA;;EAAA,SAAA,QAAA;AAAuC,cAAAC,oBAAA,MAAA;AACrC,aAAAA,mBACkB,SACA,MACA,OACA,WAA+B;;AAG/C,UAAA,QAAA,OAAK,KAAA,MAAC,OAAO,KAAC;AANE,YAAA,UAAA;AACA,YAAA,OAAA;AACA,YAAA,QAAA;AACA,YAAA,YAAA;AAKhB,UAAI,MAAM,QAAQ,MAAK,IAAI,GAAG;AAC5B,cAAK,UAAU,MAAK;AACpB,iBAAS,IAAI,MAAK,KAAK,SAAS,GAAG,KAAK,GAAG,EAAE,GAAG;AAC9C,gBAAK,WAAOC,MAAA,CAAA,GAAKA,IAAC,MAAK,KAAK,CAAC,CAAC,IAAG,MAAK,SAAOA;QAC/C;MACF,OAAO;AACL,cAAK,UAAU,MAAK;MACtB;AAIC,YAAa,YAAYD,mBAAkB;;IAC9C;AAGF,WAAAA;EAAA,EAzBuC,KAAK;;;;;;;ACI7B,IAAgB,SAAW,OAAO,UAAS;AAEpD,SAAU,UAAU,OAAU;AAClC,SAAO,UAAU,QAAQ,UAAU;AACrC;AAIM,SAAU,wBACdE,KACA,SAA0B;MADxB,aAAUA,IAAA,YAAE,KAAEA,IAAA,IAAE,MAAGA,IAAA;AAGrB,MAAI,OAAO,eAAe,UAAU;AAClC,QAAI,SAAS;AACX,cAAQ,YACN,CAAC,UAAU,EAAE,IAAI,EAAE,GAAE,IACnB,CAAC,UAAU,GAAG,IAAI,EAAE,IAAG,IACvB;IACN;AAGA,QAAI,UAAU,EAAE,KAAK,CAAC,UAAU,GAAG,GAAG;AACpC,WAAK;IACP;AAEA,QAAI,CAAC,UAAU,EAAE,GAAG;AAClB,aAAO,GAAA,OAAG,YAAU,GAAA,EAAA,OAClB,OAAO,OAAO,YAAY,OAAO,OAAO,WACtC,KACA,KAAK,UAAU,EAAE,CAAC;IAExB;EACF;AACF;AAEA,IAAM,gBAAgB;EACpB,kBAAkB;EAClB,aAAa;EACb,eAAe;;;EAGf,iBAAiB;;AAGb,SAAU,gBAAgB,QAA2B;AACzD,SAAO,QAAQ,eAAe,MAAM;AACtC;AAEM,SAAU,sBACd,QAAoD;AAEpD,MAAM,QAAQ,OAAO;AACrB,SAAO,UAAU,SAAS,cAAc,kBAAkB;AAC5D;AAEM,SAAU,2BACd,OACA,mBAA0C;AAE1C,SAAO,YAAY,iBAAiB,IAC/B,MAAM,IAAI,kBAAkB,OAAO,YAAY,IAChD,qBAAqB,kBAAkB;AAC7C;AAEO,IAAM,wBAAwB;AAE/B,SAAU,uBAAuB,gBAAsB;AAC3D,MAAM,QAAQ,eAAe,MAAM,qBAAqB;AACxD,SAAO,QAAQ,MAAM,CAAC,IAAI;AAC5B;AAEM,SAAU,0BACd,cACAC,SACA,WAA+B;AAE/B,MAAI,gBAAgBA,OAAM,GAAG;AAC3B,WAAO,QAAQA,OAAM,IACjBA,QAAO,MAAM,SAAC,MAAI;AAChB,aAAA,0BAA0B,cAAc,MAAM,SAAS;IAAvD,CAAwD,IAE1D,aAAa,WAAW,MAAM,SAAC,OAAK;AAClC,UAAI,QAAQ,KAAK,KAAK,cAAc,OAAO,SAAS,GAAG;AACrD,YAAM,MAAM,uBAAuB,KAAK;AACxC,eACE,OAAO,KAAKA,SAAQ,GAAG,MACtB,CAAC,MAAM,gBACN,0BACE,MAAM,cACNA,QAAO,GAAG,GACV,SAAS;MAGjB;AAMA,aAAO;IACT,CAAC;EACP;AACA,SAAO;AACT;AAEM,SAAU,wBACd,OAAiB;AAEjB,SAAO,gBAAgB,KAAK,KAAK,CAAC,YAAY,KAAK,KAAK,CAAC,QAAQ,KAAK;AACxE;AAEM,SAAU,4BAAyB;AACvC,SAAO,IAAI,WAAU;AACvB;AAEM,SAAU,uBACd,UACA,WAA+B;AAO/B,MAAM,cAAc,kBAAkB,uBAAuB,QAAQ,CAAC;AACtE,SAAO;IACL;IACA,gBAAc,SAAC,MAAI;AACjB,UAAI,MAAqC,YAAY,IAAI;AACzD,UAAI,CAAC,OAAO,WAAW;AACrB,cAAM,UAAU,OAAO,IAAI;MAC7B;AACA,aAAO,OAAO;IAChB;;AAEJ;;;AClIA,IAAM,SAAyB,uBAAO,OAAO,IAAI;AACjD,IAAM,cAA6B,WAAA;AAAM,SAAA;AAAA;AACzC,IAAM,aAAiC,uBAAO,OAAO,IAAI;AAEzD,IAAA;;EAAA,WAAA;AAGE,aAAAC,aACkB,UACA,OAAiB;AAFnC,UAAA,QAAA;AACkB,WAAA,WAAA;AACA,WAAA,QAAA;AAJR,WAAA,OAA8B,uBAAO,OAAO,IAAI;AAgYlD,WAAA,UAEJ,uBAAO,OAAO,IAAI;AA0Dd,WAAA,OAEJ,uBAAO,OAAO,IAAI;AAkEf,WAAA,gBAAgB,SACrB,mBACA,gBAAsB;AAEtB,eAAA,gBACE,YAAY,iBAAiB,IAC3B,MAAK,IAAI,kBAAkB,OAAO,cAAc,IAChD,qBAAqB,kBAAkB,cAAc,CAAC;MAH1D;AASK,WAAA,UAA2B,SAAC,UAAQ;AACzC,eAAO,YAAY,QAAQ,IACvB,MAAK,IAAI,SAAS,KAAK,IACvB,OAAO,aAAa;MAC1B;AAMO,WAAA,cAAmC,SAAC,cAAc,gBAAc;AACrE,YAAI,OAAO,iBAAiB,UAAU;AACpC,iBAAO,cAAc,YAAY;QACnC;AAEA,YAAI,YAAY,YAAY,GAAG;AAC7B,iBAAO;QACT;AAEO,YAAA,KAAM,MAAK,SAAS,SAAS,YAAY,EAAC,CAAA;AAEjD,YAAI,IAAI;AACN,cAAM,MAAM,cAAc,EAAE;AAC5B,cAAI,gBAAgB;AAClB,kBAAK,MAAM,IAAI,YAAY;UAC7B;AACA,iBAAO;QACT;MACF;IApiBG;AAaI,IAAAA,aAAA,UAAA,WAAP,WAAA;AACE,aAAA,SAAA,CAAA,GAAY,KAAK,IAAI;IACvB;AAEO,IAAAA,aAAA,UAAA,MAAP,SAAW,QAAc;AACvB,aAAO,KAAK,OAAO,QAAQ,IAAI,MAAM;IACvC;AAEO,IAAAA,aAAA,UAAA,MAAP,SAAW,QAAgB,WAAiB;AAC1C,WAAK,MAAM,OAAO,QAAQ,SAAS;AACnC,UAAI,OAAO,KAAK,KAAK,MAAM,MAAM,GAAG;AAClC,YAAM,cAAc,KAAK,KAAK,MAAM;AACpC,YAAI,eAAe,OAAO,KAAK,aAAa,SAAS,GAAG;AACtD,iBAAO,YAAY,SAAS;QAC9B;MACF;AACA,UACE,cAAc,gBACd,OAAO,KAAK,KAAK,SAAS,mBAAmB,MAAM,GACnD;AACA,eAAO,KAAK,SAAS,kBAAkB,MAAM;MAC/C;AACA,UAAI,gBAAgB,OAAO;AACzB,eAAO,KAAK,OAAO,IAAI,QAAQ,SAAS;MAC1C;IACF;AAEU,IAAAA,aAAA,UAAA,SAAV,SACE,QACA,mBAA2B;AAO3B,UAAI;AAAmB,aAAK,MAAM,OAAO,QAAQ,UAAU;AAE3D,UAAI,OAAO,KAAK,KAAK,MAAM,MAAM,GAAG;AAClC,eAAO,KAAK,KAAK,MAAM;MACzB;AAEA,UAAI,gBAAgB,OAAO;AACzB,eAAO,KAAK,OAAO,OAAO,QAAQ,iBAAiB;MACrD;AAEA,UAAI,KAAK,SAAS,kBAAkB,MAAM,GAAG;AAC3C,eAAO,uBAAO,OAAO,IAAI;MAC3B;IACF;AAEO,IAAAA,aAAA,UAAA,QAAP,SAAa,OAA6B,OAA2B;AAArE,UAAA,QAAA;AACE,UAAI;AAGJ,UAAI,YAAY,KAAK;AAAG,gBAAQ,MAAM;AACtC,UAAI,YAAY,KAAK;AAAG,gBAAQ,MAAM;AAEtC,UAAM,WACJ,OAAO,UAAU,WAAW,KAAK,OAAQ,SAAS,KAAM,IAAI;AAE9D,UAAM,WACJ,OAAO,UAAU,WAAW,KAAK,OAAQ,SAAS,KAAM,IAAI;AAI9D,UAAI,CAAC;AAAU;AAEf,MAAAC,WAAU,OAAO,WAAW,UAAU,CAAA;AAEtC,UAAM,SAAsB,IAAI,WAAW,qBAAqB,EAAE,MAChE,UACA,QAAQ;AAKV,WAAK,KAAK,MAAM,IAAI;AAEpB,UAAI,WAAW,UAAU;AACvB,eAAO,KAAK,KAAK,MAAM;AACvB,YAAI,KAAK,MAAM,SAAS;AACtB,cAAM,kBAAmC,uBAAO,OAAO,IAAI;AAK3D,cAAI,CAAC;AAAU,4BAAc,WAAW;AAIxC,iBAAO,KAAK,QAAQ,EAAE,QAAQ,SAAC,gBAAc;AAC3C,gBACE,CAAC,YACD,SAAS,cAAc,MAAM,OAAO,cAAc,GAClD;AAGA,8BAAc,cAAc,IAAI;AAShC,kBAAM,YAAY,uBAAuB,cAAc;AACvD,kBACE,cAAc,kBACd,CAAC,MAAK,SAAS,WAAW,OAAO,YAAY,SAAS,GACtD;AACA,gCAAc,SAAS,IAAI;cAC7B;AAKA,kBAAI,OAAO,cAAc,MAAM,UAAU,EAAE,iBAAgB,QAAQ;AACjE,uBAAO,OAAO,cAAc;cAC9B;YACF;UACF,CAAC;AAED,cACE,gBAAc,cACd,EAAE,YAAY,SAAS;;;;UAKvB,KAAK,SAAS,kBAAkB,MAAM,MAAM,OAAO,YACnD;AACA,mBAAO,gBAAc;UACvB;AAEA,iBAAO,KAAK,eAAa,EAAE,QAAQ,SAAC,WAAS;AAC3C,mBAAA,MAAK,MAAM,MAAM,QAAkB,SAAS;UAA5C,CAA6C;QAEjD;MACF;IACF;AAEO,IAAAD,aAAA,UAAA,SAAP,SACE,QACA,QAAsD;AAFxD,UAAA,QAAA;AAIE,UAAM,cAAc,KAAK,OAAO,MAAM;AAEtC,UAAI,aAAa;AACf,YAAM,kBAAqC,uBAAO,OAAO,IAAI;AAC7D,YAAI,gBAAc;AAClB,YAAI,eAAa;AAEjB,YAAM,kBAAgB;UACpB;UACA;UACA;UACA,aAAa,KAAK;UAClB,SAAS,KAAK;UACd,WAAW,SACT,oBACA,MAA8B;AAE9B,mBAAA,MAAK,SAAS,UACZ,OAAO,uBAAuB,WAC5B;cACE,WAAW;cACX,MAAM,QAAQ,cAAc,MAAM;gBAEpC,oBACF,EAAE,OAAO,MAAI,CAAE;UAPjB;;AAWJ,eAAO,KAAK,WAAW,EAAE,QAAQ,SAAC,gBAAc;AAC9C,cAAM,YAAY,uBAAuB,cAAc;AACvD,cAAI,aAAa,YAAY,cAAc;AAC3C,cAAI,eAAe;AAAQ;AAC3B,cAAM,SACJ,OAAO,WAAW,aAAa,SAC7B,OAAO,cAAc,KAAK,OAAO,SAAS;AAE9C,cAAI,QAAQ;AACV,gBAAI,WACF,WAAW,cAAc,SACvB,OAAO,gBAAgB,UAAU,GAAC,SAAA,SAAA,CAAA,GAC7B,eAAa,GAAA,EAChB,WACA,gBACA,SAAS,MAAK,WAAW,QAAQ,cAAc,EAAC,CAAA,CAAA;AAGtD,gBAAI,aAAa,YAAY;AAC3B,oBAAK,MAAM,MAAM,QAAQ,cAAc;YACzC,OAAO;AACL,kBAAI,aAAa;AAAQ,2BAAW;AACpC,kBAAI,aAAa,YAAY;AAC3B,gCAAc,cAAc,IAAI;AAChC,gCAAc;AACd,6BAAa;AAEb,oBAAI,WAAU,YAAA,OAAA;AACZ,sBAAM,iBAAiB,SAAC,KAAc;AACpC,wBAAI,MAAK,OAAO,IAAI,KAAK,MAAM,QAAW;AACxC,iCAAU,YACR,SAAAC,WAAA,KAAA,GAAA,GAAA;6BACE;;;sBAKN,YAAC,QAAA,GAAA;AACD,mCAAA,QAAA;kBACF,WACE,MAAA,QAAe,QAAU,GAAA;wBACpB,gBAAkB;AACvB,wBAAA,mBAAA;AACA,6BAAI,KAAA,GAAa,aAAkB,UAAA,KAAA,WAAA,QAAA,MAAA;AAC/B,0BAAA,QAAA,WAAgB,EAAS;AAC7B,0BAAoB,YAAA,KAAA,GAAA;AAAT,wCAAK;AACV,4BAAA,eAAkB,KAAG;AACvB;;AAGA,4BAAA,OAAA,UAAA,YAAA,CAAA,CAAA,OAAA;AACA,8BAAA,KAAA,MAAA,SAAA,SAAA,KAAA,EAAA,CAAA;AAES,8BAAA,IAAE;AACT,+CAAA;0BACA;;;0BAGF,iBAAC,qBAAA,QAAA;AACF,mCAAA,YAAA,SAAAA,WAAA,KAAA,GAAA,gBAAA;AACG;;;;;;;;6BAWX,QAAA;AACH,2BAAC;UACH;;2BAEE;AACF,eAAC,MAAA,QAAA,eAAA;AACA,cAAA,cAAA;AAEC,gBAAA,gBAAc,OAAA;AACX,mBAAM,KAAM,MAAE,IAAA;YAEf,OACE;AACF,qBAAK,KAAK,KAAO,MAAG;YACtB;iBAAO,MAAC,MAAA,QAAA,UAAA;;iBAEP;;;;;AAcT,IAAAD,aAAA,UAAA,SAAA,SAAA,QAAA,WAAA,MAAA;AACA,UAAAE;AACA,UAAA,cAAA,KAAA,OAAA,MAAA;AACO,UAAA,aAAA;;AAKC,YAAA,iBAAmB,aAAe,OACpC,KAAA,SAAc,kBAAA,EAAA,UAAA,WAAA,KAAA,CAAA,IACV;AACN,eAAM,KAAA,OAAc,QAClB,kBAAmBA,MAAA,CAAA,GACjBA,IAAA,cAAc,IAAA,aAChBA,OAAE,WAAU;;;;iBASf,UAAA,QAAA,SAAA,SAAA,OAAA;AACD,UAAA,UAAa;AACd,UAAA,QAAA,IAAA;AAEM,YAAA,OAAA,KAAA,KAAK,MAAZ,QAAa,EAAA,GAA2B;AAClC,oBAAU,KAAM,OAAA,QAAA,IAAA,QAAA,WAAA,QAAA,IAAA;QAChB;AACF,YAAI,gBAAgB,SAAO,SAAW,OAAG;AACvC,oBAAU,KAAK,OAAO,MAAA,SAAY,KAAQ,KAAA;QAC5C;AAKA,YAAA,QAAA,aAAA,SAAA;AACA,eAAA,MAAA,MAAA,QAAA,IAAA,QAAA,aAAA,UAAA;QACA;;;;iBAID,UAAA,QAAA,WAAA;AACD,WAAA,QAAO,IAAQ;IACjB;AAEO,IAAAF,aAAA,UAAA,UAAP,WAAA;AACE,UAAI,QAAQ;AACb,UAAA,MAAA,KAAA,SAAA;AAEM,UAAA,eAAA,CAAA;AAAP,WAAA,aAYC,EAAA,QAAA,SAAA,IAAA;AAXO,YAAG,CAAA,OAAQ,KAAA,MAAW,SAAA,mBAAA,EAAA,GAAA;AACtB,uBAA2B,KAAC,EAAA;QAC9B;;uBAEA,QAAiB;AACnB,YAAC,SAAA,EAAA,cAAA,aAAA,KAAA,EAAA;MACH;AACA,aAAI;;iBAEH,UAAA,UAAA,SAAA,SAAA;AACD,UAAA,QAAW;AACZ,aAAA,KAAA,KAAA,IAAA,EAAA,QAAA,SAAA,QAAA;AAEM,YAAA,EAAA,WAAA,OAAP,KAAA,SAAe,MAAqC,IAAA;AAApD,gBAAA,OAeC,MAAA;QAdC;;mBAEQ;AACN,YAAC,SAAA,QAAA,QAAA,SAAA,OAAA,SAAA,CAAA,QAAA,CAAA;AACA,eAAA,KAAA,MAAA,EAAA,QAAA,SAAA,QAAA;AACC,gBAAU,MAAA,QAAA,OAAA,MAAA,CAAA;QACJ,CAAA;AACR,YAAA,QAAY;AACV,iBAAK,aAAc,QAAK,KAAM,QAAkB,IAAA;QAClD;;;iBAGC,UAAA,SAAA,SAAA,QAAA;AACH,aAAC,KAAA,QAAA,MAAA,KAAA,KAAA,QAAA,MAAA,KAAA,KAAA;IACH;AAcO,IAAAA,aAAA,UAAA,UAAP,SAAc,QAAc;AAC1B,UAAA,KAAQ,QAAK,MAAQ,IAAM,GAAC;AAC7B,YAAA,QAAA,EAAA,KAAA,QAAA,MAAA;AAEM,YAAA,CAAA;AACG,iBAAC,KAAQ,QAAW,MAAG;AAC7B,eAAM;;;;AAKV,IAAAA,aAAC,UAAA,eAAA,SAAA,KAAA;AAED,UAAA,QAAA,QAAA;AAAA,cAAA,oBAAA,IAAA;MAAA;AACA,aAAA,KAAA,KAAA,OAAA,EAAA,QAAA,IAAA,KAAA,GAAA;AACO,UAAA,gBAAA,OAAA;AAAa,aAAA,OAAA,aAAA,GAAU;MAC5B,OACI;AAGF,eAAA,KAAA,KAAA,SAAA,iBAAA,EAAA,QAAA,IAAA,KAAA,GAA+D;;aAE/D;;AAOJ,IAAAA,aAAA,UAAA,KAAA,WAAA;AACA,UAAA,QAAA;AACA,UAAA,MAAA,KAAA,aAAA;AACO,UAAA,WAAA,KAAE,SAAT;AAAA,UAAA,QAAA,SAqBC,IAAA;AApBO,YAAG,OAAQ,KAAA,UAAe,EAAA,GAAA;AAI5B,iBAAA,KAAA,MAAA,gBAAA,EAAA,CAAA,EAAA,QAAA,IAAA,KAAA,GAAA;AAGA,iBAAO,SAAK,EAAK;;;wBAGV,OAAS,KAAI,QAAA;UACtB,YAAC,QAAA;AACA,YAAA,SAAA;AACG,eAAA,kBAAyB;AAC3B,mBAAY,OAAQ;AACtB,oBAAQ,QAAqB,SAAA,IAAA;AAAA,iBAAA,OAAA,OAAA,EAAA;QAAA,CAAA;;;;iBAG9B,UAAA,kBAAA,SAAA,QAAA;AACD,UAAA,CAAA,OAAO,KAAA,KAAY,MAAA,MAAA,GAAA;AACpB,YAAA,UAAA,KAAA,KAAA,MAAA,IAAA,uBAAA,OAAA,IAAA;AAOM,YAAAG,QAAA,KAAA,KAAA,MAAA;AACD,YAAC,CAAAA;AACG,iBAAK;AACX,YAAM,YAAY,oBAAI,IAAC,CAAAA,KAAQ,CAAA;AAG/B,kBAAM,QAAU,SAAuC,KAAO;AAC9D,cAAA,YAAA,GAAA,GAAA;AACA,oBAAA,IAAA,KAAA,IAAA;;cASI,gBAAA,GAAA,GAAA;AACA,mBAAA,KAAA,GAAA,EAAA,QAAA,SAAA,KAAA;AACD,kBAAA,QAAA,IAAA,GAAA;AAGG,kBAAM,gBAAgB,KAAC,GAAA;AACvB,0BAAA,IAAA,KAAA;cACA;;;;;kBAKH,KAAA,MAAA;;iBAEJ,UAAA,eAAA,WAAA;AACD,aAAO,KAAK,MAAK,SAAQ,YAAA,SAAA;IAC3B;AAyBO,WAAAH;;;AA8DT,IAAA;;EAAA,WAAA;AACA,aAAAI,YAAA,SAAA,QAAA;AACA,UAAA,WAAA,QAAA;AAAA,iBAAA;MAAA;AACA,WAAA,UAAA;AAOE,WAAA,SAAA;AAEU,WAAA,IAAA;AADQ,WAAA,aAAA;;gBAPT,UAAqD,eAAA,WAAA;AAU5D,WAAK,IAAA,KAAA,UAAe,IAAA,IAAA;AACrB,WAAA,WAAA,IAAAC,MAAA,aAAA;IAEM;gBACC,UAAQ,SAAU,SAAoB,QAAC,gBAAA;AAC7C,UAAI,KAAC,GAAA;AACN,aAAA,EAAA,WAAA,QAAA,cAAA,CAAA;AAEM,YAAA,YAAA,uBAAqB,cAAE;AACxB,YAAI,cAAK,gBAAA;AAMT,eAAA,EAAA,WAAA,QAAA,SAAA,CAAA;;YAEA,KAAA,QAAA;AACA,eAAK,OAAE,OAAW,QAAQ,cAAY;QACxC;;;gBAGC,UAAA,QAAA,SAAA,QAAA,gBAAA;AACH,UAAC,KAAA,GAAA;AACF,aAAA,EAAA;UAAA,WAAA,QAAA,cAAA;;;;;;;;UAUK,mBAAA,aAAA,WAAA;QAAA;;;;;;SAML,WAAA,QAAA,gBAAA;AAID,SAAA,iBAAA,MAAA;;AAEA,SAAA,+BAAA,OAAA,UAAoD;AACpD,MAAA,sBAAwB,KAAM,GAAA;AAa5B,UAAA,MAAA,OAAA,UAAA,UAAA;;;UAGAC,cAAY;AAEf,MAAA;;IAAA,SAAA,QAAA;AAED,gBAAiBC,OAAW,MAAA;AAC1B,eAAAA,MAAAC,KAAA;AACA,YAAA,WAAAA,IAAA,UAAA,KAAAA,IAAA,eAAA,gBAAA,OAAA,SAAA,OAAA,IAAA,OAAAA,IAAA;AAA0B,YAAA,QAAA,OAAA,KAAW,MAAA,UAAA,IAAA,WAAA,aAAA,CAAA,KAAA;AACnC,cAAA,QAQC,IAAA,MAAA,KAAA;cAPC,cAAQ,IAAAH,MACR,aAAA;AAOA,YAAA;AAIc,gBAAA,QAAY,IAAA;AAiBZ,eAAA;;sBApBC,WAAY,SAAE,SAAA,QAAA;AAS7B,eAAA,KAAA,MAAA,SAAA,SAAA,MAAA;;YAEA,UAAA,cAAA,WAAA;AAED,eAAA;MAEM;YACL,UAAA,aAAA,WAA+B;AAC/B,eAAO,KAAK,YAAA,YAAA,SAAA;MACd;AAGO,aAAAE;kBACL;;eACD,OAAA;mBACF,cAAA,CAAA,EAAA;AACH,IAtCiB;;EAAA,SAAW,QAsC3B;AAED,cAAAE,QAAA,MAAA;AACA,aAAAA,OAAA,IAAA,QAAA,QAAiC,OAAA;AACjC,UAAA,QAAA,OAAA,KAAA,MAAA,OAAA,UAAA,KAAA,KAAA;AAAoB,YAAA,KAAA;AAClB,YAAA,SAEkB;AAIhB,YAAA,SAAA;AALgB,YAAA,QAAU;AACV,aAAA,KAAM;AACN,aAAA;;WAIhB,UAAW,WAAE,SAAA,SAAA,QAAA;;IACf;AAEO,IAAAA,OAAA,UAAA,cAAP,SAAgB,SAAiB;AAC/B,UAAA,QAAW;AAGN,UAAA,SAAA,KAAA,OAAW,YAAC,OAAe;AAAlC,UAAA,YAAA,KAuDC,IAAA;AAtDC,YAAA,KAAA,MAAA,SAAA;AAMI,iBAAA,KAAA,KAAA,IAAA,EAAA,QAAA,SAAA,QAAA;AACA,gBAAA,iBAAA,MAAA,KAAA,MAAA;AACA,gBAAA,oBAAA,OAAA,QAAA,EAA6C,MAAA;AAC7C,gBAAO,CAAA,mBAAgB;AAMnB,oBAAA,OAAA,MAAA;uBAEA,CAAA,gBAAsB;AAItB,oBAAA,MAAA,MAAA,QAAA,UAAA;AACA,qBAAA,KAAA,iBAAA,EAAA,QAAA,SAAA,gBAAA;AACA,sBAAA,MAAA,MAAA,QAAA,cAAA;cACA,CAAA;uBAEE,mBAAiB,mBAAQ;AAG3B,qBAAA,KAAA,cAAA,EAAA,QAAA,SAAA,gBAAA;AACA,oBAAA,CAAA,MAAA,eAAA,cAAA,GAAA,kBAAgE,cAAA,CAAA,GAAA;AAChE,wBAAW,MAAA,MAAA,QAAA,cAAA;gBACX;;;;;;;UAcN,WAAO,KAAO;AACf,eAAA;AAGD,aAAI,OAAM,SAAU,KAAM,IAAA,KAAA,MAAA;;WAE1B,UAAA,WAAA,WAAA;AACA,aAAO,SAAO,SAAS,CAAA,GAAK,KAAI,OAAK,SAAQ,CAAA,GAAA,KAAA,IAAA;IAC/C;AAEO,IAAAA,OAAA,UAAA,kBAAP,SAAA,QAAA;AACE,UAAA,aAAA,KAAA,OACK,gBAAY,MAAU;AAG5B,aAAA,OAAA,KAAA,KAAA,MAAA,MAAA,IAAA,SAAA,SAAA,CAAA,GAAA,UAAA,GAAA,OAAA,UAAA,gBAAA,KAAA,MAAA,MAAA,CAAA,IAAA;IAEM;WACL,UAAM,aAAkB,WAAO;AAC/B,UAAA,IAAO,KAAM;AAMd,aAAA,EAAA;AAEM,YAAA,EAAA;AACL,aAAK,EAAgB,WAAY;QAAA;;;MACW;;WAG1CA;eACA;;AAMN,IAAA;;EAAA,SAAA,QAAA;AACA,cAAAC,QAAA,MAAA;AACA,aAAAA,OAAAC,OAAA;AACA,aAAA,OAAA,KAAA,MAAA,qBAAAA,OAAA,WAAA;MAAA,GAAA,IAAA,WAAAA,MAAA,MAAA,SAAAA,MAAA,KAAA,CAAA,KAAA;IAAoB;AAClB,IAAAD,OAAA,UAAY,cAAsB,WAAA;AAOjC,aAAA;IAEM;WACL,UAAA,QAAA,SAAA,OAAgC,OAAA;AAOhC,aAAA,KAAA,OAAA,MAAA,OAAA,KAAA;;WAEAA;;;SAED,sBAAA,gBAAA,gBAAA,UAAA;AACH,MAAA,gBAAC,eAAA,QAAA;AAvBmB,MAAK,gBAuBxB,eAAA,QAAA;AAWC,SAAA,MAAA,eAAA,aAAA,IAAA,gBAAA;;AAEA,SAAA,sBAAA,OAAA;AAED,SAAA,CAAA,EAAA,iBAAA,eAAA,MAAA,MAAA;AAED;;;;;;;;;;ACp2BA,SAAS,YAAe,OAAQ;AAC9B,MAAI,gBAAgB,KAAK,GAAG;AAC1B,WAAO,QAAQ,KAAK,IACf,MAAM,MAAM,CAAC,IACf,SAAA,EAAG,WAAW,OAAO,eAAe,KAAK,EAAC,GAAK,KAAK;EACzD;AACA,SAAO;AACT;AAyDA,IAAA;;EAAA,WAAA;AAAA,aAAAE,eAAA;AAGU,WAAA,QAAQ,KAAK,gBAAgB,UAAU,KAAI;AAG3C,WAAA,OAAO,IAAIC,MAIhB,aAAa;AAQR,WAAA,SAAS,oBAAI,QAAO;AAiGpB,WAAA,aAAa,oBAAI,IAAG;AAGZ,WAAA,QAAQ,KAAK,MAAM,CAAA,CAAE;IACvC;AA3GS,IAAAD,aAAA,UAAA,UAAP,SAAe,OAAU;AACvB,aAAO,gBAAgB,KAAK,KAAK,KAAK,MAAM,IAAI,KAAK;IACvD;AAMO,IAAAA,aAAA,UAAA,OAAP,SAAY,OAAU;AACpB,UAAI,gBAAgB,KAAK,GAAG;AAC1B,YAAM,OAAO,YAAY,KAAK;AAC9B,aAAK,OAAO,IAAI,MAAM,KAAK;AAC3B,eAAO;MACT;AACA,aAAO;IACT;AAIO,IAAAA,aAAA,UAAA,QAAP,SAAa,OAAU;AAAvB,UAAA,QAAA;AACE,UAAI,gBAAgB,KAAK,GAAG;AAC1B,YAAM,WAAW,KAAK,OAAO,IAAI,KAAK;AACtC,YAAI;AAAU,iBAAO;AAErB,YAAM,QAAQ,OAAO,eAAe,KAAK;AACzC,gBAAQ,OAAO;UACb,KAAK,MAAM,WAAW;AACpB,gBAAI,KAAK,MAAM,IAAI,KAAK;AAAG,qBAAO;AAClC,gBAAM,QAAgB,MAAgB,IAAI,KAAK,OAAO,IAAI;AAI1D,gBAAM,OAAO,KAAK,KAAK,YAAY,KAAK;AACxC,gBAAI,CAAC,KAAK,OAAO;AACf,mBAAK,MAAM,IAAK,KAAK,QAAQ,KAAM;AAInC,kBAAI,WAAU,YAAA,OAAA;AACZ,uBAAO,OAAO,KAAK;cACrB;YACF;AACA,mBAAO,KAAK;UACd;UAEA,KAAK;UACL,KAAK,OAAO,WAAW;AACrB,gBAAI,KAAK,MAAM,IAAI,KAAK;AAAG,qBAAO;AAClC,gBAAM,UAAQ,OAAO,eAAe,KAAK;AACzC,gBAAM,UAAQ,CAAC,OAAK;AACpB,gBAAM,OAAO,KAAK,WAAW,KAAK;AAClC,oBAAM,KAAK,KAAK,IAAI;AACpB,gBAAM,oBAAkB,QAAM;AAC9B,iBAAK,OAAO,QAAQ,SAAC,KAAG;AACtB,sBAAM,KAAK,MAAK,MAAO,MAAc,GAAG,CAAC,CAAC;YAC5C,CAAC;AASD,gBAAM,OAAO,KAAK,KAAK,YAAY,OAAK;AACxC,gBAAI,CAAC,KAAK,QAAQ;AAChB,kBAAM,QAAO,KAAK,SAAS,OAAO,OAAO,OAAK;AAC9C,mBAAK,MAAM,IAAI,KAAG;AAClB,mBAAK,OAAO,QAAQ,SAAC,KAAK,GAAC;AACzB,sBAAI,GAAG,IAAI,QAAM,oBAAkB,CAAC;cACtC,CAAC;AAID,kBAAI,WAAU,YAAA,OAAA;AACZ,uBAAO,OAAO,KAAG;cACnB;YACF;AACA,mBAAO,KAAK;UACd;QACF;MACF;AACA,aAAO;IACT;AAMQ,IAAAA,aAAA,UAAA,aAAR,SAAmB,KAAW;AAC5B,UAAM,OAAO,OAAO,KAAK,GAAG;AAC5B,UAAM,OAAO,KAAK,KAAK,YAAY,IAAI;AACvC,UAAI,CAAC,KAAK,MAAM;AACd,aAAK,KAAI;AACT,YAAM,OAAO,KAAK,UAAU,IAAI;AAChC,YAAI,EAAE,KAAK,OAAO,KAAK,WAAW,IAAI,IAAI,IAAI;AAC5C,eAAK,WAAW,IAAI,MAAO,KAAK,OAAO,EAAE,QAAQ,MAAM,KAAI,CAAG;QAChE;MACF;AACA,aAAO,KAAK;IACd;AAOF,WAAAA;EAAA,EAvHA;;;;AC+BA,SAAS,wBACP,SAAgC;AAEhC,SAAO;IACL,QAAQ;IACR,QAAQ;IACR,QAAQ;;;IAGR,QAAQ,QAAQ;;AAEpB;AAEA,IAAA;;EAAA,WAAA;AAiCE,aAAAE,aAAY,QAAyB;AAArC,UAAA,QAAA;AAVQ,WAAA,eAAe,KAAK,gBAAgB,UAAU,KAAI;AAWxD,WAAK,SAAS,QAAQ,QAAQ;QAC5B,aAAa,OAAO,gBAAgB;QACpC,iBAAiB,sBAAsB,MAAM;OAC9C;AAED,WAAK,QAAQ,OAAO,SAAS,IAAI,YAAW;AAM5C,WAAK,sBAAsBC,MACzB,SAAC,SAAO;;AACE,YAAA,kBAAoB,QAAQ,QAAO;AAE3C,YAAM,WAAW,wBAAwB,OAAO;AAIhD,iBAAS,CAAC,IAAI,CAAC;AAEf,YAAM,SAAQC,MAAA,MAAK,qBAAoB,KAAI,MAAAA,KAAI,QAAQ;AAEvD,YAAI,OAAO;AACT,cAAI,iBAAiB;AACnB,mBAAA,SAAA,SAAA,CAAA,GACK,KAAK,GAAA;;;cAGR,QAAQ,MAAK,MAAM,MAAM,MAAM,MAAM;YAAC,CAAA;UAE1C;AAGA,iBAAO;QACT;AAEA,uCACE,QAAQ,QAAQ,OAChB,QAAQ,aAAa,KAAK;AAK5B,eAAO,MAAK,qBAAqB,OAAO;MAC1C,GACA;QACE,KACE,KAAK,OAAO,sBACZ,WAAW,mCAAmC;QAEhD,SAAS;;;QAGT,cAAY,SAAC,cAAc,QAAQ,SAAS,iBAAe;AACzD,cAAI,sBAAsB,QAAQ,KAAK,GAAG;AACxC,mBAAO,QAAQ,MAAM,aACnB,cACA,YAAY,MAAM,IAAI,OAAO,QAAQ,QACrC,QAAQ,WACR,eAAe;UAEnB;QACF;OACD;AAGH,WAAK,0BAA0BD,MAC7B,SAAC,SAAoC;AACnC,uCACE,QAAQ,QAAQ,OAChB,QAAQ,aAAa,KAAK;AAE5B,eAAO,MAAK,yBAAyB,OAAO;MAC9C,GACA;QACE,KACE,KAAK,OAAO,sBACZ,WAAW,uCAAuC;QAEpD,cAAY,SAACC,KAAyB;cAAvB,QAAKA,IAAA,OAAE,QAAKA,IAAA,OAAE,UAAOA,IAAA;AAClC,cAAI,sBAAsB,QAAQ,KAAK,GAAG;AACxC,mBAAO,QAAQ,MAAM,aAAa,OAAO,OAAO,QAAQ,SAAS;UACnE;QACF;OACD;IAEL;AA5FO,IAAAF,aAAA,UAAA,aAAP,WAAA;AACE,WAAK,QAAQ,IAAI,YAAW;IAC9B;AAgGO,IAAAA,aAAA,UAAA,wBAAP,SAAgCE,KAOD;UAN7B,QAAKA,IAAA,OACL,QAAKA,IAAA,OACL,KAAAA,IAAA,QAAA,SAAM,OAAA,SAAG,eAAY,IACrB,YAASA,IAAA,WACT,KAAAA,IAAA,mBAAA,oBAAiB,OAAA,SAAG,OAAI,IACxB,KAAAA,IAAA,iBAAA,kBAAe,OAAA,SAAG,KAAK,OAAO,kBAAe;AAE7C,UAAM,WAAW,KAAK,OAAO,MAAM;AAEnC,kBAAS,SAAA,SAAA,CAAA,GACJ,iBAAiB,mBAAmB,KAAK,CAAC,CAAC,GAC3C,SAAU;AAGf,UAAM,UAAU,cAAc,MAAM;AACpC,UAAM,aAAa,KAAK,oBAAoB;QAC1C,cAAc,kBAAkB,KAAK,EAAE;QACvC,mBAAmB;QACnB,cAAc;QACd,SAAO,SAAA,EACL,OACA,OACA,UACA,WACA,WAAW,mBAAmB,SAAS,GACvC,gBAAe,GACZ,uBAAuB,OAAO,KAAK,OAAO,SAAS,CAAC;OAE1D;AAED,UAAI;AACJ,UAAI,WAAW,SAAS;AAKtB,kBAAU;UACR,IAAI,kBACF,aAAa,WAAW,OAAO,GAC/B,WAAW,SACX,OACA,SAAS;;AAGb,YAAI,CAAC,mBAAmB;AACtB,gBAAM,QAAQ,CAAC;QACjB;MACF;AAEA,aAAO;QACL,QAAQ,WAAW;QACnB,UAAU,CAAC;QACX;;IAEJ;AAEO,IAAAF,aAAA,UAAA,UAAP,SACEG,SACA,QACA,cACA,SAA+B;AAE/B,UACE,sBAAsB,QAAQ,KAAK,KACnC,KAAK,aAAa,IAAIA,OAAM,MAAM,cAClC;AACA,YAAM,SAAS,KAAK,oBAAoB;UACtC;UACA;UACA;;;;UAIA,KAAK,MAAM,QAAQA,OAAM;QAAC;AAE5B,YAAI,UAAUA,YAAW,OAAO,QAAQ;AACtC,iBAAO;QACT;MACF;AACA,aAAO;IACT;AAGQ,IAAAH,aAAA,UAAA,uBAAR,SAA6BE,KAKH;AAL1B,UAAA,QAAA;UACE,eAAYA,IAAA,cACZ,oBAAiBA,IAAA,mBACjB,eAAYA,IAAA,cACZ,UAAOA,IAAA;AAEP,UACE,YAAY,iBAAiB,KAC7B,CAAC,QAAQ,SAAS,kBAAkB,kBAAkB,KAAK,KAC3D,CAAC,QAAQ,MAAM,IAAI,kBAAkB,KAAK,GAC1C;AACA,eAAO;UACL,QAAQ,KAAK,MAAM;UACnB,SAAS,iCAAA,OAAiC,kBAAkB,OAAK,SAAA;;MAErE;AAEQ,UAAA,YAA+B,QAAO,WAA3B,WAAoB,QAAO,UAAjB,QAAU,QAAO;AAC9C,UAAM,WAAW,MAAM,cACrB,mBACA,YAAY;AAGd,UAAM,iBAAwC,CAAA;AAC9C,UAAI;AACJ,UAAM,gBAAgB,IAAI,WAAU;AAEpC,UACE,KAAK,OAAO,eACZ,OAAO,aAAa,YACpB,CAAC,SAAS,kBAAkB,QAAQ,GACpC;AAIA,uBAAe,KAAK,EAAE,YAAY,SAAQ,CAAE;MAC9C;AAEA,eAAS,cAAiBC,SAAuB,YAAkB;;AACjE,YAAIA,QAAO,SAAS;AAClB,oBAAU,cAAc,MAAM,UAAOD,MAAA,CAAA,GACnCA,IAAC,UAAU,IAAGC,QAAO;QAEzB;AACA,eAAOA,QAAO;MAChB;AAEA,UAAM,UAAU,IAAI,IAAI,aAAa,UAAU;AAE/C,cAAQ,QAAQ,SAAC,WAAS;;AAGxB,YAAI,CAAC,cAAc,WAAW,SAAS;AAAG;AAE1C,YAAI,QAAQ,SAAS,GAAG;AACtB,cAAI,aAAa,SAAS,UACxB;YACE,WAAW,UAAU,KAAK;YAC1B,OAAO;YACP,WAAW,QAAQ;YACnB,MAAM;aAER,OAAO;AAGT,cAAM,aAAa,uBAAuB,SAAS;AAEnD,cAAI,eAAe,QAAQ;AACzB,gBAAI,CAAC,sBAAsB,MAAM,SAAS,GAAG;AAC3C,wBAAU,cAAc,MAAM,UAAOD,MAAA,CAAA,GACnCA,IAAC,UAAU,IAAG,qBAAA,OAAqB,UAAU,KAAK,OAAK,OAAA,EAAA,OACrD,YAAY,iBAAiB,IAC3B,kBAAkB,QAAQ,YAC1B,YAAY,KAAK,UAAU,mBAAmB,MAAM,CAAC,CAAC;YAG9D;UACF,WAAW,QAAQ,UAAU,GAAG;AAC9B,gBAAI,WAAW,SAAS,GAAG;AACzB,2BAAa,cACX,MAAK,wBAAwB;gBAC3B,OAAO;gBACP,OAAO;gBACP;gBACA;eACD,GACD,UAAU;YAEd;UACF,WAAW,CAAC,UAAU,cAAc;AAKlC,gBAAI,QAAQ,iBAAiB;AAC3B,2BAAa,MAAK,MAAM,KAAK,UAAU;YACzC;UACF,WAAW,cAAc,MAAM;AAI7B,yBAAa,cACX,MAAK,oBAAoB;cACvB,cAAc,UAAU;cACxB,mBAAmB;cACnB,cAAc,YAAY,UAAU,IAAI,aAAa;cACrD;aACD,GACD,UAAU;UAEd;AAEA,cAAI,eAAe,QAAQ;AACzB,2BAAe,MAAI,KAAA,CAAA,GAAG,GAAC,UAAU,IAAG,YAAU,GAAA;UAChD;QACF,OAAO;AACL,cAAM,WAAW,yBACf,WACA,QAAQ,cAAc;AAGxB,cAAI,CAAC,YAAY,UAAU,SAAS,KAAK,iBAAiB;AACxD,kBAAM,kBAAkB,GAAA,UAAA,KAAA,KAAsB;UAChD;AAEA,cAAI,YAAY,SAAS,gBAAgB,UAAU,QAAQ,GAAG;AAC5D,qBAAS,aAAa,WAAW,QAAQ,QAAQ,KAAK,OAAO;UAC/D;QACF;MACF,CAAC;AAED,UAAMC,UAAS,eAAe,cAAc;AAC5C,UAAM,cAA0B,EAAE,QAAMA,SAAE,QAAO;AACjD,UAAM,SACJ,QAAQ,kBACN,KAAK,MAAM,MAAM,WAAW,IAG5B,gBAAgB,WAAW;AAI/B,UAAI,OAAO,QAAQ;AACjB,aAAK,aAAa,IAAI,OAAO,QAAQ,YAAY;MACnD;AAEA,aAAO;IACT;AAGQ,IAAAH,aAAA,UAAA,2BAAR,SAAiCE,KAKH;AAL9B,UAAA,QAAA;UACE,QAAKA,IAAA,OACL,QAAKA,IAAA,OACL,eAAYA,IAAA,cACZ,UAAOA,IAAA;AAEP,UAAI;AACJ,UAAI,gBAAgB,IAAI,WAAU;AAElC,eAAS,cAAiB,aAA4B,GAAS;;AAC7D,YAAI,YAAY,SAAS;AACvB,oBAAU,cAAc,MAAM,UAAOA,MAAA,CAAA,GAAIA,IAAC,CAAC,IAAG,YAAY,SAAOA,IAAA;QACnE;AACA,eAAO,YAAY;MACrB;AAEA,UAAI,MAAM,cAAc;AACtB,gBAAQ,MAAM,OAAO,QAAQ,MAAM,OAAO;MAC5C;AAEA,cAAQ,MAAM,IAAI,SAAC,MAAM,GAAC;AAExB,YAAI,SAAS,MAAM;AACjB,iBAAO;QACT;AAGA,YAAI,QAAQ,IAAI,GAAG;AACjB,iBAAO,cACL,MAAK,wBAAwB;YAC3B;YACA,OAAO;YACP;YACA;WACD,GACD,CAAC;QAEL;AAGA,YAAI,MAAM,cAAc;AACtB,iBAAO,cACL,MAAK,oBAAoB;YACvB,cAAc,MAAM;YACpB,mBAAmB;YACnB,cAAc,YAAY,IAAI,IAAI,OAAO;YACzC;WACD,GACD,CAAC;QAEL;AAEA,YAAI,WAAU,YAAA,OAAA;AACZ,uCAA6B,QAAQ,OAAO,OAAO,IAAI;QACzD;AAEA,eAAO;MACT,CAAC;AAED,aAAO;QACL,QAAQ,QAAQ,kBAAkB,KAAK,MAAM,MAAM,KAAK,IAAI;QAC5D;;IAEJ;AACF,WAAAF;EAAA,EAzaA;;AA2aA,SAAS,aAAa,MAAiB;AACrC,MAAI;AACF,SAAK,UAAU,MAAM,SAAC,GAAG,OAAK;AAC5B,UAAI,OAAO,UAAU;AAAU,cAAM;AACrC,aAAO;IACT,CAAC;EACH,SAASI,SAAQ;AACf,WAAOA;EACT;AACF;AAEA,SAAS,6BACP,OACA,OACA,YAAe;AAEf,MAAI,CAAC,MAAM,cAAc;AACvB,QAAM,YAAU,oBAAI,IAAI,CAAC,UAAU,CAAC;AACpC,cAAQ,QAAQ,SAAC,OAAK;AACpB,UAAI,gBAAgB,KAAK,GAAG;AAC1B,QAAAC;UAMA,CAAA,YAAc,KAAO;UACtB;UACA,2BAAA,OAAA,KAAA;UACJ,MAAA,KAAA;QACF;;;;;;;;;;;;;;AC7iBM,IAAM,YAAY,IAAI,KAAI;AAEjC,IAAM,eAAe,oBAAI,QAAO;AAQhC,SAAS,aAAa,OAAuB;AAC3C,MAAI,OAAO,aAAa,IAAI,KAAK;AACjC,MAAI,CAAC,MAAM;AACT,iBAAa,IACX,OACC,OAAO;MACN,MAAM,oBAAI,IAAG;MACb,KAAK,IAAG;KACR;EAEN;AACA,SAAO;AACT;AAEM,SAAU,YAAY,OAAuB;AACjD,eAAa,KAAK,EAAE,KAAK,QAAQ,SAAC,IAAE;AAAK,WAAA,GAAG,YAAY,KAAK;EAApB,CAAqB;AAChE;AAUM,SAAU,YAAY,OAAuB;AACjD,eAAa,KAAK,EAAE,KAAK,QAAQ,SAAC,IAAE;AAAK,WAAA,GAAG,YAAY,KAAK;EAApB,CAAqB;AAChE;AAEM,SAAU,QAAW,OAAQ;AACjC,MAAMC,UAAS,oBAAI,IAAG;AACtB,MAAM,YAAY,oBAAI,IAAG;AAEzB,MAAM,KAAqB,SAAU,UAAQ;AAC3C,QAAI,UAAU,SAAS,GAAG;AACxB,UAAI,UAAU,UAAU;AACtB,gBAAQ;AACR,QAAAA,QAAO,QAAQ,SAACC,QAAK;AAInB,uBAAaA,MAAK,EAAE,IAAI,MAAM,EAAE;AAGhC,oBAAUA,MAAK;QACjB,CAAC;AAED,YAAM,eAAe,MAAM,KAAK,SAAS;AACzC,kBAAU,MAAK;AACf,qBAAa,QAAQ,SAAC,UAAQ;AAAK,iBAAA,SAAS,KAAK;QAAd,CAAe;MACpD;IACF,OAAO;AAIL,UAAM,QAAQ,UAAU,SAAQ;AAChC,UAAI,OAAO;AACT,eAAO,KAAK;AACZ,qBAAa,KAAK,EAAE,IAAI,EAAE;MAC5B;IACF;AAEA,WAAO;EACT;AAEA,KAAG,eAAe,SAAC,UAAQ;AACzB,cAAU,IAAI,QAAQ;AACtB,WAAO,WAAA;AACL,gBAAU,OAAO,QAAQ;IAC3B;EACF;AAEA,MAAM,SAAU,GAAG,cAAc,SAAC,OAAK;AACrC,IAAAD,QAAO,IAAI,KAAK;AAChB,iBAAa,KAAK,EAAE,KAAK,IAAI,EAAE;AAC/B,WAAO;EACT;AAEA,KAAG,cAAc,SAAC,OAAK;AAAK,WAAAA,QAAO,OAAO,KAAK;EAAnB;AAE5B,SAAO;AACT;AAQA,SAAS,UAAU,OAAoB;AACrC,MAAI,MAAM,kBAAkB;AAC1B,UAAM,iBAAgB;EACxB;AACF;;;ACvGA,IAAM,qBAOF,uBAAO,OAAO,IAAI;AAEtB,SAAS,oBAAoB,MAAkB;AAI7C,MAAM,WAAW,KAAK,UAAU,IAAI;AACpC,SACE,mBAAmB,QAAQ,MAC1B,mBAAmB,QAAQ,IAAI,uBAAO,OAAO,IAAI;AAEtD;AAEM,SAAU,yBACd,WAAuB;AAEvB,MAAM,OAAO,oBAAoB,SAAS;AAE1C,SACE,KAAK,gBAAW,KAAA,cAAA,SAAA,QAAA,SAAA;AACf,QAAK,UAAW,SAAG,MAAC,KAAQ;AACrB,aAAO,QAAsB,UAAK,KAAK,IAAA;;AAC3C,QAA6B,YAAA,QAAA,YAAA,sBAAA,WAAA,SAAA,eAAA;AAEzB,UAAA,YAAa;QAAiB,QAAG;QAAA;;;;QAQjC;MAAA;AACA,UAAA,cACA,UAGA,WAAS,QAAU,eACnB,OAAM,KAAK,QAAQ,cAAW,CAAA,CAAA,GAAA;AAW9B,oBAAA,eAAA,QAAA,eAAyC,UAAA;;AAE3C,MAAAE,WAAC,cAAA,QAAA,GAAA,cAAA,KAAA,GAAA,GAAA,MAAA;AAED,aAAA;;AAQF,WACC,GAAA,OAAA,QAAA,UAAA,GAAA,EAAA,OAAA,KAAA,UAAA,SAAA,CAAA;;;AAaT,SAAA,uBAAqB,WAAA;AACrB,MAAM,OAAA,oBAAU,SACd;AAEA,SAAU,KAAG,cAEb,KACE,YAAc,SAAA,MAAAC,KAAA;AACb,QAAK,QAASA,IAAG,OAAA,YAAsCA,IAAA,WAAA,YAAAA,IAAA;QAA7B,YAAK,sBAAW,WAAE,SAAS,SAAA;AAC9C,UAAA,WAAY,QAAA,CAAA;AAChB,UAAM,YAAW,SAAU,OAAC,CAAA;AAC5B,UAAM,cAAY,KAAA;AAEd,YAAA,SAAS,gBAAW,MAAA,UAAA,GAAA;AAClB,cAAA,kBAAS,SAAsB,MAAA,CAAA;AAIjC,cAAA,IAAA,MAAA,WAAA,KAAA,SAAAC,IAAA;AAAA,mBAA+CA,GAAA,KAAA,UAAA;UAAA,CAAA;AAI/C,cAAA,gBAAA,KAAA,yBAAA,GAAA,SAAA;AAQA,iBAAA,iBACA;YACE;;;;YAKE,QAAA,MAAA,CAAA;UAAA;;AAON;;AAEF,UAAC,cAAA,KAAA;AAEG,YAAA,eAAmB,SAAC,MAAA,CAAA;AACtB,YAAM,aAAY,OAAG,KAAS,WAAS,YAAA,GAAA;AACnC,cAAA,aAAa,QAAY,MAAA,CAAA;AAC3B,qBAAM,CAAA,IAAU;AAChB,iBAAA,eAAgB,WAAa,UAAA;;AAK/B;;AAEF,UAAC,MAAA;AAEG,eAAO,eAAA,MAAA,OAAA;;;AAGb,QAAG,SAAA,KAAA,UAAA,SAAA;AAQH,QAAA,QAAA,WAAA,MAAA;AACI,mBAAQ,MAAW;;AAEvB,WAAC;;;AAKN,SAAA,sBAAA,WAAA,WAAA;AAOC,MAAA,SAAA,IAAA,WAAA;AACA,SAAM,kBAAa,SAAa,EAAA,OAAA,SAAA,WAAA,MAAA;AAChC,QAAOD;;AACL,QAAI,YAAU,QAAU;AAGtB,eAAA,IAAA,KAAA,SAAA,GAAA,KAAA,GAAA,EAAA,GAAA;AACA,mBAAaA,MAAK,CAAA,GAAMA,IAAG,KAAI,CAAA,CAAA,IAAO,SAAMA;;AAE5C,kBAAC,OAAA,MAAA,WAAA,OAAA;;AAEH,WAAC;4BACD,OAAO,IAAU,CAAA;;AAEpB,SAAA,kBAAA,MAAA;AAED,MAAM,OAAA,oBAA4B,IAAkB;AAClD,MAAM,CAAA,KAAI,OAAG;AAET,QAAC,UAAa,KAAA,QAAA,CAAA;AAChB,QAAM,gBAA0B,CAAA;AAChC,SAAM,QAAA,SAA2B,GAAA,GAAA;AAE7B,UAAC,QAAQ,CAAA,GAAA;AACP,0BAAa,CAAA,EAAA,QAAA,SAAA,GAAA;AAAA,iBAAA,QAAA,KAAA,cAAA,OAAA,CAAA,CAAA;QAAA,CAAA;AACf,sBAAA,SAAqB;aAEtB;sBAAO,KAAA,CAAA;AACN,YAAA,CAAA,QAAW,KAAK,IAAI,CAAA,CAAA,GAAA;AAChB,kBAAQ,KAAK,cAAW,MAAA,CAAA,CAAA;AAC1B,wBAAW,SAAA;;;;;AAKnB,SAAC,KAAA;;AAGH,SAAC,WAAA,QAAA,KAAA;AAED,SAAS,OAAA,GACP;;AAID,SAAA,eAAA,QAAA,MAAA,SAAA;AAiBC,YAAA,WAAA;AACA,SAAO,UAAU,KAAI,OAAA,SAAW,QAAA,KAAA,KAAA;AAChC,WAAO,QACL,GAAK,IACH,IAAO,IAAA,SAAc,OAAA;AAAA,aAAA,QAAA,OAAA,GAAA;IAAA,CAAA,IACjB,OAAQ,QAAA,KAAC,GAAK;WACf,CAAC;;AAGV,SAAC,UAAA,OAAA;AAKC,MAAA,gBAAA,KAAA,GAAA;AACI,QAAA,QAAA,KAAgB,GAAA;AACd,aAAO,MAAM,IAAI,SAAA;;AAErB,WAAC,sBAAA,OAAA,KAAA,KAAA,EAAA,KAAA,GAAA,SAAA,MAAA;AACD,aAAO,eAAA,OAAsB,IAAO;;;AAGtC,SAAC;;;;ACvGH,SAAS,uBAAuB,MAAoB;AAClD,SACE,KAAK,SAAS,SAAS,KAAK,OAC1B,KAAK,QAAQ,yBAAyB,KAAK,OAAO,KAAK,SAAS,IAChE;AAEN;AA6FA,IAAM,kBAAqC,WAAA;AAAM,SAAA;AAAA;AACjD,IAAM,kBAAmC,SAAC,OAAO,SAAO;AAAK,SAAA,QAAQ;AAAR;AAI7D,IAAM,cAAuC,SAC3C,UACA,UACAE,KAAgB;MAAd,eAAYA,IAAA;AACX,SAAA,aAAa,UAAU,QAAQ;AAA/B;AACL,IAAM,eAAwC,SAAC,GAAG,UAAQ;AAAK,SAAA;AAAA;AAM/D,IAAA;;EAAA,WAAA;AAwCE,aAAAC,UACU,QAKP;AALO,WAAA,SAAA;AAxCF,WAAA,eAYJ,uBAAO,OAAO,IAAI;AAEd,WAAA,YAEJ,uBAAO,OAAO,IAAI;AAMd,WAAA,eAAe,oBAAI,IAAG;AAMtB,WAAA,gBAAgB,oBAAI,IAAG;AAIf,WAAA,oBACd,uBAAO,OAAO,IAAI;AACJ,WAAA,oBACd,uBAAO,OAAO,IAAI;AAEJ,WAAA,qBAAqB;AAUnC,WAAK,SAAM,SAAA,EACT,kBAAkB,wBAAuB,GACtC,MAAM;AAGX,WAAK,QAAQ,KAAK,OAAO;AAEzB,WAAK,gBAAgB,OAAO;AAC5B,WAAK,gBAAgB,UAAU;AAC/B,WAAK,gBAAgB,cAAc;AAEnC,UAAI,OAAO,eAAe;AACxB,aAAK,iBAAiB,OAAO,aAAa;MAC5C;AAEA,UAAI,OAAO,cAAc;AACvB,aAAK,gBAAgB,OAAO,YAAY;MAC1C;IACF;AAEO,IAAAA,UAAA,UAAA,WAAP,SACE,QACA,gBAA0C;;AAE1C,UAAM,WAAW;AAEjB,UAAM,WACH,mBACE,eAAe,cAAYD,MAAA,eAAe,iBAAW,QAAAA,QAAA,SAAA,SAAAA,IAAE,gBAC1D,OAAO;AAOT,UAAI,aAAa,KAAK,kBAAkB,YAAY;AAClD,eAAO,CAAC,YAAY;MACtB;AAGA,UAAM,cACH,kBAAkB,eAAe,eAAgB;AAEpD,UAAM,UAAO,SAAA,SAAA,CAAA,GACR,cAAc,GAAA,EACjB,UACA,aACA,WACG,kBAAkB,eAAe,aAClC,WAAA;AACE,YAAM,UAAU,0BAA0B,WAAW,WAAW;AAChE,eAAO,SAAS,UAAU,SAAS;UACjC,OAAO,SAAS,MAAM,MAAM;UAC5B,WAAW,QAAQ;SACpB;MACH,EAAC,CAAA;AAGL,UAAI;AAEJ,UAAM,SAAS,YAAY,KAAK,cAAc,QAAQ;AACtD,UAAI,QAAS,UAAU,OAAO,SAAU,KAAK,OAAO;AACpD,aAAO,OAAO;AACZ,YAAM,gBAAgB,MAAK,SAAA,SAAA,CAAA,GAAM,MAAM,GAAK,WAAW,GAAI,OAAO;AAClE,YAAI,QAAQ,aAAa,GAAG;AAC1B,kBAAQ,yBAAyB,aAAa;QAChD,OAAO;AACL,eAAK;AACL;QACF;MACF;AAEA,WAAK,KAAK,OAAO,EAAE,IAAI;AACvB,aAAO,QAAQ,YAAY,CAAC,IAAI,QAAQ,SAAS,IAAI,CAAC,EAAE;IAC1D;AAEO,IAAAC,UAAA,UAAA,kBAAP,SAAuB,cAA0B;AAAjD,UAAA,QAAA;AACE,aAAO,KAAK,YAAY,EAAE,QAAQ,SAAC,UAAQ;AACzC,YAAMD,MACJ,aAAa,QAAQ,GADf,YAASA,IAAA,WAAE,eAAYA,IAAA,cAAE,mBAAgBA,IAAA,kBAAK,WAAQ,OAAAA,KAAxD,CAAA,aAAA,gBAAA,kBAAA,CAA0D;AAiBhE,YAAI;AAAW,gBAAK,gBAAgB,SAAS,QAAQ;AACrD,YAAI;AAAc,gBAAK,gBAAgB,YAAY,QAAQ;AAC3D,YAAI;AAAkB,gBAAK,gBAAgB,gBAAgB,QAAQ;AAEnE,YAAI,OAAO,KAAK,MAAK,WAAW,QAAQ,GAAG;AACzC,gBAAK,UAAU,QAAQ,EAAE,KAAK,QAAQ;QACxC,OAAO;AACL,gBAAK,UAAU,QAAQ,IAAI,CAAC,QAAQ;QACtC;MACF,CAAC;IACH;AAEQ,IAAAC,UAAA,UAAA,mBAAR,SAAyB,UAAkB,UAAoB;AAA/D,UAAA,QAAA;AACE,UAAM,WAAW,KAAK,cAAc,QAAQ;AACpC,UAAA,YAAsB,SAAQ,WAAnB,SAAW,SAAQ;AAEtC,eAAS,SACPC,WACA,OAAoC;AAEpC,QAAAA,UAAS,QACP,OAAO,UAAU,aAAa,QAG5B,UAAU,OAAO,cAGjB,UAAU,QAAQ,eAClBA,UAAS;MACf;AAIA,eAAS,UAAU,SAAS,KAAK;AAEjC,eAAS;MAEP,cAAc,QAAQ,kBAGpB,QAAQ,SAAS,IAAI,yBAAyB,SAAS,IAEvD,OAAO,cAAc,aAAa,YAElC,SAAS;AAEb,UAAI,QAAQ;AACV,eAAO,KAAK,MAAM,EAAE,QAAQ,SAAC,WAAS;AACpC,cAAMA,YAAW,MAAK,eAAe,UAAU,WAAW,IAAI;AAC9D,cAAMC,YAAW,OAAO,SAAS;AAEjC,cAAI,OAAOA,cAAa,YAAY;AAClC,YAAAD,UAAS,OAAOC;UAClB,OAAO;AACG,gBAAA,UAAyBA,UAAQ,SAAxB,OAAgBA,UAAQ,MAAlB,QAAUA,UAAQ;AAEzC,YAAAD,UAAS;;YAGP,YAAY,QAAQ,kBAGlB,QAAQ,OAAO,IAAI,uBAAuB,OAAO,IAEjD,OAAO,YAAY,aAAa,UAEhCA,UAAS;AAEb,gBAAI,OAAO,SAAS,YAAY;AAC9B,cAAAA,UAAS,OAAO;YAClB;AAEA,qBAASA,WAAU,KAAK;UAC1B;AAEA,cAAIA,UAAS,QAAQA,UAAS,OAAO;AAMnC,YAAAA,UAAS,QAAQA,UAAS,SAAS;UACrC;QACF,CAAC;MACH;IACF;AAEQ,IAAAD,UAAA,UAAA,kBAAR,SACE,OACA,UAAwB;AAAxB,UAAA,aAAA,QAAA;AAAA,mBAAA;MAAwB;AAExB,UAAM,SAAS,UAAU,MAAM,YAAW;AAC1C,UAAM,MAAM,KAAK,kBAAkB,MAAM;AACzC,UAAI,aAAa,KAAK;AACpB,QAAAG,WACE,CAAC,OAAO,QAAQ,OAChB,GAAA,KAAA;AAKF,YAAI;AAAK,iBAAO,KAAK,kBAAkB,GAAG;AAE1C,aAAK,kBAAkB,QAAQ,IAAI;AAEnC,aAAK,kBAAkB,MAAM,IAAI;MACnC;IACF;AAEO,IAAAH,UAAA,UAAA,mBAAP,SAAwB,eAA+B;AAAvD,UAAA,QAAA;AACG,WAAK,qBAAiC;AACvC,aAAO,KAAK,aAAa,EAAE,QAAQ,SAAC,WAAS;AAI3C,cAAK,gBAAgB,WAAW,IAAI;AAEpC,sBAAc,SAAS,EAAE,QAAQ,SAAC,SAAO;AACvC,gBAAK,gBAAgB,SAAS,IAAI,EAAG,IAAI,SAAS;AAClD,cAAM,QAAQ,QAAQ,MAAM,qBAAqB;AACjD,cAAI,CAAC,SAAS,MAAM,CAAC,MAAM,SAAS;AAElC,kBAAK,cAAc,IAAI,SAAS,IAAI,OAAO,OAAO,CAAC;UACrD;QACF,CAAC;MACH,CAAC;IACH;AAEQ,IAAAA,UAAA,UAAA,gBAAR,SAAsB,UAAgB;AAAtC,UAAA,QAAA;AACE,UAAI,CAAC,OAAO,KAAK,KAAK,cAAc,QAAQ,GAAG;AAC7C,YAAM,WAA4C,KAAK,aACrD,QAAQ,IACN,uBAAO,OAAO,IAAI;AACtB,iBAAO,SAAS,uBAAO,OAAO,IAAI;AAuBlC,YAAI,eAAa,KAAK,aAAa,IAAI,QAAQ;AAC/C,YAAI,CAAC,gBAAc,KAAK,cAAc,MAAM;AAI1C,yBAAa,KAAK,gBAAgB,UAAU,IAAI;AAMhD,eAAK,cAAc,QAAQ,SAAC,QAAQ,OAAK;AACvC,gBAAI,OAAO,KAAK,QAAQ,GAAG;AAIzB,kBAAM,kBAAkB,MAAK,aAAa,IAAI,KAAK;AACnD,kBAAI,iBAAiB;AACnB,gCAAgB,QAAQ,SAAC,WAAS;AAChC,yBAAA,aAAY,IAAI,SAAS;gBAAzB,CAA0B;cAE9B;YACF;UACF,CAAC;QACH;AACA,YAAI,gBAAc,aAAW,MAAM;AACjC,uBAAW,QAAQ,SAAC,WAAS;AAC3B,gBAAMD,MAAsB,MAAK,cAAc,SAAS,GAAhD,SAAMA,IAAA,QAAK,OAAI,OAAAA,KAAjB,CAAA,QAAA,CAAmB;AACzB,mBAAO,OAAO,UAAQ,IAAI;AAC1B,mBAAO,OAAO,SAAO,QAAQ,MAAM;UACrC,CAAC;QACH;MACF;AAEA,UAAM,QAAQ,KAAK,UAAU,QAAQ;AACrC,UAAI,SAAS,MAAM,QAAQ;AAGzB,cAAM,OAAO,CAAC,EAAE,QAAQ,SAAC,QAAM;AAC7B,gBAAK,iBAAiB,UAAU,MAAM;QACxC,CAAC;MACH;AAEA,aAAO,KAAK,aAAa,QAAQ;IACnC;AAEQ,IAAAC,UAAA,UAAA,iBAAR,SACE,UACA,WACA,iBAAwB;AAQxB,UAAI,UAAU;AACZ,YAAM,gBAAgB,KAAK,cAAc,QAAQ,EAAE;AACnD,eACE,cAAc,SAAS,KACtB,oBAAoB,cAAc,SAAS,IAAI,uBAAO,OAAO,IAAI;MAEtE;IACF;AAEQ,IAAAA,UAAA,UAAA,kBAAR,SACE,SACA,iBAAwB;AAExB,UAAI,eAAe,KAAK,aAAa,IAAI,OAAO;AAChD,UAAI,CAAC,gBAAgB,iBAAiB;AACpC,aAAK,aAAa,IAAI,SAAU,eAAe,oBAAI,IAAG,CAAW;MACnE;AACA,aAAO;IACT;AAEO,IAAAA,UAAA,UAAA,kBAAP,SACE,UACA,UACAI,SACA,WAA+B;AAJjC,UAAA,QAAA;AAME,UAAI,CAAC,SAAS;AAAe,eAAO;AAIpC,UAAI,CAAC;AAAU,eAAO;AAEtB,UAAM,YAAY,SAAS,cAAc,KAAK;AAE9C,UAAI,aAAa;AAAW,eAAO;AAEnC,UAAI,KAAK,sBAAsB,KAAK,aAAa,IAAI,SAAS,GAAG;AAC/D,YAAM,uBAAuB,KAAK,gBAAgB,UAAU,IAAI;AAChE,YAAM,cAAY,CAAC,oBAAoB;AACvC,YAAM,iBAAe,SAAC,SAAe;AACnC,cAAMC,gBAAe,MAAK,gBAAgB,SAAS,KAAK;AACxD,cACEA,iBACAA,cAAa,QACb,YAAU,QAAQA,aAAY,IAAI,GAClC;AACA,wBAAU,KAAKA,aAAY;UAC7B;QACF;AAQA,YAAI,2BAA2B,CAAC,EAAED,WAAU,KAAK,cAAc;AAC/D,YAAI,wBAAwB;AAI5B,iBAAS,IAAI,GAAG,IAAI,YAAU,QAAQ,EAAE,GAAG;AACzC,cAAM,eAAe,YAAU,CAAC;AAEhC,cAAI,aAAa,IAAI,SAAS,GAAG;AAC/B,gBAAI,CAAC,qBAAqB,IAAI,SAAS,GAAG;AACxC,kBAAI,uBAAuB;AACzB,2BAAU,YACR,SAAAD,WAAA,KAAA,GAAA,UACA,SACA;cAEJ;AAKA,mCAAqB,IAAI,SAAS;YACpC;AACA,mBAAO;UACT;AAEA,uBAAa,QAAQ,cAAY;AAEjC,cACE;;UAGA,MAAM,YAAU,SAAS;;;;UAKzB,0BAA0B,SAAS,cAAcC,SAAS,SAAS,GACnE;AAIA,uCAA2B;AAC3B,oCAAwB;AAMxB,iBAAK,cAAc,QAAQ,SAAC,QAAQ,aAAW;AAC7C,kBAAM,QAAQ,SAAS,MAAM,MAAM;AACnC,kBAAI,SAAS,MAAM,CAAC,MAAM,UAAU;AAClC,+BAAa,WAAW;cAC1B;YACF,CAAC;UACH;QACF;MACF;AAEA,aAAO;IACT;AAEO,IAAAJ,UAAA,UAAA,aAAP,SAAkB,UAA8B,WAAiB;AAC/D,UAAM,SAAS,KAAK,eAAe,UAAU,WAAW,KAAK;AAC7D,aAAO,CAAC,EAAE,UAAU,OAAO;IAC7B;AAEO,IAAAA,UAAA,UAAA,oBAAP,SAAyB,WAAyB;AACxC,UAAA,WAAwB,UAAS,UAAvB,YAAc,UAAS;AACzC,UAAM,SAAS,KAAK,eAAe,UAAU,WAAW,KAAK;AAC7D,UAAI;AAEJ,UAAI,QAAQ,UAAU,OAAO;AAC7B,UAAI,SAAS,UAAU;AACrB,YAAM,UAA0C;UAC9C;UACA;UACA,OAAO,UAAU,SAAS;UAC1B,WAAW,UAAU;;AAEvB,YAAM,OAAO,uBAAuB,SAAS;AAC7C,eAAO,OAAO;AACZ,cAAM,oBAAoB,MAAM,MAAM,OAAO;AAC7C,cAAI,QAAQ,iBAAiB,GAAG;AAC9B,oBAAQ,uBAAuB,iBAAiB;UAClD,OAAO;AAGL,6BAAiB,qBAAqB;AACtC;UACF;QACF;MACF;AAEA,UAAI,mBAAmB,QAAQ;AAC7B,yBACE,UAAU,QACR,sBAAsB,UAAU,OAAO,UAAU,SAAS,IAC1D,gBAAgB,WAAW,uBAAuB,SAAS,CAAC;MAClE;AAIA,UAAI,mBAAmB,OAAO;AAC5B,eAAO;MACT;AAKA,aAAO,cAAc,uBAAuB,cAAc,IAAI,iBAC1D,YAAY,MAAM;IACxB;AAEO,IAAAA,UAAA,UAAA,YAAP,SACE,SACA,SAA+B;AAE/B,UAAM,oBAAoB,QAAQ;AAClC,UAAI,CAAC;AAAmB;AAExB,UAAM,cAAc,QAAQ,SAAS,QAAQ;AAC7C,UAAI,CAAC;AAAa;AAElB,UAAI,QAAQ,aAAa,QAAQ;AAC/B,YAAM,WAAW,QAAQ,MAAM,cAC7B,mBACA,YAAY;AAEd,YAAI;AAAU,kBAAQ,WAAW;MACnC;AAEA,UAAM,iBAAiB,KAAK,kBAAkB,OAAO;AACrD,UAAM,YAAY,uBAAuB,cAAc;AACvD,UAAM,WAAW,QAAQ,MAAM,cAC7B,mBACA,cAAc;AAEhB,UAAM,SAAS,KAAK,eAAe,QAAQ,UAAU,WAAW,KAAK;AACrE,UAAM,OAAO,UAAU,OAAO;AAE9B,UAAI,MAAM;AACR,YAAM,cAAc,yBAClB,MACA,mBACA,SACA,SACA,QAAQ,MAAM,WACZ,YAAY,iBAAiB,IAC3B,kBAAkB,QAClB,mBACF,cAAc,CACf;AAIH,eAAO,UAAU,UAAU,KAAK,OAAO,MAAM;UAC3C;UACA;SACD;MACH;AAEA,aAAO;IACT;AAEO,IAAAA,UAAA,UAAA,kBAAP,SACE,UACA,WAAiB;AAEjB,UAAM,SAAS,KAAK,eAAe,UAAU,WAAW,KAAK;AAC7D,aAAO,UAAU,OAAO;IAC1B;AAEO,IAAAA,UAAA,UAAA,mBAAP,SACE,gBACA,WACA,eAAiC;AAEjC,UAAI,SAGY,KAAK,eAAe,gBAAgB,WAAW,KAAK;AACpE,UAAI,QAAQ,UAAU,OAAO;AAC7B,UAAI,CAAC,SAAS,eAAe;AAC3B,iBAAS,KAAK,cAAc,aAAa;AACzC,gBAAQ,UAAU,OAAO;MAC3B;AACA,aAAO;IACT;AAEO,IAAAA,UAAA,UAAA,mBAAP,SACE,UACA,UACAD,KACA,SACA,SAAqB;UAFnB,QAAKA,IAAA,OAAE,WAAQA,IAAA,UAAE,QAAKA,IAAA;AAIxB,UAAI,UAAU,aAAa;AAIzB,eAAO,yBAAyB,QAAQ,KAAK,EAC3C,UACA,QAAuB;MAE3B;AAEA,UAAI,UAAU,cAAc;AAE1B,eAAO;MACT;AAMA,UAAI,QAAQ,WAAW;AACrB,mBAAW;MACb;AAEA,aAAO,MACL,UACA,UACA;QACE;;;;;;;;;;;;QAYA;QACA;UACE;UACA,WAAW,MAAM,KAAK;UACtB;UACA,WAAW,QAAQ;;QAErB;QACA,WAAW,uBAAO,OAAO,IAAI;MAAC,CAC/B;IAEL;AACF,WAAAC;EAAA,EArpBA;;AAupBA,SAAS,yBACP,UACA,mBACA,WACA,SACA,SAAoB;AAEpB,MAAM,iBAAiB,SAAS,kBAAkB,SAAS;AAC3D,MAAM,YAAY,uBAAuB,cAAc;AACvD,MAAM,YAAY,UAAU,aAAa,QAAQ;AAC3C,MAAAM,MAA2B,QAAQ,OAAjC,cAAWA,IAAA,aAAE,UAAOA,IAAA;AAE5B,SAAO;IACL,MAAM,uBAAuB,SAAS;IACtC,OAAO,UAAU,SAAS;IAC1B;IACA;IACA;IACA;IACA;IACA;IACA,OAAO,SAAS;IAChB;IACA,WAAS,WAAA;AACP,aAAO,SAAS,UACd,0BAA0B,WAAW,mBAAmB,SAAS,GACjE,OAAO;IAEX;IACA,cAAc,yBAAyB,QAAQ,KAAK;;AAExD;AAEM,SAAU,0BACd,eACA,mBACA,WAA+C;AAEvC,MAAG,qBAA8C,cAAa,CAAA,GAApC,OAAuB,cAAa,CAAA,GAAtB,OAAS,cAAa;AAEtE,MAAI;AAEJ,MAAI,OAAO,uBAAuB,UAAU;AAC1C,cAAU;MACR,WAAW;;;;MAIX,MAAM,OAAO,IAAI,OAAO;;EAE5B,OAAO;AACL,cAAO,SAAA,CAAA,GAAQ,kBAAkB;AAGjC,QAAI,CAAC,OAAO,KAAK,SAAS,MAAM,GAAG;AACjC,cAAQ,OAAO;IACjB;EACF;AAEA,MAAI,WAAW,YAAY,SAAK,QAAS,SAAA,QAAA;AACvC,eAAU,YACR,SAAAC,WAAA,KAAA,GAAA,oBAAA,MACA,KAAA,aAAoB,CAAA,CAAA;EAExB;AAEA,MAAI,WAAW,QAAQ,WAAW;AAChC,YAAQ,YAAY;EACtB;AAEA,SAAO;AACT;AAEA,SAAS,yBACP,OAAsB;AAEtB,SAAO,SAAS,aAAa,UAAU,UAAQ;AAC7C,QAAI,QAAQ,QAAQ,KAAK,QAAQ,QAAQ,GAAG;AAC1C,YAAM,kBAAkB,CAAA;IAC1B;AAMA,QAAI,gBAAgB,QAAQ,KAAK,gBAAgB,QAAQ,GAAG;AAC1D,UAAM,QAAQ,MAAM,cAAc,UAAU,YAAY;AACxD,UAAM,QAAQ,MAAM,cAAc,UAAU,YAAY;AACxD,UAAM,cAAc,SAAS,SAAS,UAAU;AAEhD,UAAI,aAAa;AACf,eAAO;MACT;AAEA,UAAI,YAAY,QAAQ,KAAK,wBAAwB,QAAQ,GAAG;AAI9D,cAAM,MAAM,SAAS,OAAO,QAAQ;AACpC,eAAO;MACT;AAEA,UAAI,wBAAwB,QAAQ,KAAK,YAAY,QAAQ,GAAG;AAK9D,cAAM,MAAM,UAAU,SAAS,KAAK;AACpC,eAAO;MACT;AAEA,UACE,wBAAwB,QAAQ,KAChC,wBAAwB,QAAQ,GAChC;AACA,eAAA,SAAA,SAAA,CAAA,GAAY,QAAQ,GAAK,QAAQ;MACnC;IACF;AAEA,WAAO;EACT;AACF;;;ACp9BA,SAAS,iBACP,SACA,YACA,UAA8B;AAE9B,MAAM,MAAM,GAAA,OAAG,UAAU,EAAA,OAAG,QAAQ;AACpC,MAAI,WAAW,QAAQ,QAAQ,IAAI,GAAG;AACtC,MAAI,CAAC,UAAU;AACb,YAAQ,QAAQ,IACd,KACC,WACC,QAAQ,eAAe,cAAc,QAAQ,aAAa,WACxD,UACD,SAAA,SAAA,CAAA,GACM,OAAO,GAAA,EACV,YACA,SAAQ,CAAA,CACR;EAEV;AACA,SAAO;AACT;AAUA,IAAA;;EAAA,WAAA;AACE,aAAAC,aACkB,OACR,QACA,WAA4C;AAFpC,WAAA,QAAA;AACR,WAAA,SAAA;AACA,WAAA,YAAA;IACP;AAEI,IAAAA,aAAA,UAAA,eAAP,SACE,OACAC,KAAmE;AAFrE,UAAA,QAAA;UAEI,QAAKA,IAAA,OAAEC,UAAMD,IAAA,QAAE,SAAMA,IAAA,QAAE,YAASA,IAAA,WAAE,YAASA,IAAA;AAE7C,UAAM,sBAAsB,uBAAuB,KAAK;AACxD,UAAM,SAAS,0BAAyB;AAExC,kBAAS,SAAA,SAAA,CAAA,GACJ,iBAAiB,mBAAmB,CAAC,GACrC,SAAU;AAGf,UAAM,UAAO,SAAA,SAAA,EACX,OACA,SAAS,uBAAO,OAAO,IAAI,GAC3B,OAAK,SAAI,UAAa,UAAW;AAC/B,eAAO,OAAO,MAAM,UAAU,QAAQ;MACxC,GACA,WACA,WAAW,mBAAmB,SAAS,EAAC,GACrC,uBAAuB,OAAO,KAAK,SAAS,CAAC,GAAA,EAChD,WAAW,CAAC,CAAC,WACb,cAAc,oBAAI,IAAG,GACrB,YAAY,OACZ,UAAU,OACV,SAAS,oBAAI,IAAG,EAAE,CAAA;AAGpB,UAAM,MAAM,KAAK,oBAAoB;QACnC,QAAQC,WAAU,uBAAO,OAAO,IAAI;QACpC;QACA,cAAc,oBAAoB;QAClC,WAAW,EAAE,KAAK,oBAAI,IAAG,EAAE;QAC3B;OACD;AAED,UAAI,CAAC,YAAY,GAAG,GAAG;AACrB,cAAM,kBAAkB,IAAAA,OAAA;MAC1B;AAIA,cAAQ,aAAa,QACnB,SAACD,KAA0CE,SAAM;YAA9C,cAAWF,IAAA,aAAE,YAASA,IAAA,WAAE,eAAYA,IAAA;AACrC,YAAM,YAAY,cAAcE,OAAM;AAEtC,YAAI,aAAa,UAAU,IAAI,MAAM;AACnC,cAAM,UAAU,MAAK,YACnB,WACA,WACA,aACA,OAAO;AAET,cAAI,YAAY,OAAO,GAAG;AAIxB;UACF;AAGA,wBAAc;QAChB;AAEA,YAAI,WAAW,YAAS,SAAY,CAAA,QAAA,WAAA;AAClC,cAAM,4BACJ,uBAAO,OAAO,IAAI;AACpB,uBAAa,QAAQ,SAAC,OAAK;AACzB,gBAAI,MAAM,cAAc;AACtB,wCAAwB,MAAM,KAAK,KAAK,IAAI;YAC9C;UACF,CAAC;AAED,cAAM,oBAAkB,SAAC,gBAAsB;AAC7C,mBAAA,0BAAwB,uBAAuB,cAAc,CAAC,MAC9D;UADA;AAGF,cAAM,qBAAmB,SAAC,gBAAsB;AAC9C,gBAAM,YAAY,aAAa,UAAU,IAAI,IAAI,cAAc;AAC/D,mBAAO,QAAQ,aAAa,UAAU,QAAQ,UAAU,KAAK,KAAK;UACpE;AAEA,iBAAO,KAAK,WAAW,EAAE,QAAQ,SAAC,gBAAc;AAK9C,gBACE,kBAAgB,cAAc,KAC9B,CAAC,mBAAiB,cAAc,GAChC;AACA,gCACE,WACA,aACA,gBACA,QAAQ,KAAK;YAEjB;UACF,CAAC;QACH;AAEA,cAAM,MAAMA,SAAQ,WAAW;MACjC,CAAC;AAQH,YAAM,OAAO,IAAI,KAAK;AAEtB,aAAO;IACT;AAEQ,IAAAH,aAAA,UAAA,sBAAR,SAA4BC,KAQC;AAR7B,UAAA,QAAA;UACE,SAAMA,IAAA,QACNC,UAAMD,IAAA,QACN,eAAYA,IAAA,cACZ,UAAOA,IAAA,SAGP,YAASA,IAAA;AAED,UAAA,WAAa,KAAK,MAAK;AAI/B,UAAI,WAAwB,uBAAO,OAAO,IAAI;AAK9C,UAAM,WACH,UAAU,SAAS,kBAAkB,MAAM,KAC5C,sBAAsBC,SAAQ,cAAc,QAAQ,WAAW,KAC9D,UAAW,QAAQ,MAAM,IAAI,QAAQ,YAAY;AAEpD,UAAI,aAAa,OAAO,UAAU;AAChC,iBAAS,aAAa;MACxB;AAUA,UAAM,YAA+B,WAAA;AACnC,YAAM,UAAU,0BACd,WACA,UACA,QAAQ,SAAS;AAGnB,YAAI,YAAY,QAAQ,IAAI,GAAG;AAC7B,cAAM,OAAO,QAAQ,aAAa,IAAI,QAAQ,KAAK,KAAK;AACxD,cAAI,MAAM;AACR,gBAAM,WAAS,SAAS,UAAS,SAAA,SAAA,CAAA,GAE1B,OAAO,GAAA,EACV,MAAM,KAAK,YAAW,CAAA,GAExB,OAAO;AAGT,gBAAI,aAAW,QAAQ;AACrB,qBAAO;YACT;UACF;QACF;AAEA,eAAO,SAAS,UAAU,SAAS,OAAO;MAC5C;AAEA,UAAM,eAAe,oBAAI,IAAG;AAE5B,WAAK;QACH;QACAA;;;;QAIA;QACA;MAAQ,EACR,QAAQ,SAACE,UAAS,OAAK;;AACvB,YAAM,iBAAiB,uBAAuB,KAAK;AACnD,YAAM,QAAQF,QAAO,cAAc;AAEnC,qBAAa,IAAI,KAAK;AAEtB,YAAI,UAAU,QAAQ;AACpB,cAAM,iBAAiB,SAAS,kBAAkB;YAChD;YACA,WAAW,MAAM,KAAK;YACtB;YACA,WAAWE,SAAQ;WACpB;AAED,cAAM,YAAY,kBAAkB,WAAW,cAAc;AAE7D,cAAI,gBAAgB,MAAK;YACvB;YACA;;;YAGA,MAAM,eACJ,iBAAiBA,UAAS,OAAO,KAAK,IACtCA;YACF;UAAS;AAMX,cAAI,gBAAa;AAIjB,cACE,MAAM,iBACL,YAAY,aAAa,KAAK,wBAAwB,aAAa,IACpE;AACA,4BAAgB,UAAkB,cAAc,aAAa;UAC/D;AAEA,cAAM,QAAQ,SAAS,iBACrB,UACA,MAAM,KAAK,OACX,aAAa;AAGf,cAAI,OAAO;AACT,sBAAU,OAAO;;cAEf;cACA;cACA;;UAEJ,OAAO;AACL,uCAA2B,WAAW,cAAc;UACtD;AAEA,qBAAWA,SAAQ,MAAM,WAAQH,MAAA,CAAA,GAC/BA,IAAC,cAAc,IAAG;QAEtB,WACE,WAAO,YAAA,SACP,CAACG,SAAQ,cACT,CAACA,SAAQ,YACT,CAAC,sBAAsB,MAAM,KAAK;;;QAIlC,CAAC,SAAS,gBAAgB,UAAU,MAAM,KAAK,KAAK,GACpD;AACA,qBAAU,YACR,SAAAC,WAAA,MAAA,IAAA,uBACA,KAAA,GAAAH,OAAuB;QAG3B;MACF,CAAC;AAID,UAAI;AACI,YAAA,KAAkB,SAAS,SAASA,SAAQ;UAChD;UACA;UACA,aAAa,QAAQ;UACrB,aAAa;UACb;SACD,GANM,KAAE,GAAA,CAAA,GAAE,YAAS,GAAA,CAAA;AAUpB,iBAAS,UAAU;AAInB,YAAI,WAAW;AAEb,qBAAW,QAAQ,MAAM,UAAU,SAAS;QAC9C;MACF,SAAS,GAAG;AAEV,YAAI,CAAC;AAAQ,gBAAM;MACrB;AAEA,UAAI,aAAa,OAAO,QAAQ;AAC9B,YAAM,UAAU,cAAc,MAAM;AAOpC,YAAM,OAAO,QAAQ,QAAQ,MAAM,MAAM,QAAQ,QAAQ,MAAM,IAAI,CAAA;AACnE,YAAI,KAAK,QAAQ,YAAY,KAAK;AAAG,iBAAO;AAC5C,aAAK,KAAK,YAAY;AAOtB,YACE,KAAK,UACL,KAAK,OAAO,QAAQA,SAAQ,SAAS,cAAc,OAAO,GAC1D;AACA,iBAAO;QACT;AAEA,YAAM,aAAW,QAAQ,aAAa,IAAI,MAAM;AAChD,YAAI,YAAU;AACZ,qBAAS,cAAc,QAAQ,MAAM,WAAS,aAAa,QAAQ;AACnE,qBAAS,YAAY,gBAAgB,WAAS,WAAW,SAAS;AAClE,uBAAa,QAAQ,SAAC,OAAK;AAAK,mBAAA,WAAS,aAAa,IAAI,KAAK;UAA/B,CAAgC;QAClE,OAAO;AACL,kBAAQ,aAAa,IAAI,QAAQ;YAC/B,aAAa;;;;YAIb,WAAW,iBAAiB,SAAS,IAAI,SAAS;YAClD;WACD;QACH;AAEA,eAAO;MACT;AAEA,aAAO;IACT;AAEQ,IAAAF,aAAA,UAAA,oBAAR,SACE,OACA,OACA,SACA,WAAoB;AAJtB,UAAA,QAAA;AAME,UAAI,CAAC,MAAM,gBAAgB,UAAU,MAAM;AAIzC,eAAO,WAAU,YAAU,QAAS,UAAM,KAAA,IAAA;MAC5C;AAEA,UAAI,QAAQ,KAAK,GAAG;AAClB,eAAO,MAAM,IAAI,SAAC,MAAM,GAAC;AACvB,cAAMM,SAAQ,MAAK,kBACjB,MACA,OACA,SACA,kBAAkB,WAAW,CAAC,CAAC;AAEjC,qCAA2B,WAAW,CAAC;AACvC,iBAAOA;QACT,CAAC;MACH;AAEA,aAAO,KAAK,oBAAoB;QAC9B,QAAQ;QACR,cAAc,MAAM;QACpB;QACA;OACD;IACH;AAIQ,IAAAN,aAAA,UAAA,gBAAR,SAWE,cACAE,SACA,SACA,UAA2E;AAA3E,UAAA,aAAA,QAAA;AAAA,mBAAW,sBAAsBA,SAAQ,cAAc,QAAQ,WAAW;MAAC;AAE3E,UAAM,WAAW,oBAAI,IAAG;AAChB,UAAA,WAAa,KAAK,MAAK;AAE/B,UAAM,eAAe,IAAIK,MAUtB,KAAK;AAER,OAAC,SAAS,QAERC,eACA,kBAA0B;AAE1B,YAAM,cAAc,aAAa;UAC/BA;;;;;UAKA,iBAAiB;UACjB,iBAAiB;QAAQ;AAE3B,YAAI,YAAY;AAAS;AACzB,oBAAY,UAAU;AAEtB,QAAAA,cAAa,WAAW,QAAQ,SAAC,WAAS;AACxC,cAAI,CAAC,cAAc,WAAW,QAAQ,SAAS;AAAG;AAE5C,cAAA,aAAyB,iBAAgB,YAA7B,WAAa,iBAAgB;AAC/C;;;;YAIE,EAAE,cAAc,aAChB,gBAAgB,UAAU,UAAU;YACpC;AACA,sBAAU,WAAW,QAAQ,SAAC,KAAG;AAC/B,kBAAM,OAAO,IAAI,KAAK;AACtB,kBAAI,SAAS;AAAU,6BAAa;AACpC,kBAAI,SAAS,SAAS;AACpB,oBAAM,OAAO,yBAAyB,KAAK,QAAQ,SAAS;AAK5D,oBAAI,CAAC,QAAS,KAA0B,OAAO,OAAO;AACpD,6BAAW;gBACb;cAGF;YACF,CAAC;UACH;AAEA,cAAI,QAAQ,SAAS,GAAG;AACtB,gBAAM,WAAW,SAAS,IAAI,SAAS;AACvC,gBAAI,UAAU;AAIZ,2BAAa,cAAc,SAAS;AACpC,yBAAW,YAAY,SAAS;YAClC;AAEA,qBAAS,IACP,WACA,iBAAiB,SAAS,YAAY,QAAQ,CAAC;UAEnD,OAAO;AACL,gBAAM,WAAW,yBACf,WACA,QAAQ,cAAc;AAGxB,gBAAI,CAAC,YAAY,UAAU,SAAS,KAAK,iBAAiB;AACxD,oBAAM,kBACJ,IAAA,UAAA,KAAA,KACA;YAEJ;AAEA,gBACE,YACA,SAAS,gBACP,UACA,UACAN,SACA,QAAQ,SAAS,GAEnB;AACA,sBACE,SAAS,cACT,iBAAiB,SAAS,YAAY,QAAQ,CAAC;YAEnD;UACF;QACF,CAAC;MACH,GAAG,cAAc,OAAO;AAExB,aAAO;IACT;AAEQ,IAAAF,aAAA,UAAA,cAAR,SACE,WACA,UACA,UACA,SACA,gBAAsD;;AALxD,UAAA,QAAA;AAOE,UAAI,UAAU,IAAI,QAAQ,CAAC,YAAY,QAAQ,GAAG;AAChD,YAAM;;;;UAKF,CAAC,QAAQ,QAAQ;;;WAIhB,YAAY,QAAQ,KAAK,wBAAwB,QAAQ,KAE1D,WACA;;AAKJ,YAAM,MAAI;AAMV,YAAI,OAAK,CAAC,gBAAgB;AACxB,2BAAiB,CAAC,YAAY,GAAC,IAAI,IAAE,QAAQ,GAAC;QAChD;AAOA,YAAI;AAEJ,YAAM,aAAW,SACf,MACA,MAAqB;AAErB,iBACE,QAAQ,IAAI,IACV,OAAO,SAAS,WACd,KAAK,IAAI,IACT,SACF,QAAQ,MAAM,cAAc,MAAM,OAAO,IAAI,CAAC;QAEpD;AAEA,kBAAU,IAAI,QAAQ,SAAC,WAAW,gBAAc;AAC9C,cAAM,OAAO,WAAS,KAAG,cAAc;AACvC,cAAM,OAAO,WAAS,KAAG,cAAc;AAEvC,cAAI,WAAW;AAAM;AACrB,cAAI,gBAAgB;AAClB,2BAAe,KAAK,cAAc;UACpC;AACA,cAAM,OAAO,MAAK,YAChB,WACA,MACA,MACA,SACA,cAAc;AAEhB,cAAI,SAAS,MAAM;AACjB,8BAAgB,mBAAiB,oBAAI,IAAG;AACxC,4BAAc,IAAI,gBAAgB,IAAI;UACxC;AACA,cAAI,gBAAgB;AAClB,YAAAK,WAAU,eAAe,IAAG,MAAO,cAAc;UACnD;QACF,CAAC;AAED,YAAI,iBAAe;AAEjB,qBAAY,QAAQ,GAAC,IAAI,IAAE,MAAM,CAAC,IAAG,SAAA,CAAA,GAAM,GAAC;AAC5C,0BAAc,QAAQ,SAAC,OAAO,MAAI;AAC/B,qBAAiB,IAAI,IAAI;UAC5B,CAAC;QACH;MACF;AAEA,UAAI,UAAU,MAAM;AAClB,eAAO,KAAK,MAAM,SAAS,iBACzB,UACA,UACA,UAAU,MACV,SACA,mBAAkBJ,MAAA,QAAQ,OAAM,WAAU,MAAAA,KAAI,cAAc,CAAC;MAEjE;AAEA,aAAO;IACT;AACF,WAAAD;EAAA,EA9lBA;;AAgmBA,IAAM,qBAAkC,CAAA;AAExC,SAAS,kBACPS,KACA,MAAqB;MADnB,MAAGA,IAAA;AAGL,MAAI,CAAC,IAAI,IAAI,IAAI,GAAG;AAClB,QAAI,IAAI,MAAM,mBAAmB,IAAG,KAAM,EAAE,KAAK,oBAAI,IAAG,EAAE,CAAE;EAC9D;AACA,SAAO,IAAI,IAAI,IAAI;AACrB;AAEA,SAAS,gBACP,MACA,OAA4B;AAE5B,MAAI,SAAS,SAAS,CAAC,SAAS,iBAAiB,KAAK;AAAG,WAAO;AAChE,MAAI,CAAC,QAAQ,iBAAiB,IAAI;AAAG,WAAO;AAE5C,MAAM,OACJ,KAAK,QAAQ,MAAM,OAAM,SAAA,SAAA,CAAA,GAElB,KAAK,IAAI,GACT,MAAM,IAAI,IAEf,KAAK,QAAQ,MAAM;AAEvB,MAAM,kBAAkB,KAAK,IAAI,QAAQ,MAAM,IAAI;AACnD,MAAM,MACJ,kBAAkB,oBAAI,IAAG,IACvB,KAAK,IAAI,OAAO,KAAK,MACrB,MAAM;AAEV,MAAM,SAAS,EAAE,MAAM,IAAG;AAE1B,MAAI,iBAAiB;AACnB,QAAM,uBAAqB,IAAI,IAAI,MAAM,IAAI,KAAI,CAAE;AAEnD,SAAK,IAAI,QAAQ,SAAC,UAAU,KAAG;AAC7B,aAAO,IAAI,IAAI,KAAK,gBAAgB,UAAU,MAAM,IAAI,IAAI,GAAG,CAAC,CAAC;AACjE,2BAAmB,OAAO,GAAG;IAC/B,CAAC;AAED,yBAAmB,QAAQ,SAAC,KAAG;AAC7B,aAAO,IAAI,IACT,KACA,gBAAgB,MAAM,IAAI,IAAI,GAAG,GAAG,KAAK,IAAI,IAAI,GAAG,CAAC,CAAC;IAE1D,CAAC;EACH;AAEA,SAAO;AACT;AAEA,SAAS,iBAAiB,MAA2B;AACnD,SAAO,CAAC,QAAQ,EAAE,KAAK,QAAQ,KAAK,IAAI;AAC1C;AAEA,SAAS,2BAA2BA,KAAoB,MAAqB;MAAvC,MAAGA,IAAA;AACvC,MAAM,YAAY,IAAI,IAAI,IAAI;AAC9B,MAAI,aAAa,iBAAiB,SAAS,GAAG;AAC5C,uBAAmB,KAAK,SAAS;AACjC,QAAI,OAAO,IAAI;EACjB;AACF;AAEA,IAAM,WAAW,oBAAI,IAAG;AAIxB,SAAS,kBACP,aACA,aACA,gBACA,OAAsB;AAEtB,MAAM,WAAW,SAAC,UAAiC;AACjD,QAAM,QAAQ,MAAM,cAA2B,UAAU,cAAc;AACvE,WAAO,OAAO,UAAU,YAAY;EACtC;AAEA,MAAM,WAAW,SAAS,WAAW;AACrC,MAAI,CAAC;AAAU;AAEf,MAAM,WAAW,SAAS,WAAW;AACrC,MAAI,CAAC;AAAU;AAIf,MAAI,YAAY,QAAQ;AAAG;AAI3B,MAAI,MAAM,UAAU,QAAQ;AAAG;AAK/B,MACE,OAAO,KAAK,QAAQ,EAAE,MACpB,SAAC,KAAG;AAAK,WAAA,MAAM,cAAc,UAAU,GAAG,MAAM;EAAvC,CAA6C,GAExD;AACA;EACF;AAEA,MAAM,aACJ,MAAM,cAAsB,aAAa,YAAY,KACrD,MAAM,cAAsB,aAAa,YAAY;AACvD,MAAM,YAAY,uBAAuB,cAAc;AACvD,MAAM,cAAc,GAAA,OAAG,YAAU,GAAA,EAAA,OAAI,SAAS;AAE9C,MAAI,SAAS,IAAI,WAAW;AAAG;AAC/B,WAAS,IAAI,WAAW;AAExB,MAAM,iBAA2B,CAAA;AAGjC,MAAI,CAAC,QAAQ,QAAQ,KAAK,CAAC,QAAQ,QAAQ,GAAG;AAC5C,KAAC,UAAU,QAAQ,EAAE,QAAQ,SAAC,OAAK;AACjC,UAAM,WAAW,MAAM,cAAc,OAAO,YAAY;AACxD,UAAI,OAAO,aAAa,YAAY,CAAC,eAAe,SAAS,QAAQ,GAAG;AACtE,uBAAe,KAAK,QAAQ;MAC9B;IACF,CAAC;EACH;AAEA,aAAU,YACR,SAAAC,WAAA,KAAA,IAAA,WAAA,YAAA,eAAA,SAiBE,uCACE,eAAe,KAAK,OAAO,IAC3B,gDACF,IACF,aAAW,SAAA,CAAA,GACN,QAAQ,GAAA,SAAA,CAAA,GACR,QAAQ,CAAA;AAEjB;;;ACx0BA,IAAA;;EAAA,SAAA,QAAA;AAAmC,cAAAC,gBAAA,MAAA;AA6BjC,aAAAA,eAAY,QAAgC;AAAhC,UAAA,WAAA,QAAA;AAAA,iBAAA,CAAA;MAAgC;AAC1C,UAAA,QAAA,OAAK,KAAA,IAAA,KAAE;AAzBD,YAAA,UAAU,oBAAI,IAAG;AAKjB,YAAA,uBAAuB,IAAI,kBAAkB,qBAAqB;AAU1D,YAAA,yBAAyB;AAOzB,YAAA,UAAU;AA4VlB,YAAA,UAAU;AAxVhB,YAAK,SAAS,gBAAgB,MAAM;AACpC,YAAK,cAAc,CAAC,CAAC,MAAK,OAAO;AAEjC,YAAK,WAAW,IAAI,SAAS;QAC3B,OAAO;QACP,kBAAkB,MAAK,OAAO;QAC9B,eAAe,MAAK,OAAO;QAC3B,cAAc,MAAK,OAAO;OAC3B;AAED,YAAK,KAAI;;IACX;AAEQ,IAAAA,eAAA,UAAA,OAAR,WAAA;AAIE,UAAM,YAAa,KAAK,OAAO,IAAI,YAAY,KAAK;QAClD,UAAU,KAAK;QACf,eAAe,KAAK,OAAO;OAC5B;AAOD,WAAK,iBAAiB,UAAU;AAEhC,WAAK,iBAAgB;IACvB;AAEQ,IAAAA,eAAA,UAAA,mBAAR,SAAyB,uBAA+B;AAAxD,UAAA,QAAA;AACE,UAAM,iBAAiB,KAAK;AACpB,UAAA,YAAc,KAAK,OAAM;AAKjC,WAAK,cAAc,IAAI,YACrB,MACC,KAAK,cAAc,IAAI,YAAY;QAClC,OAAO;QACP,aAAa,KAAK;QAClB,oBAAoB,KAAK,OAAO;QAChC,iBAAiB,sBAAsB,KAAK,MAAM;QAClD,OACE,wBAAwB,SACtB,kBAAkB,eAAe;QAErC;OACD,GACD,SAAS;AAGX,WAAK,sBAAsBC,MACzB,SAAC,GAAuB,SAA0B;AAChD,eAAO,MAAK,eAAe,GAAG,OAAO;MACvC,GACA;QACE,KACE,KAAK,OAAO,sBACZ,WAAW,mCAAmC;QAEhD,cAAc,SAAC,GAAqB;AAGlC,cAAM,QAAQ,EAAE,aAAa,MAAK,iBAAiB,MAAK;AACxD,cAAI,sBAAsB,KAAK,GAAG;AACxB,gBAAA,aAA8B,EAAC,YAAnB,KAAkB,EAAC,IAAf,YAAc,EAAC;AACvC,mBAAO,MAAM;cACX,EAAE;;;;;;;cAOF,EAAE;cACF,mBAAmB,EAAE,YAAY,IAAI,UAAS,CAAE;YAAC;UAErD;QACF;OACD;AAMH,2BAAI,IAAI,CAAC,KAAK,KAAK,OAAO,KAAK,eAAe,KAAK,CAAC,GAAE,QAAQ,SAAC,OAAK;AAClE,eAAA,MAAM,aAAY;MAAlB,CAAoB;IAExB;AAEO,IAAAD,eAAA,UAAA,UAAP,SAAe,MAA2B;AACxC,WAAK,KAAI;AAIT,UAAI;AAAM,aAAK,KAAK,QAAQ,IAAI;AAChC,aAAO;IACT;AAEO,IAAAA,eAAA,UAAA,UAAP,SAAe,YAA2B;AAA3B,UAAA,eAAA,QAAA;AAAA,qBAAA;MAA2B;AACxC,cAAQ,aAAa,KAAK,iBAAiB,KAAK,MAAM,QAAO;IAC/D;AAEO,IAAAA,eAAA,UAAA,OAAP,SAAe,SAA0B;AASrC,UAAAE,MACE,QAAO,mBADT,oBAAiBA,QAAA,SAAG,QAAKA;AAE3B,UAAI;AACF,eACE,KAAK,YAAY,sBAAqB,SAAA,SAAA,CAAA,GACjC,OAAO,GAAA,EACV,OAAO,QAAQ,aAAa,KAAK,iBAAiB,KAAK,MACvD,QAAQ,KAAK,QACb,kBAAiB,CAAA,CAAA,EAChB,UAAU;MAEjB,SAAS,GAAG;AACV,YAAI,aAAa,mBAAmB;AAMlC,iBAAO;QACT;AACA,cAAM;MACR;IACF;AAEO,IAAAF,eAAA,UAAA,QAAP,SAAa,SAA2B;AACtC,UAAI;AACF,UAAE,KAAK;AACP,eAAO,KAAK,YAAY,aAAa,KAAK,MAAM,OAAO;MACzD;AACE,YAAI,CAAC,EAAE,KAAK,WAAW,QAAQ,cAAc,OAAO;AAClD,eAAK,iBAAgB;QACvB;MACF;IACF;AAEO,IAAAA,eAAA,UAAA,SAAP,SACE,SAAoC;AAEpC,UAAI,OAAO,KAAK,SAAS,IAAI,KAAK,CAAC,QAAQ,IAAI;AAU7C,eAAO;MACT;AACA,UAAM,QAEF,QAAQ,aAER,KAAK,iBACL,KAAK;AACT,UAAI;AACF,UAAE,KAAK;AACP,eAAO,MAAM,OAAO,QAAQ,MAAM,cAAc,QAAQ,MAAM;MAChE;AACE,YAAI,CAAC,EAAE,KAAK,WAAW,QAAQ,cAAc,OAAO;AAClD,eAAK,iBAAgB;QACvB;MACF;IACF;AAEO,IAAAA,eAAA,UAAA,OAAP,SACE,SAA6C;AAE7C,aAAO,KAAK,YAAY,sBAAqB,SAAA,SAAA,CAAA,GACxC,OAAO,GAAA,EACV,OAAO,QAAQ,aAAa,KAAK,iBAAiB,KAAK,MACvD,QAAQ,QAAQ,MAAM,cACtB,QAAQ,KAAK,OAAM,CAAA,CAAA;IAEvB;AAEO,IAAAA,eAAA,UAAA,QAAP,SACE,OAA4C;AAD9C,UAAA,QAAA;AAGE,UAAI,CAAC,KAAK,QAAQ,MAAM;AAWtB,oBAAY,IAAI;MAClB;AACA,WAAK,QAAQ,IAAI,KAAK;AACtB,UAAI,MAAM,WAAW;AACnB,aAAK,oBAAoB,KAAK;MAChC;AACA,aAAO,WAAA;AAIL,YAAI,MAAK,QAAQ,OAAO,KAAK,KAAK,CAAC,MAAK,QAAQ,MAAM;AACpD,sBAAY,KAAI;QAClB;AAIA,cAAK,oBAAoB,OAAO,KAAK;MACvC;IACF;AAEO,IAAAA,eAAA,UAAA,KAAP,SAAU,SAQT;;AACC,yBAAmB,MAAK;AACxB,MAAAG,OAAM,MAAK;AACX,WAAK,qBAAqB,WAAU;AACpC,OAAAD,MAAA,KAAK,OAAO,eAAS,QAAAA,QAAA,SAAA,SAAAA,IAAE,YAAW;AAClC,UAAM,MAAM,KAAK,eAAe,GAAE;AAClC,UAAI,WAAW,CAAC,KAAK,SAAS;AAC5B,YAAI,QAAQ,kBAAkB;AAC5B,eAAK,iBAAiB,QAAQ,qBAAqB;QACrD,WAAW,QAAQ,uBAAuB;AACxC,eAAK,YAAY,WAAU;QAC7B;MACF;AACA,aAAO;IACT;AASO,IAAAF,eAAA,UAAA,SAAP,SAAc,QAAgB,YAAoB;AAChD,cAAQ,aAAa,KAAK,iBAAiB,KAAK,MAAM,OAAO,MAAM;IACrE;AAOO,IAAAA,eAAA,UAAA,UAAP,SAAe,QAAgB,YAAoB;AACjD,cAAQ,aAAa,KAAK,iBAAiB,KAAK,MAAM,QAAQ,MAAM;IACtE;AAQO,IAAAA,eAAA,UAAA,WAAP,SAAgB,QAA+B;AAC7C,UAAI,YAAY,MAAM;AAAG,eAAO,OAAO;AACvC,UAAI;AACF,eAAO,KAAK,SAAS,SAAS,MAAM,EAAE,CAAC;MACzC,SAAS,GAAG;AACV,mBAAU,YAAQ,SAAAI,WAAA,KAAA,CAAA;MACpB;IACF;AAEO,IAAAJ,eAAA,UAAA,QAAP,SAAa,SAA2B;AACtC,UAAI,CAAC,QAAQ,IAAI;AACf,YAAI,OAAO,KAAK,SAAS,IAAI,GAAG;AAG9B,iBAAO;QACT;AACA,kBAAO,SAAA,SAAA,CAAA,GAAQ,OAAO,GAAA,EAAE,IAAI,aAAY,CAAA;MAC1C;AACA,UAAI;AAKF,UAAE,KAAK;AAIP,eAAO,KAAK,eAAe,MAAM,SAAS,KAAK,IAAI;MACrD;AACE,YAAI,CAAC,EAAE,KAAK,WAAW,QAAQ,cAAc,OAAO;AAClD,eAAK,iBAAgB;QACvB;MACF;IACF;AAEO,IAAAA,eAAA,UAAA,QAAP,SAAa,SAA4B;AAAzC,UAAA,QAAA;AACE,WAAK,KAAI;AAET,yBAAmB,MAAK;AAExB,UAAI,WAAW,QAAQ,gBAAgB;AAGrC,aAAK,QAAQ,QAAQ,SAAC,OAAK;AAAK,iBAAA,MAAK,oBAAoB,OAAO,KAAK;QAArC,CAAsC;AACtE,aAAK,QAAQ,MAAK;AAClB,oBAAY,IAAI;MAClB,OAAO;AAOL,aAAK,iBAAgB;MACvB;AAEA,aAAO,QAAQ,QAAO;IACxB;AAEO,IAAAA,eAAA,UAAA,mBAAP,SAAwB,YAAkB;AACxC,UAAM,oBAAoB,KAAK,eAAe,YAAY,UAAU;AACpE,UAAI,sBAAsB,KAAK,gBAAgB;AAC7C,aAAK,iBAAiB;AACtB,aAAK,iBAAgB;MACvB;IACF;AAIO,IAAAA,eAAA,UAAA,QAAP,SACE,SAAyD;AAD3D,UAAA,QAAA;AAII,UAAA,SAIE,QAAO,QAHTE,MAGE,QAAO,YAHT,aAAUA,QAAA,SAAG,OAAIA,KACjB,mBAEE,QAAO,kBADT,iBACE,QAAO;AAEX,UAAI;AACJ,UAAM,UAAU,SAAC,OAAmB;AAC5B,YAAAA,MAA2B,OAAzB,OAAIA,IAAA,MAAE,iBAAcA,IAAA;AAC5B,UAAE,MAAK;AACP,YAAI,OAAO;AACT,gBAAK,OAAO,MAAK,iBAAiB;QACpC;AACA,YAAI;AACF,iBAAQ,eAAe,OAAO,KAAI;QACpC;AACE,YAAE,MAAK;AACP,gBAAK,OAAO;AACZ,gBAAK,iBAAiB;QACxB;MACF;AAEA,UAAM,eAAe,oBAAI,IAAG;AAE5B,UAAI,kBAAkB,CAAC,KAAK,SAAS;AAUnC,aAAK,iBAAgB,SAAA,SAAA,CAAA,GAChB,OAAO,GAAA,EACV,gBAAc,SAAC,OAAK;AAClB,uBAAa,IAAI,KAAK;AACtB,iBAAO;QACT,EAAC,CAAA,CAAA;MAEL;AAEA,UAAI,OAAO,eAAe,UAAU;AAIlC,aAAK,iBAAiB,KAAK,eAAe,SAAS,YAAY,OAAO;MACxE,WAAW,eAAe,OAAO;AAM/B,gBAAQ,KAAK,IAAI;MACnB,OAAO;AAGL,gBAAO;MACT;AAEA,UAAI,OAAO,qBAAqB,UAAU;AACxC,aAAK,iBAAiB,KAAK,eAAe,YAAY,gBAAgB;MACxE;AAKA,UAAI,kBAAkB,aAAa,MAAM;AACvC,aAAK,iBAAgB,SAAA,SAAA,CAAA,GAChB,OAAO,GAAA,EACV,gBAAc,SAAC,OAAO,MAAI;AACxB,cAAMG,UAAS,eAAe,KAAK,MAAM,OAAO,IAAI;AACpD,cAAIA,YAAW,OAAO;AAIpB,yBAAa,OAAO,KAAK;UAC3B;AACA,iBAAOA;QACT,EAAC,CAAA,CAAA;AAIH,YAAI,aAAa,MAAM;AACrB,uBAAa,QAAQ,SAAC,OAAK;AAAK,mBAAA,MAAK,oBAAoB,MAAM,KAAK;UAApC,CAAqC;QACvE;MACF,OAAO;AAIL,aAAK,iBAAiB,OAAO;MAC/B;AAEA,aAAO;IACT;AAEO,IAAAL,eAAA,UAAA,qBAAP,SACE,QACA,cAA4B;AAE5B,aAAO,KAAK,MAAM;QAChB;QACA,YAAY,gBAAgB,iBAAiB;OAC9C;IACH;AAEO,IAAAA,eAAA,UAAA,oBAAP,SAAyB,UAAsB;AAC7C,aAAO,KAAK,sBAAsB,KAAK,uBAAuB,QAAQ,CAAC;IACzE;AAEU,IAAAA,eAAA,UAAA,mBAAV,SAA2B,SAA0B;AAArD,UAAA,QAAA;AACE,UAAI,CAAC,KAAK,SAAS;AACjB,aAAK,QAAQ,QAAQ,SAAC,GAAC;AAAK,iBAAA,MAAK,oBAAoB,GAAG,OAAO;QAAnC,CAAoC;MAClE;IACF;AAEQ,IAAAA,eAAA,UAAA,yBAAR,SAA+B,UAAsB;AAC3C,UAAA,YAAc,KAAK,OAAM;AACjC,aAAO,YAAY,UAAU,UAAU,QAAQ,IAAI;IACrD;AAEQ,IAAAA,eAAA,UAAA,wBAAR,SAA8B,UAAsB;AAClD,UAAI,KAAK,aAAa;AACpB,eAAO,KAAK,qBAAqB,kBAAkB,QAAQ;MAC7D;AACA,aAAO;IACT;AAQQ,IAAAA,eAAA,UAAA,iBAAR,SAAuB,GAAuB,SAA0B;AAC9D,UAAA,WAAa,EAAC;AAQtB,UAAM,OAAO,KAAK,KAAU,CAAC;AAE7B,UAAI,SAAS;AACX,YAAI,EAAE,cAAc,OAAO,QAAQ,eAAe,UAAU;AAC1D,eAAK,4BAA4B;QACnC;AAEA,YACE,QAAQ,kBACR,QAAQ,eAAe,KAAK,MAAM,GAAG,MAAM,QAAQ,MAAM,OACzD;AAGA;QACF;MACF;AAEA,UAAI,CAAC,YAAY,CAAC,MAAM,SAAS,QAAQ,KAAK,MAAM,GAAG;AACrD,UAAE,SAAU,EAAE,WAAW,MAAO,QAAQ;MAC1C;IACF;AAUF,WAAAA;EAAA,EA3iBmC,WAAW;;AA6iB9C,IAAI,WAAU,YAAA,OAAA;AACZ,gBAAc,UAAU,qBAAqB;AAC/C;;;;ACtjBM,SAAU,yBAAsB;AACpC,MAAA,YAAA,CAAA;WAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAA4B;AAA5B,cAAA,EAAA,IAAA,UAAA,EAAA;;AAEA,SAAA,KAAW,iBAAgB,KAAA,MAAhB,kBAAgB,cAAA,CAAA,MAAA,GAAI,WAAS,KAAA,CAAA,GAAA;AAC1C;AAEA,IAAA;;EAAA,WAAA;AAME,aAAAM,oBAAA;AAAY,UAAA,YAAA,CAAA;eAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAA4B;AAA5B,kBAAA,EAAA,IAAA,UAAA,EAAA;;AALJ,WAAA,WAAwB,uBAAO,OAAO,IAAI;AAMhD,WAAK,YAAW;AAChB,UAAI,UAAU,QAAQ;AACpB,aAAK,SAAQ,MAAb,MAAiB,SAAS;MAC5B;IACF;AAEO,IAAAA,kBAAA,UAAA,WAAP,WAAA;AAAA,UAAA,QAAA;AAAgB,UAAA,YAAA,CAAA;eAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAA4B;AAA5B,kBAAA,EAAA,IAAA,UAAA,EAAA;;AACd,UAAM,cAAc,oBAAI,IAAG;AAC3B,gBAAU,QAAQ,SAAC,KAAiB;AAClC,+BAAuB,GAAG,EAAE,QAAQ,SAAC,MAAI;AACvC,sBAAY,IAAI,KAAK,KAAK,OAAO,IAAI;QACvC,CAAC;MACH,CAAC;AAED,kBAAY,QAAQ,SAAC,MAAM,MAAI;AAC7B,YAAI,SAAS,MAAK,SAAS,IAAI,GAAG;AAChC,gBAAK,SAAS,IAAI,IAAI;AACtB,gBAAK,WAAW,IAAI;QACtB;MACF,CAAC;AAED,aAAO;IACT;AAGQ,IAAAA,kBAAA,UAAA,aAAR,SAAmB,MAAY;IAAG;AAE3B,IAAAA,kBAAA,UAAA,cAAP,WAAA;AACE,UAAM,QAAQA,kBAAiB;AAC/B,WAAK,cAAc,KAAK,SAASC,MAAK,MAAM,OAAO,KAAK,IAAI,GAAG;QAC7D,cAAc,SAAC,KAAG;AAAK,iBAAA;QAAA;QACvB,KACE,WAAW,yBAAyB;OAEvC,GAAG;AACJ,WAAK,YAAYA,MAAK,MAAM,UAAU,KAAK,IAAI,GAAG;QAChD,OAAO;QACP,KACE,WAAW,4BAA4B;OAE1C;AACD,WAAK,sBAAsBA,MAAK,MAAM,oBAAoB,KAAK,IAAI,GAAG;QACpE,OAAO;QACP,KACE,WAAW,sCAAsC;OAEpD;IACH;AAOO,IAAAD,kBAAA,UAAA,SAAP,SAAc,cAAoB;AAChC,aAAO,KAAK,SAAS,YAAY,KAAK;IACxC;AAEO,IAAAA,kBAAA,UAAA,YAAP,SAAyC,UAAW;AAApD,UAAA,QAAA;AACE,UAAM,UAAU,oBAAI,IAAG;AACvB,6BAAuB,QAAQ,EAAE,QAAQ,SAAC,KAAG;AAC3C,gBAAQ,IAAI,IAAI,KAAK,OAAO,GAAG;MACjC,CAAC;AAED,UAAM,UAAU,oBAAI,IAAG;AACvB,UAAME,WAAU,SAAC,YAAkB;AACjC,YAAI,CAAC,QAAQ,IAAI,UAAU,GAAG;AAC5B,kBAAQ,IAAI,UAAU;QACxB;MACF;AAEA,UAAM,sBAAsB,SAAC,MAAa;AACxC,eAAA,OAAO,KAAK,MAAK,oBAAoB,IAAI,CAAC,EAAE,QAAQA,QAAO;MAA3D;AAEF,0BAAoB,QAAQ;AAE5B,UAAM,UAAoB,CAAA;AAC1B,UAAM,MAAmB,uBAAO,OAAO,IAAI;AAI3C,cAAQ,QAAQ,SAAC,cAAY;AAC3B,YAAM,mBAAmB,QAAQ,IAAI,YAAY;AACjD,YAAI,kBAAkB;AACpB,8BAAqB,IAAI,YAAY,IAAI,gBAAiB;QAC5D,OAAO;AACL,kBAAQ,KAAK,YAAY;AACzB,cAAM,MAAM,MAAK,OAAO,YAAY;AACpC,cAAI,KAAK;AACP,gCAAqB,IAAI,YAAY,IAAI,GAAI;UAC/C;QACF;MACF,CAAC;AAED,UAAI,QAAQ,QAAQ;AAClB,YAAM,iBAAyC,CAAA;AAC/C,gBAAQ,QAAQ,SAAC,MAAI;AACnB,cAAM,MAAM,IAAI,IAAI;AACpB,cAAI,KAAK;AACP,2BAAa,KAAK,GAAG;UACvB;QACF,CAAC;AAED,YAAI,eAAa,QAAQ;AACvB,qBAAQ,SAAA,SAAA,CAAA,GACH,QAAQ,GAAA,EACX,aAAa,SAAS,YAAY,OAAO,cAAY,EAAC,CAAA;QAE1D;MACF;AAEA,aAAO;IACT;AAEO,IAAAF,kBAAA,UAAA,sBAAP,SAA2BG,OAAa;AACtC,UAAM,UAA6B,uBAAO,OAAO,IAAI;AAErD,YAAMA,OAAM;QACV,gBAAc,SAAC,MAAI;AACjB,kBAAQ,KAAK,KAAK,KAAK,IAAI;QAC7B;OACD;AAED,aAAO;IACT;AACF,WAAAH;EAAA,EApIA;;",
  "names": ["InvariantError", "invariant", "_a", "value", "invariant", "_a", "defaultDispose", "maybe", "Slot", "hasOwnProperty", "dep", "_a", "dep", "hasOwnProperty", "wrap", "cache", "_a", "invariant", "root", "_a", "result", "invariant", "defaultMakeData", "forEach", "slice", "hasOwnProperty", "Trie", "isObjRef", "invariant", "_a", "canonicalStringify", "key", "_a", "result", "invariant", "_a", "DocumentTransform", "Trie", "wrap", "invariant", "print", "result", "invariant", "hasOwnProperty", "DeepMerger", "result", "Subscription", "SubscriptionObserver", "Observable", "forEach", "value", "root", "result", "Symbol", "result", "Concast", "result", "_a", "sources", "result", "_a", "result", "result", "toString", "hasOwnProperty", "_a", "ApolloCache", "wrap", "_a", "result", "Cache", "MissingFieldError", "_a", "_a", "result", "EntityStore", "invariant", "_a", "root", "CacheGroup", "Trie", "EntityStore", "Root", "_a", "Layer", "Stump", "root", "ObjectCanon", "Trie", "StoreReader", "wrap", "_a", "result", "result", "invariant", "caches", "cache", "invariant", "_a", "d", "_a", "Policies", "existing", "incoming", "invariant", "result", "supertypeSet", "_a", "invariant", "StoreWriter", "_a", "result", "dataId", "context", "invariant", "value", "Trie", "selectionSet", "_a", "invariant", "InMemoryCache", "wrap", "_a", "print", "invariant", "result", "FragmentRegistry", "wrap", "enqueue", "root"]
}
